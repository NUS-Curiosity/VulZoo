diff --git a/.vscode/settings.json b/.vscode/settings.json
index 72b612b862..a87e960bf2 100644
--- a/.vscode/settings.json
+++ b/.vscode/settings.json
@@ -2,6 +2,7 @@
   "cSpell.words": [
     "anythingllm",
     "Astra",
+    "comkey",
     "Dockerized",
     "Embeddable",
     "GROQ",
@@ -20,4 +21,4 @@
   ],
   "eslint.experimental.useFlatConfig": true,
   "docker.languageserver.formatter.ignoreMultilineInstructions": true
-}
+}
\ No newline at end of file
diff --git a/collector/extensions/index.js b/collector/extensions/index.js
index bcf2229f2d..0e91d17316 100644
--- a/collector/extensions/index.js
+++ b/collector/extensions/index.js
@@ -1,9 +1,10 @@
+const { verifyPayloadIntegrity } = require("../middleware/verifyIntegrity");
 const { reqBody } = require("../utils/http");
 
 function extensions(app) {
   if (!app) return;
 
-  app.post("/ext/github-repo", async function (request, response) {
+  app.post("/ext/github-repo", [verifyPayloadIntegrity], async function (request, response) {
     try {
       const loadGithubRepo = require("../utils/extensions/GithubRepo");
       const { success, reason, data } = await loadGithubRepo(reqBody(request));
@@ -24,7 +25,7 @@ function extensions(app) {
   });
 
   // gets all branches for a specific repo
-  app.post("/ext/github-repo/branches", async function (request, response) {
+  app.post("/ext/github-repo/branches", [verifyPayloadIntegrity], async function (request, response) {
     try {
       const GithubRepoLoader = require("../utils/extensions/GithubRepo/RepoLoader");
       const allBranches = await (new GithubRepoLoader(reqBody(request))).getRepoBranches()
@@ -48,7 +49,7 @@ function extensions(app) {
     return;
   });
 
-  app.post("/ext/youtube-transcript", async function (request, response) {
+  app.post("/ext/youtube-transcript", [verifyPayloadIntegrity], async function (request, response) {
     try {
       const loadYouTubeTranscript = require("../utils/extensions/YoutubeTranscript");
       const { success, reason, data } = await loadYouTubeTranscript(reqBody(request));
diff --git a/collector/index.js b/collector/index.js
index 910451e228..f316705925 100644
--- a/collector/index.js
+++ b/collector/index.js
@@ -13,6 +13,7 @@ const { processLink } = require("./processLink");
 const { wipeCollectorStorage } = require("./utils/files");
 const extensions = require("./extensions");
 const { processRawText } = require("./processRawText");
+const { verifyPayloadIntegrity } = require("./middleware/verifyIntegrity");
 const app = express();
 
 app.use(cors({ origin: true }));
@@ -24,71 +25,83 @@ app.use(
   })
 );
 
-app.post("/process", async function (request, response) {
-  const { filename, options = {} } = reqBody(request);
-  try {
-    const targetFilename = path
-      .normalize(filename)
-      .replace(/^(\.\.(\/|\\|$))+/, "");
-    const {
-      success,
-      reason,
-      documents = [],
-    } = await processSingleFile(targetFilename, options);
-    response
-      .status(200)
-      .json({ filename: targetFilename, success, reason, documents });
-  } catch (e) {
-    console.error(e);
-    response.status(200).json({
-      filename: filename,
-      success: false,
-      reason: "A processing error occurred.",
-      documents: [],
-    });
+app.post(
+  "/process",
+  [verifyPayloadIntegrity],
+  async function (request, response) {
+    const { filename, options = {} } = reqBody(request);
+    try {
+      const targetFilename = path
+        .normalize(filename)
+        .replace(/^(\.\.(\/|\\|$))+/, "");
+      const {
+        success,
+        reason,
+        documents = [],
+      } = await processSingleFile(targetFilename, options);
+      response
+        .status(200)
+        .json({ filename: targetFilename, success, reason, documents });
+    } catch (e) {
+      console.error(e);
+      response.status(200).json({
+        filename: filename,
+        success: false,
+        reason: "A processing error occurred.",
+        documents: [],
+      });
+    }
+    return;
   }
-  return;
-});
+);
 
-app.post("/process-link", async function (request, response) {
-  const { link } = reqBody(request);
-  try {
-    const { success, reason, documents = [] } = await processLink(link);
-    response.status(200).json({ url: link, success, reason, documents });
-  } catch (e) {
-    console.error(e);
-    response.status(200).json({
-      url: link,
-      success: false,
-      reason: "A processing error occurred.",
-      documents: [],
-    });
+app.post(
+  "/process-link",
+  [verifyPayloadIntegrity],
+  async function (request, response) {
+    const { link } = reqBody(request);
+    try {
+      const { success, reason, documents = [] } = await processLink(link);
+      response.status(200).json({ url: link, success, reason, documents });
+    } catch (e) {
+      console.error(e);
+      response.status(200).json({
+        url: link,
+        success: false,
+        reason: "A processing error occurred.",
+        documents: [],
+      });
+    }
+    return;
   }
-  return;
-});
+);
 
-app.post("/process-raw-text", async function (request, response) {
-  const { textContent, metadata } = reqBody(request);
-  try {
-    const {
-      success,
-      reason,
-      documents = [],
-    } = await processRawText(textContent, metadata);
-    response
-      .status(200)
-      .json({ filename: metadata.title, success, reason, documents });
-  } catch (e) {
-    console.error(e);
-    response.status(200).json({
-      filename: metadata?.title || "Unknown-doc.txt",
-      success: false,
-      reason: "A processing error occurred.",
-      documents: [],
-    });
+app.post(
+  "/process-raw-text",
+  [verifyPayloadIntegrity],
+  async function (request, response) {
+    const { textContent, metadata } = reqBody(request);
+    try {
+      const {
+        success,
+        reason,
+        documents = [],
+      } = await processRawText(textContent, metadata);
+      response
+        .status(200)
+        .json({ filename: metadata.title, success, reason, documents });
+    } catch (e) {
+      console.error(e);
+      response.status(200).json({
+        filename: metadata?.title || "Unknown-doc.txt",
+        success: false,
+        reason: "A processing error occurred.",
+        documents: [],
+      });
+    }
+    return;
   }
-  return;
-});
+);
 
 extensions(app);
 
diff --git a/collector/middleware/verifyIntegrity.js b/collector/middleware/verifyIntegrity.js
new file mode 100644
index 0000000000..0dcb3f75d1
--- /dev/null
+++ b/collector/middleware/verifyIntegrity.js
@@ -0,0 +1,21 @@
+const { CommunicationKey } = require("../utils/comKey");
+
+function verifyPayloadIntegrity(request, response, next) {
+  const comKey = new CommunicationKey();
+  if (process.env.NODE_ENV === "development") {
+    comKey.log('verifyPayloadIntegrity is skipped in development.')
+    next();
+    return;
+  }
+
+  const signature = request.header("X-Integrity");
+  if (!signature) return response.status(400).json({ msg: 'Failed integrity signature check.' })
+
+  const validSignedPayload = comKey.verify(signature, request.body);
+  if (!validSignedPayload) return response.status(400).json({ msg: 'Failed integrity signature check.' })
+  next();
+}
+
+module.exports = {
+  verifyPayloadIntegrity
+}
\ No newline at end of file
diff --git a/collector/processSingleFile/index.js b/collector/processSingleFile/index.js
index 37f47759a6..89dee17258 100644
--- a/collector/processSingleFile/index.js
+++ b/collector/processSingleFile/index.js
@@ -4,11 +4,27 @@ const {
   WATCH_DIRECTORY,
   SUPPORTED_FILETYPE_CONVERTERS,
 } = require("../utils/constants");
-const { trashFile, isTextType } = require("../utils/files");
+const {
+  trashFile,
+  isTextType,
+  normalizePath,
+  isWithin,
+} = require("../utils/files");
 const RESERVED_FILES = ["__HOTDIR__.md"];
 
 async function processSingleFile(targetFilename, options = {}) {
-  const fullFilePath = path.resolve(WATCH_DIRECTORY, targetFilename);
+  const fullFilePath = path.resolve(
+    WATCH_DIRECTORY,
+    normalizePath(targetFilename)
+  );
+  if (!isWithin(path.resolve(WATCH_DIRECTORY), fullFilePath)) {
+    return {
+      success: false,
+      reason: "Filename is a not a valid path to process.",
+      documents: [],
+    };
+  }
+
   if (RESERVED_FILES.includes(targetFilename)) {
     return {
       success: false,
diff --git a/collector/utils/comKey/index.js b/collector/utils/comKey/index.js
new file mode 100644
index 0000000000..0e96a6972b
--- /dev/null
+++ b/collector/utils/comKey/index.js
@@ -0,0 +1,42 @@
+const crypto = require("crypto");
+const fs = require("fs");
+const path = require("path");
+
+const keyPath =
+  process.env.NODE_ENV === "development"
+    ? path.resolve(__dirname, `../../../server/storage/comkey`)
+    : path.resolve(process.env.STORAGE_DIR, `comkey`);
+
+class CommunicationKey {
+  #pubKeyName = "ipc-pub.pem";
+  #storageLoc = keyPath;
+
+  constructor() {}
+
+  log(text, ...args) {
+    console.log(`\x1b[36m[CommunicationKeyVerify]\x1b[0m ${text}`, ...args);
+  }
+
+  #readPublicKey() {
+    return fs.readFileSync(path.resolve(this.#storageLoc, this.#pubKeyName));
+  }
+
+  // Given a signed payload from private key from /app/server/ this signature should
+  // decode to match the textData provided. This class does verification only in collector.
+  // Note: The textData is typically the JSON stringified body sent to the document processor API.
+  verify(signature = "", textData = "") {
+    try {
+      let data = textData;
+      if (typeof textData !== "string") data = JSON.stringify(data);
+      return crypto.verify(
+        "RSA-SHA256",
+        Buffer.from(data),
+        this.#readPublicKey(),
+        Buffer.from(signature, "hex")
+      );
+    } catch {}
+    return false;
+  }
+}
+
+module.exports = { CommunicationKey };
diff --git a/collector/utils/files/index.js b/collector/utils/files/index.js
index 02e178b074..5509a29906 100644
--- a/collector/utils/files/index.js
+++ b/collector/utils/files/index.js
@@ -119,10 +119,33 @@ async function wipeCollectorStorage() {
   return;
 }
 
+/**
+ * Checks if a given path is within another path.
+ * @param {string} outer - The outer path (should be resolved).
+ * @param {string} inner - The inner path (should be resolved).
+ * @returns {boolean} - Returns true if the inner path is within the outer path, false otherwise.
+ */
+function isWithin(outer, inner) {
+  if (outer === inner) return false;
+  const rel = path.relative(outer, inner);
+  return !rel.startsWith("../") && rel !== "..";
+}
+
+function normalizePath(filepath = "") {
+  const result = path
+    .normalize(filepath.trim())
+    .replace(/^(\.\.(\/|\\|$))+/, "")
+    .trim();
+  if (["..", ".", "/"].includes(result)) throw new Error("Invalid path.");
+  return result;
+}
+
 module.exports = {
   trashFile,
   isTextType,
   createdDate,
   writeToServerDocuments,
   wipeCollectorStorage,
+  normalizePath,
+  isWithin,
 };
diff --git a/docker/.env.example b/docker/.env.example
index ed6fd3bce6..5efb2c049a 100644
--- a/docker/.env.example
+++ b/docker/.env.example
@@ -27,6 +27,7 @@ GID='1000'
 
 # LLM_PROVIDER='lmstudio'
 # LMSTUDIO_BASE_PATH='http://your-server:1234/v1'
+# LMSTUDIO_MODEL_PREF='Loaded from Chat UI' # this is a bug in LMStudio 0.2.17
 # LMSTUDIO_MODEL_TOKEN_LIMIT=4096
 
 # LLM_PROVIDER='localai'
diff --git a/docker/HOW_TO_USE_DOCKER.md b/docker/HOW_TO_USE_DOCKER.md
index 20ae0ccf72..19a0920efb 100644
--- a/docker/HOW_TO_USE_DOCKER.md
+++ b/docker/HOW_TO_USE_DOCKER.md
@@ -109,6 +109,17 @@ container rebuilds or pulls from Docker Hub.
 
 Your docker host will show the image as online once the build process is completed. This will build the app to `http://localhost:3001`.
 
+## Integrations and one-click setups
+
+The integrations below are templates or tooling built by the community to make running the docker experience of AnythingLLM easier.
+
+### Use the Midori AI Subsystem to Manage AnythingLLM
+
+Follow the setup found on [Midori AI Subsystem Site](https://io.midori-ai.xyz/subsystem/manager/) for your host OS
+After setting that up install the AnythingLLM docker backend to the Midori AI Subsystem.
+
+Once that is done, you are all set!
+
 ## Common questions and fixes
 
 ### Cannot connect to service running on localhost!
diff --git a/frontend/src/assets/llmprovider/lmstudio.png b/frontend/src/assets/llmprovider/lmstudio.png
index a5dc75afb7..0a9dd41e7d 100644
Binary files a/frontend/src/assets/llmprovider/lmstudio.png and b/frontend/src/assets/llmprovider/lmstudio.png differ
diff --git a/frontend/src/components/LLMSelection/LMStudioOptions/index.jsx b/frontend/src/components/LLMSelection/LMStudioOptions/index.jsx
index 6b3b01796c..edb340c652 100644
--- a/frontend/src/components/LLMSelection/LMStudioOptions/index.jsx
+++ b/frontend/src/components/LLMSelection/LMStudioOptions/index.jsx
@@ -1,8 +1,15 @@
-import { Info } from "@phosphor-icons/react";
-import paths from "../../../utils/paths";
+import { useEffect, useState } from "react";
 import { Link } from "react-router-dom";
+import { Info } from "@phosphor-icons/react";
+import paths from "@/utils/paths";
+import System from "@/models/system";
 
 export default function LMStudioOptions({ settings, showAlert = false }) {
+  const [basePathValue, setBasePathValue] = useState(
+    settings?.LMStudioBasePath
+  );
+  const [basePath, setBasePath] = useState(settings?.LMStudioBasePath);
+
   return (
     <div className="w-full flex flex-col">
       {showAlert && (
@@ -36,8 +43,11 @@ export default function LMStudioOptions({ settings, showAlert = false }) {
             required={true}
             autoComplete="off"
             spellCheck={false}
+            onChange={(e) => setBasePathValue(e.target.value)}
+            onBlur={() => setBasePath(basePathValue)}
           />
         </div>
+        <LMStudioModelSelection settings={settings} basePath={basePath} />
         <div className="flex flex-col w-60">
           <label className="text-white text-sm font-semibold block mb-4">
             Token context window
@@ -58,3 +68,73 @@ export default function LMStudioOptions({ settings, showAlert = false }) {
     </div>
   );
 }
+
+function LMStudioModelSelection({ settings, basePath = null }) {
+  const [customModels, setCustomModels] = useState([]);
+  const [loading, setLoading] = useState(true);
+
+  useEffect(() => {
+    async function findCustomModels() {
+      if (!basePath || !basePath.includes("/v1")) {
+        setCustomModels([]);
+        setLoading(false);
+        return;
+      }
+      setLoading(true);
+      const { models } = await System.customModels("lmstudio", null, basePath);
+      setCustomModels(models || []);
+      setLoading(false);
+    }
+    findCustomModels();
+  }, [basePath]);
+
+  if (loading || customModels.length == 0) {
+    return (
+      <div className="flex flex-col w-60">
+        <label className="text-white text-sm font-semibold block mb-4">
+          Chat Model Selection
+        </label>
+        <select
+          name="LMStudioModelPref"
+          disabled={true}
+          className="bg-zinc-900 border-gray-500 text-white text-sm rounded-lg block w-full p-2.5"
+        >
+          <option disabled={true} selected={true}>
+            {basePath?.includes("/v1")
+              ? "-- loading available models --"
+              : "-- waiting for URL --"}
+          </option>
+        </select>
+      </div>
+    );
+  }
+
+  return (
+    <div className="flex flex-col w-60">
+      <label className="text-white text-sm font-semibold block mb-4">
+        Chat Model Selection
+      </label>
+      <select
+        name="LMStudioModelPref"
+        required={true}
+        className="bg-zinc-900 border-gray-500 text-white text-sm rounded-lg block w-full p-2.5"
+      >
+        {customModels.length > 0 && (
+          <optgroup label="Your loaded models">
+            {customModels.map((model) => {
+              return (
+                <option
+                  key={model.id}
+                  value={model.id}
+                  selected={settings.LMStudioModelPref === model.id}
+                >
+                  {model.id}
+                </option>
+              );
+            })}
+          </optgroup>
+        )}
+      </select>
+    </div>
+  );
+}
diff --git a/frontend/src/components/Modals/MangeWorkspace/Documents/Directory/FolderSelectionPopup/index.jsx b/frontend/src/components/Modals/MangeWorkspace/Documents/Directory/FolderSelectionPopup/index.jsx
index e7532bdaac..f8cd29c5f4 100644
--- a/frontend/src/components/Modals/MangeWorkspace/Documents/Directory/FolderSelectionPopup/index.jsx
+++ b/frontend/src/components/Modals/MangeWorkspace/Documents/Directory/FolderSelectionPopup/index.jsx
@@ -7,7 +7,7 @@ export default function FolderSelectionPopup({ folders, onSelect, onClose }) {
   };
 
   return (
-    <div className="absolute bottom-full left-0 mb-2 bg-white rounded-lg shadow-lg">
+    <div className="absolute bottom-full left-0 mb-2 bg-white rounded-lg shadow-lg max-h-40 overflow-y-auto no-scroll">
       <ul className="list-none m-1 p-0">
         {folders.map((folder) => (
           <li
diff --git a/frontend/src/components/Modals/Password/index.jsx b/frontend/src/components/Modals/Password/index.jsx
index 460a300551..8a3c259e84 100644
--- a/frontend/src/components/Modals/Password/index.jsx
+++ b/frontend/src/components/Modals/Password/index.jsx
@@ -35,7 +35,7 @@ export default function PasswordModal({ mode = "single" }) {
   );
 }
 
-export function usePasswordModal() {
+export function usePasswordModal(notry = false) {
   const [auth, setAuth] = useState({
     loading: true,
     requiresAuth: false,
@@ -48,7 +48,7 @@ export function usePasswordModal() {
 
       // If the last validity check is still valid
       // we can skip the loading.
-      if (!System.needsAuthCheck()) {
+      if (!System.needsAuthCheck() && notry === false) {
         setAuth({
           loading: false,
           requiresAuth: false,
@@ -61,7 +61,7 @@ export function usePasswordModal() {
       if (settings?.MultiUserMode) {
         const currentToken = window.localStorage.getItem(AUTH_TOKEN);
         if (!!currentToken) {
-          const valid = await System.checkAuth(currentToken);
+          const valid = notry ? false : await System.checkAuth(currentToken);
           if (!valid) {
             setAuth({
               loading: false,
@@ -103,7 +103,7 @@ export function usePasswordModal() {
 
         const currentToken = window.localStorage.getItem(AUTH_TOKEN);
         if (!!currentToken) {
-          const valid = await System.checkAuth(currentToken);
+          const valid = notry ? false : await System.checkAuth(currentToken);
           if (!valid) {
             setAuth({
               loading: false,
@@ -111,6 +111,8 @@ export function usePasswordModal() {
               mode: "single",
             });
             window.localStorage.removeItem(AUTH_TOKEN);
+            window.localStorage.removeItem(AUTH_USER);
+            window.localStorage.removeItem(AUTH_TIMESTAMP);
             return;
           } else {
             setAuth({
diff --git a/frontend/src/components/PrivateRoute/index.jsx b/frontend/src/components/PrivateRoute/index.jsx
index 8e7ed4fc6e..5045160c78 100644
--- a/frontend/src/components/PrivateRoute/index.jsx
+++ b/frontend/src/components/PrivateRoute/index.jsx
@@ -139,6 +139,6 @@ export default function PrivateRoute({ Component }) {
       <Component />
     </AppLayout>
   ) : (
-    <Navigate to={paths.login()} />
+    <Navigate to={paths.login(true)} />
   );
 }
diff --git a/frontend/src/components/UserMenu/UserButton/index.jsx b/frontend/src/components/UserMenu/UserButton/index.jsx
index 1a4122b291..74b90a0804 100644
--- a/frontend/src/components/UserMenu/UserButton/index.jsx
+++ b/frontend/src/components/UserMenu/UserButton/index.jsx
@@ -40,7 +40,7 @@ export default function UserButton() {
 
   if (mode === null) return null;
   return (
-    <div className="absolute top-9 right-10 w-fit h-fit z-99">
+    <div className="absolute top-3 right-4 md:top-9 md:right-10 w-fit h-fit z-99">
       <button
         ref={buttonRef}
         onClick={() => setShowMenu(!showMenu)}
diff --git a/frontend/src/models/admin.js b/frontend/src/models/admin.js
index e5dcc1715a..c8c9b4acda 100644
--- a/frontend/src/models/admin.js
+++ b/frontend/src/models/admin.js
@@ -66,8 +66,12 @@ const Admin = {
   },
   newInvite: async () => {
     return await fetch(`${API_BASE()}/admin/invite/new`, {
-      method: "GET",
+      method: "POST",
       headers: baseHeaders(),
+      body: JSON.stringify({
+        role,
+        workspaceIds,
+      }),
     })
       .then((res) => res.json())
       .catch((e) => {
diff --git a/frontend/src/pages/Admin/Invitations/NewInviteModal/index.jsx b/frontend/src/pages/Admin/Invitations/NewInviteModal/index.jsx
index 3aef87a658..e69da4ae70 100644
--- a/frontend/src/pages/Admin/Invitations/NewInviteModal/index.jsx
+++ b/frontend/src/pages/Admin/Invitations/NewInviteModal/index.jsx
@@ -1,16 +1,23 @@
 import React, { useEffect, useState } from "react";
 import { X } from "@phosphor-icons/react";
 import Admin from "@/models/admin";
+import Workspace from "@/models/workspace";
 
 export default function NewInviteModal({ closeModal }) {
   const [invite, setInvite] = useState(null);
   const [error, setError] = useState(null);
   const [copied, setCopied] = useState(false);
+  const [workspaces, setWorkspaces] = useState([]);
+  const [selectedWorkspaceIds, setSelectedWorkspaceIds] = useState([]);
 
   const handleCreate = async (e) => {
     setError(null);
     e.preventDefault();
-    const { invite: newInvite, error } = await Admin.newInvite();
+
+    const { invite: newInvite, error } = await Admin.newInvite({
+      role: null,
+      workspaceIds: selectedWorkspaceIds,
+    });
     if (!!newInvite) setInvite(newInvite);
     setError(error);
   };
@@ -21,6 +28,16 @@ export default function NewInviteModal({ closeModal }) {
     );
     setCopied(true);
   };
+
+  const handleWorkspaceSelection = (workspaceId) => {
+    if (selectedWorkspaceIds.includes(workspaceId)) {
+      const updated = selectedWorkspaceIds.filter((id) => id !== workspaceId);
+      setSelectedWorkspaceIds(updated);
+      return;
+    }
+    setSelectedWorkspaceIds([...selectedWorkspaceIds, workspaceId]);
+  };
+
   useEffect(() => {
     function resetStatus() {
       if (!copied) return false;
@@ -31,6 +48,15 @@ export default function NewInviteModal({ closeModal }) {
     resetStatus();
   }, [copied]);
 
+  useEffect(() => {
+    async function fetchWorkspaces() {
+      Workspace.all()
+        .then((workspaces) => setWorkspaces(workspaces))
+        .catch(() => setWorkspaces([]));
+    }
+    fetchWorkspaces();
+  }, []);
+
   return (
     <div className="relative w-[500px] max-w-2xl max-h-full">
       <div className="relative bg-main-gradient rounded-lg shadow">
@@ -61,11 +87,45 @@ export default function NewInviteModal({ closeModal }) {
               )}
               <p className="text-white text-xs md:text-sm">
                 After creation you will be able to copy the invite and send it
-                to a new user where they can create an account as a default
-                user.
+                to a new user where they can create an account as the{" "}
+                <b>default</b> role and automatically be added to workspaces
+                selected.
               </p>
             </div>
           </div>
+
+          {workspaces.length > 0 && !invite && (
+            <div className="p-6 flex w-full justify-between">
+              <div className="w-full">
+                <div className="flex flex-col gap-y-1  mb-2">
+                  <label
+                    htmlFor="workspaces"
+                    className="text-sm font-medium text-white"
+                  >
+                    Auto-add invitee to workspaces
+                  </label>
+                  <p className="text-white/60 text-xs">
+                    You can optionally automatically assign the user to the
+                    workspaces below by selecting them. By default, the user
+                    will not have any workspaces visible. You can assign
+                    workspaces later post-invite acceptance.
+                  </p>
+                </div>
+
+                <div className="flex flex-col gap-y-2">
+                  {workspaces.map((workspace) => (
+                    <WorkspaceOption
+                      key={workspace.id}
+                      workspace={workspace}
+                      selected={selectedWorkspaceIds.includes(workspace.id)}
+                      toggleSelection={handleWorkspaceSelection}
+                    />
+                  ))}
+                </div>
+              </div>
+            </div>
+          )}
+
           <div className="flex w-full justify-between items-center p-6 space-x-2 border-t rounded-b border-gray-500/50">
             {!invite ? (
               <>
@@ -99,3 +159,31 @@ export default function NewInviteModal({ closeModal }) {
     </div>
   );
 }
+
+function WorkspaceOption({ workspace, selected, toggleSelection }) {
+  return (
+    <button
+      type="button"
+      onClick={() => toggleSelection(workspace.id)}
+      className={`transition-all duration-300 w-full h-11 p-2.5 bg-white/10 rounded-lg flex justify-start items-center gap-2.5 cursor-pointer border border-transparent ${
+        selected ? "border-white border-opacity-40" : "border-none "
+      } hover:border-white/60`}
+    >
+      <input
+        type="radio"
+        name="workspace"
+        value={workspace.id}
+        checked={selected}
+        className="hidden"
+      />
+      <div
+        className={`w-4 h-4 rounded-full border-2 border-white mr-2 ${
+          selected ? "bg-white" : ""
+        }`}
+      ></div>
+      <div className="text-white text-sm font-medium font-['Plus Jakarta Sans'] leading-tight">
+        {workspace.name}
+      </div>
+    </button>
+  );
+}
diff --git a/frontend/src/pages/Login/index.jsx b/frontend/src/pages/Login/index.jsx
index cf8ab24930..4e77a5c662 100644
--- a/frontend/src/pages/Login/index.jsx
+++ b/frontend/src/pages/Login/index.jsx
@@ -3,9 +3,11 @@ import PasswordModal, { usePasswordModal } from "@/components/Modals/Password";
 import { FullScreenLoader } from "@/components/Preloader";
 import { Navigate } from "react-router-dom";
 import paths from "@/utils/paths";
+import useQuery from "@/hooks/useQuery";
 
 export default function Login() {
-  const { loading, requiresAuth, mode } = usePasswordModal();
+  const query = useQuery();
+  const { loading, requiresAuth, mode } = usePasswordModal(!!query.get("nt"));
   if (loading) return <FullScreenLoader />;
   if (requiresAuth === false) return <Navigate to={paths.home()} />;
 
diff --git a/frontend/src/utils/paths.js b/frontend/src/utils/paths.js
index 14d0a67527..97246d7bdf 100644
--- a/frontend/src/utils/paths.js
+++ b/frontend/src/utils/paths.js
@@ -4,8 +4,8 @@ export default {
   home: () => {
     return "/";
   },
-  login: () => {
-    return "/login";
+  login: (noTry = false) => {
+    return `/login${noTry ? "?nt=1" : ""}`;
   },
   onboarding: {
     home: () => {
diff --git a/server/.env.example b/server/.env.example
index 71c6b3effb..642df8d6f1 100644
--- a/server/.env.example
+++ b/server/.env.example
@@ -23,6 +23,7 @@ DATABASE_URL="file:../storage/anythingllm.db"
 
 # LLM_PROVIDER='lmstudio'
 # LMSTUDIO_BASE_PATH='http://your-server:1234/v1'
+# LMSTUDIO_MODEL_PREF='Loaded from Chat UI' # this is a bug in LMStudio 0.2.17
 # LMSTUDIO_MODEL_TOKEN_LIMIT=4096
 
 # LLM_PROVIDER='localai'
diff --git a/server/.gitignore b/server/.gitignore
index 33d72e6a4c..12d17a1af9 100644
--- a/server/.gitignore
+++ b/server/.gitignore
@@ -3,6 +3,7 @@
 storage/assets/*
 !storage/assets/anything-llm.png
 storage/documents/*
+storage/comkey/*
 storage/tmp/*
 storage/vector-cache/*.json
 storage/exports
diff --git a/server/endpoints/admin.js b/server/endpoints/admin.js
index 792cf2dd93..f55cbb6e7d 100644
--- a/server/endpoints/admin.js
+++ b/server/endpoints/admin.js
@@ -165,13 +165,18 @@ function adminEndpoints(app) {
     }
   );
 
-  app.get(
+  app.post(
     "/admin/invite/new",
     [validatedRequest, strictMultiUserRoleValid([ROLES.admin, ROLES.manager])],
     async (request, response) => {
       try {
         const user = await userFromSession(request, response);
-        const { invite, error } = await Invite.create(user.id);
+        const body = reqBody(request);
+        const { invite, error } = await Invite.create({
+          createdByUserId: user.id,
+          workspaceIds: body?.workspaceIds || [],
+        });
+
         await EventLogs.logEvent(
           "invite_created",
           {
diff --git a/server/endpoints/api/admin/index.js b/server/endpoints/api/admin/index.js
index e91672e007..228777ab52 100644
--- a/server/endpoints/api/admin/index.js
+++ b/server/endpoints/api/admin/index.js
@@ -323,6 +323,18 @@ function apiAdminEndpoints(app) {
     /*
     #swagger.tags = ['Admin']
     #swagger.description = 'Create a new invite code for someone to use to register with instance. Methods are disabled until multi user mode is enabled via the UI.'
+    #swagger.requestBody = {
+        description: 'Request body for creation parameters of the invitation',
+        required: false,
+        type: 'object',
+        content: {
+          "application/json": {
+            example: {
+              workspaceIds: [1,2,45],
+            }
+          }
+        }
+      }
     #swagger.responses[200] = {
       content: {
         "application/json": {
@@ -355,7 +367,10 @@ function apiAdminEndpoints(app) {
         return;
       }
 
-      const { invite, error } = await Invite.create();
+      const body = reqBody(request);
+      const { invite, error } = await Invite.create({
+        workspaceIds: body?.workspaceIds ?? [],
+      });
       response.status(200).json({ invite, error });
     } catch (e) {
       console.error(e);
diff --git a/server/endpoints/api/document/index.js b/server/endpoints/api/document/index.js
index 2bbbcf2b06..e1fc96f78c 100644
--- a/server/endpoints/api/document/index.js
+++ b/server/endpoints/api/document/index.js
@@ -1,6 +1,6 @@
 const { Telemetry } = require("../../../models/telemetry");
 const { validApiKey } = require("../../../utils/middleware/validApiKey");
-const { setupMulter } = require("../../../utils/files/multer");
+const { handleFileUpload } = require("../../../utils/files/multer");
 const {
   viewLocalFiles,
   findDocumentInDocuments,
@@ -9,7 +9,6 @@ const {
 const { reqBody } = require("../../../utils/http");
 const { EventLogs } = require("../../../models/eventLogs");
 const { CollectorApi } = require("../../../utils/collectorApi");
-const { handleUploads } = setupMulter();
 const fs = require("fs");
 const path = require("path");
 const { Document } = require("../../../models/documents");
@@ -23,8 +22,7 @@ function apiDocumentEndpoints(app) {
 
   app.post(
     "/v1/document/upload",
-    [validApiKey],
-    handleUploads.single("file"),
+    [validApiKey, handleFileUpload],
     async (request, response) => {
       /*
     #swagger.tags = ['Documents']
diff --git a/server/endpoints/system.js b/server/endpoints/system.js
index 16b4255d90..2c65c4b3c5 100644
--- a/server/endpoints/system.js
+++ b/server/endpoints/system.js
@@ -16,12 +16,11 @@ const {
   multiUserMode,
   queryParams,
 } = require("../utils/http");
-const { setupLogoUploads } = require("../utils/files/multer");
+const { handleAssetUpload } = require("../utils/files/multer");
 const { v4 } = require("uuid");
 const { SystemSettings } = require("../models/systemSettings");
 const { User } = require("../models/user");
 const { validatedRequest } = require("../utils/middleware/validatedRequest");
-const { handleLogoUploads } = setupLogoUploads();
 const {
   getDefaultFilename,
   determineLogoFilepath,
@@ -101,7 +100,7 @@ function systemEndpoints(app) {
 
       if (await SystemSettings.isMultiUserMode()) {
         const { username, password } = reqBody(request);
-        const existingUser = await User.get({ username });
+        const existingUser = await User.get({ username: String(username) });
 
         if (!existingUser) {
           await EventLogs.logEvent(
@@ -121,7 +120,7 @@ function systemEndpoints(app) {
           return;
         }
 
-        if (!bcrypt.compareSync(password, existingUser.password)) {
+        if (!bcrypt.compareSync(String(password), existingUser.password)) {
           await EventLogs.logEvent(
             "failed_login_invalid_password",
             {
@@ -382,9 +381,7 @@ function systemEndpoints(app) {
     [validatedRequest],
     async (request, response) => {
       try {
-        const { username, password } = reqBody(request);
-        const multiUserModeEnabled = await SystemSettings.isMultiUserMode();
-        if (multiUserModeEnabled) {
+        if (response.locals.multiUserMode) {
           response.status(200).json({
             success: false,
             error: "Multi-user mode is already enabled.",
@@ -392,12 +389,13 @@ function systemEndpoints(app) {
           return;
         }
 
+        const { username, password } = reqBody(request);
         const { user, error } = await User.create({
           username,
           password,
           role: ROLES.admin,
         });
-        await SystemSettings.updateSettings({
+        await SystemSettings._updateSettings({
           multi_user_mode: true,
           users_can_delete_workspaces: false,
           limit_user_messages: false,
@@ -419,7 +417,7 @@ function systemEndpoints(app) {
         response.status(200).json({ success: !!user, error });
       } catch (e) {
         await User.delete({});
-        await SystemSettings.updateSettings({
+        await SystemSettings._updateSettings({
           multi_user_mode: false,
         });
 
@@ -478,10 +476,13 @@ function systemEndpoints(app) {
 
   app.post(
     "/system/upload-logo",
-    [validatedRequest, flexUserRoleValid([ROLES.admin, ROLES.manager])],
-    handleLogoUploads.single("logo"),
+    [
+      validatedRequest,
+      flexUserRoleValid([ROLES.admin, ROLES.manager]),
+      handleAssetUpload,
+    ],
     async (request, response) => {
-      if (!request.file || !request.file.originalname) {
+      if (!request?.file || !request?.file.originalname) {
         return response.status(400).json({ message: "No logo file provided." });
       }
 
@@ -496,7 +497,7 @@ function systemEndpoints(app) {
         const existingLogoFilename = await SystemSettings.currentLogoFilename();
         await removeCustomLogo(existingLogoFilename);
 
-        const { success, error } = await SystemSettings.updateSettings({
+        const { success, error } = await SystemSettings._updateSettings({
           logo_filename: newFilename,
         });
 
@@ -530,7 +531,7 @@ function systemEndpoints(app) {
       try {
         const currentLogoFilename = await SystemSettings.currentLogoFilename();
         await removeCustomLogo(currentLogoFilename);
-        const { success, error } = await SystemSettings.updateSettings({
+        const { success, error } = await SystemSettings._updateSettings({
           logo_filename: LOGO_FILENAME,
         });
 
diff --git a/server/endpoints/workspaces.js b/server/endpoints/workspaces.js
index aa835f26eb..7aa31bdf4e 100644
--- a/server/endpoints/workspaces.js
+++ b/server/endpoints/workspaces.js
@@ -1,10 +1,13 @@
+const path = require("path");
+const fs = require("fs");
 const { reqBody, multiUserMode, userFromSession } = require("../utils/http");
+const { normalizePath } = require("../utils/files");
 const { Workspace } = require("../models/workspace");
 const { Document } = require("../models/documents");
 const { DocumentVectors } = require("../models/vectors");
 const { WorkspaceChats } = require("../models/workspaceChats");
 const { getVectorDbClass } = require("../utils/helpers");
-const { setupMulter } = require("../utils/files/multer");
+const { handleFileUpload, handlePfpUpload } = require("../utils/files/multer");
 const { validatedRequest } = require("../utils/middleware/validatedRequest");
 const { Telemetry } = require("../models/telemetry");
 const {
@@ -18,12 +21,6 @@ const {
 const { validWorkspaceSlug } = require("../utils/middleware/validWorkspace");
 const { convertToChatHistory } = require("../utils/helpers/chat/responses");
 const { CollectorApi } = require("../utils/collectorApi");
-const { handleUploads } = setupMulter();
-const { setupPfpUploads } = require("../utils/files/multer");
-const { normalizePath } = require("../utils/files");
-const { handlePfpUploads } = setupPfpUploads();
-const path = require("path");
-const fs = require("fs");
 const {
   determineWorkspacePfpFilepath,
   fetchPfp,
@@ -101,8 +98,11 @@ function workspaceEndpoints(app) {
 
   app.post(
     "/workspace/:slug/upload",
-    [validatedRequest, flexUserRoleValid([ROLES.admin, ROLES.manager])],
-    handleUploads.single("file"),
+    [
+      validatedRequest,
+      flexUserRoleValid([ROLES.admin, ROLES.manager]),
+      handleFileUpload,
+    ],
     async function (request, response) {
       const Collector = new CollectorApi();
       const { originalname } = request.file;
@@ -478,8 +478,11 @@ function workspaceEndpoints(app) {
 
   app.post(
     "/workspace/:slug/upload-pfp",
-    [validatedRequest, flexUserRoleValid([ROLES.admin, ROLES.manager])],
-    handlePfpUploads.single("file"),
+    [
+      validatedRequest,
+      flexUserRoleValid([ROLES.admin, ROLES.manager]),
+      handlePfpUpload,
+    ],
     async function (request, response) {
       try {
         const { slug } = request.params;
diff --git a/server/index.js b/server/index.js
index 926acea867..e3da102c77 100644
--- a/server/index.js
+++ b/server/index.js
@@ -25,6 +25,7 @@ const { workspaceThreadEndpoints } = require("./endpoints/workspaceThreads");
 const {
   preloadOllamaService,
 } = require("./utils/AiProviders/anythingLLM/utils/preload");
+const { CommunicationKey } = require("./utils/comKey");
 const app = express();
 const apiRouter = express.Router();
 const FILE_LIMIT = "3GB";
@@ -62,6 +63,7 @@ app
   .listen(process.env.SERVER_PORT || 3001, async () => {
     await setupTelemetry();
     await preloadOllamaService();
+    new CommunicationKey(true);
     console.log(
       `[${
         process.env.NODE_ENV || "development"
diff --git a/server/models/invite.js b/server/models/invite.js
index ff9ae86871..781a9434fd 100644
--- a/server/models/invite.js
+++ b/server/models/invite.js
@@ -1,3 +1,4 @@
+const { safeJsonParse } = require("../utils/http");
 const prisma = require("../utils/prisma");
 
 const Invite = {
@@ -6,12 +7,13 @@ const Invite = {
     return uuidAPIKey.create().apiKey;
   },
 
-  create: async function (createdByUserId = 0) {
+  create: async function ({ createdByUserId = 0, workspaceIds = [] }) {
     try {
       const invite = await prisma.invites.create({
         data: {
           code: this.makeCode(),
           createdBy: createdByUserId,
+          workspaceIds: JSON.stringify(workspaceIds),
         },
       });
       return { invite, error: null };
@@ -23,7 +25,7 @@ const Invite = {
 
   deactivate: async function (inviteId = null) {
     try {
-      const invite = await prisma.invites.update({
+      await prisma.invites.update({
         where: { id: Number(inviteId) },
         data: { status: "disabled" },
       });
@@ -40,6 +42,26 @@ const Invite = {
         where: { id: Number(inviteId) },
         data: { status: "claimed", claimedBy: user.id },
       });
+
+      try {
+        if (!!invite?.workspaceIds) {
+          const { Workspace } = require("./workspace");
+          const { WorkspaceUser } = require("./workspaceUsers");
+          const workspaceIds = (await Workspace.where({})).map(
+            (workspace) => workspace.id
+          );
+          const ids = safeJsonParse(invite.workspaceIds)
+            .map((id) => Number(id))
+            .filter((id) => workspaceIds.includes(id));
+          if (ids.length !== 0) await WorkspaceUser.createMany(user.id, ids);
+        }
+      } catch (e) {
+        console.error(
+          "Could not add user to workspaces automatically",
+          e.message
+        );
+      }
+
       return { success: true, error: null };
     } catch (error) {
       console.error(error.message);
diff --git a/server/models/systemSettings.js b/server/models/systemSettings.js
index 9841321f7d..1db745f498 100644
--- a/server/models/systemSettings.js
+++ b/server/models/systemSettings.js
@@ -5,10 +5,11 @@ require("dotenv").config({
     : `${path.join(__dirname, ".env")}`,
 });
 
+const { isValidUrl } = require("../utils/http");
 const prisma = require("../utils/prisma");
 const SystemSettings = {
+  protectedFields: ["multi_user_mode"],
   supportedFields: [
-    "multi_user_mode",
     "users_can_delete_workspaces",
     "limit_user_messages",
     "message_limit",
@@ -20,8 +21,10 @@ const SystemSettings = {
   validations: {
     footer_data: (updates) => {
       try {
-        const array = JSON.parse(updates);
-        return JSON.stringify(array.slice(0, 3)); // max of 3 items in footer.
+        const array = JSON.parse(updates)
+          .filter((setting) => isValidUrl(setting.url))
+          .slice(0, 3); // max of 3 items in footer.
+        return JSON.stringify(array);
       } catch (e) {
         console.error(`Failed to run validation function on footer_data`);
         return JSON.stringify([]);
@@ -139,6 +142,7 @@ const SystemSettings = {
         ? {
             LMStudioBasePath: process.env.LMSTUDIO_BASE_PATH,
             LMStudioTokenLimit: process.env.LMSTUDIO_MODEL_TOKEN_LIMIT,
+            LMStudioModelPref: process.env.LMSTUDIO_MODEL_PREF,
 
             // For embedding credentials when lmstudio is selected.
             OpenAiKey: !!process.env.OPEN_AI_KEY,
@@ -283,26 +287,43 @@ const SystemSettings = {
     }
   },
 
+  // Can take generic keys and will pre-filter invalid keys
+  // from the set before sending to the explicit update function
+  // that will then enforce validations as well.
   updateSettings: async function (updates = {}) {
+    const validFields = Object.keys(updates).filter((key) =>
+      this.supportedFields.includes(key)
+    );
+
+    Object.entries(updates).forEach(([key]) => {
+      if (validFields.includes(key)) return;
+      delete updates[key];
+    });
+
+    return this._updateSettings(updates);
+  },
+
+  // Explicit update of settings + key validations.
+  // Only use this method when directly setting a key value
+  // that takes no user input for the keys being modified.
+  _updateSettings: async function (updates = {}) {
     try {
-      const updatePromises = Object.keys(updates)
-        .filter((key) => this.supportedFields.includes(key))
-        .map((key) => {
-          const validatedValue = this.validations.hasOwnProperty(key)
-            ? this.validations[key](updates[key])
-            : updates[key];
+      const updatePromises = Object.keys(updates).map((key) => {
+        const validatedValue = this.validations.hasOwnProperty(key)
+          ? this.validations[key](updates[key])
+          : updates[key];
 
-          return prisma.system_settings.upsert({
-            where: { label: key },
-            update: {
-              value: validatedValue === null ? null : String(validatedValue),
-            },
-            create: {
-              label: key,
-              value: validatedValue === null ? null : String(validatedValue),
-            },
-          });
+        return prisma.system_settings.upsert({
+          where: { label: key },
+          update: {
+            value: validatedValue === null ? null : String(validatedValue),
+          },
+          create: {
+            label: key,
+            value: validatedValue === null ? null : String(validatedValue),
+          },
         });
+      });
 
       await Promise.all(updatePromises);
       return { success: true, error: null };
diff --git a/server/models/telemetry.js b/server/models/telemetry.js
index 2f49011044..1d1b6252cc 100644
--- a/server/models/telemetry.js
+++ b/server/models/telemetry.js
@@ -65,7 +65,7 @@ const Telemetry = {
 
   setUid: async function () {
     const newId = v4();
-    await SystemSettings.updateSettings({ [this.label]: newId });
+    await SystemSettings._updateSettings({ [this.label]: newId });
     return newId;
   },
 
diff --git a/server/models/welcomeMessages.js b/server/models/welcomeMessages.js
index 88393f36cd..a24c43c9aa 100644
--- a/server/models/welcomeMessages.js
+++ b/server/models/welcomeMessages.js
@@ -34,7 +34,7 @@ const WelcomeMessages = {
       // We create each message individually because prisma
       // with sqlite does not support createMany()
       for (const [index, message] of messages.entries()) {
-        if (!message.response) continue;
+        if (!message.response && !message.user) continue;
         await prisma.welcome_messages.create({
           data: {
             user: message.user,
diff --git a/server/models/workspaceThread.js b/server/models/workspaceThread.js
index 45c9b0f118..0f99082b45 100644
--- a/server/models/workspaceThread.js
+++ b/server/models/workspaceThread.js
@@ -25,16 +25,19 @@ const WorkspaceThread = {
   update: async function (prevThread = null, data = {}) {
     if (!prevThread) throw new Error("No thread id provided for update");
 
-    const validKeys = Object.keys(data).filter((key) =>
-      this.writable.includes(key)
-    );
-    if (validKeys.length === 0)
+    const validData = {};
+    Object.entries(data).forEach(([key, value]) => {
+      if (!this.writable.includes(key)) return;
+      validData[key] = value;
+    });
+
+    if (Object.keys(validData).length === 0)
       return { thread: prevThread, message: "No valid fields to update!" };
 
     try {
       const thread = await prisma.workspace_threads.update({
         where: { id: prevThread.id },
-        data,
+        data: validData,
       });
       return { thread, message: null };
     } catch (error) {
diff --git a/server/prisma/migrations/20240326231053_init/migration.sql b/server/prisma/migrations/20240326231053_init/migration.sql
new file mode 100644
index 0000000000..85fe8be755
--- /dev/null
+++ b/server/prisma/migrations/20240326231053_init/migration.sql
@@ -0,0 +1,2 @@
+-- AlterTable
+ALTER TABLE "invites" ADD COLUMN "workspaceIds" TEXT;
diff --git a/server/prisma/schema.prisma b/server/prisma/schema.prisma
index fc3db268fd..11e0d86108 100644
--- a/server/prisma/schema.prisma
+++ b/server/prisma/schema.prisma
@@ -41,6 +41,7 @@ model invites {
   code          String   @unique
   status        String   @default("pending")
   claimedBy     Int?
+  workspaceIds  String?
   createdAt     DateTime @default(now())
   createdBy     Int
   lastUpdatedAt DateTime @default(now())
@@ -100,7 +101,7 @@ model workspaces {
   chatModel                    String?
   topN                         Int?                           @default(4)
   chatMode                     String?                        @default("chat")
-  pfpFilename     String?
+  pfpFilename                  String?
   workspace_users              workspace_users[]
   documents                    workspace_documents[]
   workspace_suggested_messages workspace_suggested_messages[]
diff --git a/server/swagger/openapi.json b/server/swagger/openapi.json
index 77dc974ad4..e0ee35a563 100644
--- a/server/swagger/openapi.json
+++ b/server/swagger/openapi.json
@@ -489,6 +489,22 @@
           "500": {
             "description": "Internal Server Error"
           }
+        },
+        "requestBody": {
+          "description": "Request body for creation parameters of the invitation",
+          "required": false,
+          "type": "object",
+          "content": {
+            "application/json": {
+              "example": {
+                "workspaceIds": [
+                  1,
+                  2,
+                  45
+                ]
+              }
+            }
+          }
         }
       }
     },
diff --git a/server/utils/AiProviders/gemini/index.js b/server/utils/AiProviders/gemini/index.js
index 3d334b2919..35885a2c6c 100644
--- a/server/utils/AiProviders/gemini/index.js
+++ b/server/utils/AiProviders/gemini/index.js
@@ -87,7 +87,7 @@ class GeminiLLM {
   formatMessages(messages = []) {
     // Gemini roles are either user || model.
     // and all "content" is relabeled to "parts"
-    return messages
+    const allMessages = messages
       .map((message) => {
         if (message.role === "system")
           return { role: "user", parts: message.content };
@@ -98,6 +98,16 @@ class GeminiLLM {
         return null;
       })
       .filter((msg) => !!msg);
+
+    // Specifically, Google cannot have the last sent message be from a user with no assistant reply
+    // otherwise it will crash. So if the last item is from the user, it was not completed so pop it off
+    // the history.
+    if (
+      allMessages.length > 0 &&
+      allMessages[allMessages.length - 1].role === "user"
+    )
+      allMessages.pop();
+    return allMessages;
   }
 
   async sendChat(chatHistory = [], prompt, workspace = {}, rawHistory = []) {
@@ -210,7 +220,27 @@ class GeminiLLM {
       response.on("close", handleAbort);
 
       for await (const chunk of stream) {
-        fullText += chunk.text();
+        let chunkText;
+        try {
+          // Due to content sensitivity we cannot always get the function .text();
+          // https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes#gemini-TASK-samples-nodejs
+          // and it is not possible to unblock or disable this safety protocol without being allowlisted by Google.
+          chunkText = chunk.text();
+        } catch (e) {
+          chunkText = e.message;
+          writeResponseChunk(response, {
+            uuid,
+            sources: [],
+            type: "abort",
+            textResponse: null,
+            close: true,
+            error: e.message,
+          });
+          resolve(e.message);
+          return;
+        }
+
+        fullText += chunkText;
         writeResponseChunk(response, {
           uuid,
           sources: [],
diff --git a/server/utils/AiProviders/lmStudio/index.js b/server/utils/AiProviders/lmStudio/index.js
index f0e55ecdad..1db495ada1 100644
--- a/server/utils/AiProviders/lmStudio/index.js
+++ b/server/utils/AiProviders/lmStudio/index.js
@@ -13,9 +13,14 @@ class LMStudioLLM {
       basePath: process.env.LMSTUDIO_BASE_PATH?.replace(/\/+$/, ""), // here is the URL to your LMStudio instance
     });
     this.lmstudio = new OpenAIApi(config);
-    // When using LMStudios inference server - the model param is not required so
-    // we can stub it here. LMStudio can only run one model at a time.
-    this.model = "model-placeholder";
+
+    // Prior to LMStudio 0.2.17 the `model` param was not required and you could pass anything
+    // into that field and it would work. On 0.2.17 LMStudio introduced multi-model chat
+    // which now has a bug that reports the server model id as "Loaded from Chat UI"
+    // and any other value will crash inferencing. So until this is patched we will
+    // try to fetch the `/models` and have the user set it, or just fallback to "Loaded from Chat UI"
+    // which will not impact users with <v0.2.17 and should work as well once the bug is fixed.
+    this.model = process.env.LMSTUDIO_MODEL_PREF || "Loaded from Chat UI";
     this.limits = {
       history: this.promptWindowLimit() * 0.15,
       system: this.promptWindowLimit() * 0.15,
diff --git a/server/utils/boot/index.js b/server/utils/boot/index.js
new file mode 100644
index 0000000000..ea95e1f52c
--- /dev/null
+++ b/server/utils/boot/index.js
@@ -0,0 +1,66 @@
+const { Telemetry } = require("../../models/telemetry");
+const { CommunicationKey } = require("../comKey");
+const setupTelemetry = require("../telemetry");
+
+function bootSSL(app, port = 3001) {
+  try {
+    console.log(
+      `\x1b[33m[SSL BOOT ENABLED]\x1b[0m Loading the certificate and key for HTTPS mode...`
+    );
+    const fs = require("fs");
+    const https = require("https");
+    const privateKey = fs.readFileSync(process.env.HTTPS_KEY_PATH);
+    const certificate = fs.readFileSync(process.env.HTTPS_CERT_PATH);
+    const credentials = { key: privateKey, cert: certificate };
+
+    https
+      .createServer(credentials, app)
+      .listen(port, async () => {
+        await setupTelemetry();
+        new CommunicationKey(true);
+        console.log(`Primary server in HTTPS mode listening on port ${port}`);
+      })
+      .on("error", catchSigTerms);
+    return app;
+  } catch (e) {
+    console.error(
+      `\x1b[31m[SSL BOOT FAILED]\x1b[0m ${e.message} - falling back to HTTP boot.`,
+      {
+        ENABLE_HTTPS: process.env.ENABLE_HTTPS,
+        HTTPS_KEY_PATH: process.env.HTTPS_KEY_PATH,
+        HTTPS_CERT_PATH: process.env.HTTPS_CERT_PATH,
+        stacktrace: e.stack,
+      }
+    );
+    return bootHTTP(app, port);
+  }
+}
+
+function bootHTTP(app, port = 3001) {
+  if (!app) throw new Error('No "app" defined - crashing!');
+
+  app
+    .listen(port, async () => {
+      await setupTelemetry();
+      new CommunicationKey(true);
+      console.log(`Primary server in HTTP mode listening on port ${port}`);
+    })
+    .on("error", catchSigTerms);
+  return app;
+}
+
+function catchSigTerms() {
+  process.once("SIGUSR2", function () {
+    Telemetry.flush();
+    process.kill(process.pid, "SIGUSR2");
+  });
+  process.on("SIGINT", function () {
+    Telemetry.flush();
+    process.kill(process.pid, "SIGINT");
+  });
+}
+
+module.exports = {
+  bootHTTP,
+  bootSSL,
+};
diff --git a/server/utils/collectorApi/index.js b/server/utils/collectorApi/index.js
index 5ba006e4c9..6c43625dd8 100644
--- a/server/utils/collectorApi/index.js
+++ b/server/utils/collectorApi/index.js
@@ -5,6 +5,8 @@
 
 class CollectorApi {
   constructor() {
+    const { CommunicationKey } = require("../comKey");
+    this.comkey = new CommunicationKey();
     this.endpoint = `http://0.0.0.0:${process.env.COLLECTOR_PORT || 8888}`;
   }
 
@@ -40,15 +42,19 @@ class CollectorApi {
 
   async processDocument(filename = "") {
     if (!filename) return false;
+
+    const data = JSON.stringify({
+      filename,
+      options: this.#attachOptions(),
+    });
+
     return await fetch(`${this.endpoint}/process`, {
       method: "POST",
       headers: {
         "Content-Type": "application/json",
+        "X-Integrity": this.comkey.sign(data),
       },
-      body: JSON.stringify({
-        filename,
-        options: this.#attachOptions(),
-      }),
+      body: data,
     })
       .then((res) => {
         if (!res.ok) throw new Error("Response could not be completed");
@@ -64,12 +70,14 @@ class CollectorApi {
   async processLink(link = "") {
     if (!link) return false;
 
+    const data = JSON.stringify({ link });
     return await fetch(`${this.endpoint}/process-link`, {
       method: "POST",
       headers: {
         "Content-Type": "application/json",
+        "X-Integrity": this.comkey.sign(data),
       },
-      body: JSON.stringify({ link }),
+      body: data,
     })
       .then((res) => {
         if (!res.ok) throw new Error("Response could not be completed");
@@ -83,12 +91,14 @@ class CollectorApi {
   }
 
   async processRawText(textContent = "", metadata = {}) {
+    const data = JSON.stringify({ textContent, metadata });
     return await fetch(`${this.endpoint}/process-raw-text`, {
       method: "POST",
       headers: {
         "Content-Type": "application/json",
+        "X-Integrity": this.comkey.sign(data),
       },
-      body: JSON.stringify({ textContent, metadata }),
+      body: data,
     })
       .then((res) => {
         if (!res.ok) throw new Error("Response could not be completed");
@@ -110,6 +120,7 @@ class CollectorApi {
       body, // Stringified JSON!
       headers: {
         "Content-Type": "application/json",
+        "X-Integrity": this.comkey.sign(body),
       },
     })
       .then((res) => {
diff --git a/server/utils/comKey/index.js b/server/utils/comKey/index.js
new file mode 100644
index 0000000000..e545a6be51
--- /dev/null
+++ b/server/utils/comKey/index.js
@@ -0,0 +1,75 @@
+const crypto = require("crypto");
+const fs = require("fs");
+const path = require("path");
+const keyPath =
+  process.env.NODE_ENV === "development"
+    ? path.resolve(__dirname, `../../storage/comkey`)
+    : path.resolve(process.env.STORAGE_DIR, `comkey`);
+
+// What does this class do?
+// This class generates a hashed version of some text (typically a JSON payload) using a rolling RSA key
+// that can then be appended as a header value to do integrity checking on a payload. Given the
+// nature of this class and that keys are rolled constantly, this protects the request
+// integrity of requests sent to the collector as only the server can sign these requests.
+// This keeps accidental misconfigurations of AnythingLLM that leaving port 8888 open from
+// being abused or SSRF'd by users scraping malicious sites who have a loopback embedded in a <script>, for example.
+// Since each request to the collector must be signed to be valid, unsigned requests directly to the collector
+// will be dropped and must go through the /server endpoint directly.
+class CommunicationKey {
+  #privKeyName = "ipc-priv.pem";
+  #pubKeyName = "ipc-pub.pem";
+  #storageLoc = keyPath;
+
+  // Init the class and determine if keys should be rolled.
+  // This typically occurs on boot up so key is fresh each boot.
+  constructor(generate = false) {
+    if (generate) this.#generate();
+  }
+
+  log(text, ...args) {
+    console.log(`\x1b[36m[CommunicationKey]\x1b[0m ${text}`, ...args);
+  }
+
+  #readPrivateKey() {
+    return fs.readFileSync(path.resolve(this.#storageLoc, this.#privKeyName));
+  }
+
+  #generate() {
+    const keyPair = crypto.generateKeyPairSync("rsa", {
+      modulusLength: 2048,
+      publicKeyEncoding: {
+        type: "pkcs1",
+        format: "pem",
+      },
+      privateKeyEncoding: {
+        type: "pkcs1",
+        format: "pem",
+      },
+    });
+
+    if (!fs.existsSync(this.#storageLoc))
+      fs.mkdirSync(this.#storageLoc, { recursive: true });
+    fs.writeFileSync(
+      `${path.resolve(this.#storageLoc, this.#privKeyName)}`,
+      keyPair.privateKey
+    );
+    fs.writeFileSync(
+      `${path.resolve(this.#storageLoc, this.#pubKeyName)}`,
+      keyPair.publicKey
+    );
+    this.log(
+      "RSA key pair generated for signed payloads within AnythingLLM services."
+    );
+  }
+
+  // This instance of ComKey on server is intended for generation of Priv/Pub key for signing and decoding.
+  // this resource is shared with /collector/ via a class of the same name in /utils which does decoding/verification only
+  // while this server class only does signing with the private key.
+  sign(textData = "") {
+    return crypto
+      .sign("RSA-SHA256", Buffer.from(textData), this.#readPrivateKey())
+      .toString("hex");
+  }
+}
+
+module.exports = { CommunicationKey };
diff --git a/server/utils/files/logo.js b/server/utils/files/logo.js
index eb4738b09d..68c56c2173 100644
--- a/server/utils/files/logo.js
+++ b/server/utils/files/logo.js
@@ -3,6 +3,7 @@ const fs = require("fs");
 const { getType } = require("mime");
 const { v4 } = require("uuid");
 const { SystemSettings } = require("../../models/systemSettings");
+const { normalizePath } = require(".");
 const LOGO_FILENAME = "anything-llm.png";
 
 function validFilename(newFilename = "") {
@@ -21,7 +22,7 @@ async function determineLogoFilepath(defaultFilename = LOGO_FILENAME) {
   const defaultFilepath = path.join(basePath, defaultFilename);
 
   if (currentLogoFilename && validFilename(currentLogoFilename)) {
-    customLogoPath = path.join(basePath, currentLogoFilename);
+    customLogoPath = path.join(basePath, normalizePath(currentLogoFilename));
     return fs.existsSync(customLogoPath) ? customLogoPath : defaultFilepath;
   }
 
@@ -52,11 +53,19 @@ async function renameLogoFile(originalFilename = null) {
   const extname = path.extname(originalFilename) || ".png";
   const newFilename = `${v4()}${extname}`;
   const originalFilepath = process.env.STORAGE_DIR
-    ? path.join(process.env.STORAGE_DIR, "assets", originalFilename)
-    : path.join(__dirname, `../../storage/assets/${originalFilename}`);
+    ? path.join(
+        process.env.STORAGE_DIR,
+        "assets",
+        normalizePath(originalFilename)
+      )
+    : path.join(
+        __dirname,
+        `../../storage/assets`,
+        normalizePath(originalFilename)
+      );
   const outputFilepath = process.env.STORAGE_DIR
-    ? path.join(process.env.STORAGE_DIR, "assets", newFilename)
-    : path.join(__dirname, `../../storage/assets/${newFilename}`);
+    ? path.join(process.env.STORAGE_DIR, "assets", normalizePath(newFilename))
+    : path.join(__dirname, `../../storage/assets`, normalizePath(newFilename));
 
   fs.renameSync(originalFilepath, outputFilepath);
   return newFilename;
@@ -65,8 +74,8 @@ async function renameLogoFile(originalFilename = null) {
 async function removeCustomLogo(logoFilename = LOGO_FILENAME) {
   if (!logoFilename || !validFilename(logoFilename)) return false;
   const logoPath = process.env.STORAGE_DIR
-    ? path.join(process.env.STORAGE_DIR, `assets/${logoFilename}`)
-    : path.join(__dirname, `../../storage/assets/${logoFilename}`);
+    ? path.join(process.env.STORAGE_DIR, `assets`, normalizePath(logoFilename))
+    : path.join(__dirname, `../../storage/assets`, normalizePath(logoFilename));
   if (fs.existsSync(logoPath)) fs.unlinkSync(logoPath);
   return true;
 }
diff --git a/server/utils/files/multer.js b/server/utils/files/multer.js
index 1daab9ed2e..1355c6ab44 100644
--- a/server/utils/files/multer.js
+++ b/server/utils/files/multer.js
@@ -2,71 +2,114 @@ const multer = require("multer");
 const path = require("path");
 const fs = require("fs");
 
-function setupMulter() {
-  // Handle File uploads for auto-uploading.
-  const storage = multer.diskStorage({
-    destination: function (_, __, cb) {
-      const uploadOutput =
-        process.env.NODE_ENV === "development"
-          ? path.resolve(__dirname, `../../../collector/hotdir`)
-          : path.resolve(process.env.STORAGE_DIR, `hotdir`);
-      cb(null, uploadOutput);
-    },
-    filename: function (_, file, cb) {
-      file.originalname = Buffer.from(file.originalname, "latin1").toString(
-        "utf8"
-      );
-      cb(null, file.originalname);
-    },
-  });
+// Handle File uploads for auto-uploading.
+const fileUploadStorage = multer.diskStorage({
+  destination: function (_, __, cb) {
+    const uploadOutput =
+      process.env.NODE_ENV === "development"
+        ? path.resolve(__dirname, `../../../collector/hotdir`)
+        : path.resolve(process.env.STORAGE_DIR, `../../collector/hotdir`);
+    cb(null, uploadOutput);
+  },
+  filename: function (_, file, cb) {
+    file.originalname = Buffer.from(file.originalname, "latin1").toString(
+      "utf8"
+    );
+    cb(null, file.originalname);
+  },
+});
 
-  return { handleUploads: multer({ storage }) };
-}
+// Asset storage for logos
+const assetUploadStorage = multer.diskStorage({
+  destination: function (_, __, cb) {
+    const uploadOutput =
+      process.env.NODE_ENV === "development"
+        ? path.resolve(__dirname, `../../storage/assets`)
+        : path.resolve(process.env.STORAGE_DIR, "assets");
+    fs.mkdirSync(uploadOutput, { recursive: true });
+    return cb(null, uploadOutput);
+  },
+  filename: function (_, file, cb) {
+    file.originalname = Buffer.from(file.originalname, "latin1").toString(
+      "utf8"
+    );
+    cb(null, file.originalname);
+  },
+});
 
-function setupLogoUploads() {
-  // Handle Logo uploads.
-  const storage = multer.diskStorage({
-    destination: function (_, __, cb) {
-      const uploadOutput =
-        process.env.NODE_ENV === "development"
-          ? path.resolve(__dirname, `../../storage/assets`)
-          : path.resolve(process.env.STORAGE_DIR, "assets");
-      fs.mkdirSync(uploadOutput, { recursive: true });
-      return cb(null, uploadOutput);
-    },
-    filename: function (_, file, cb) {
-      file.originalname = Buffer.from(file.originalname, "latin1").toString(
-        "utf8"
-      );
-      cb(null, file.originalname);
-    },
-  });
+// Asset sub-storage manager for pfp icons.
+const pfpUploadStorage = multer.diskStorage({
+  destination: function (_, __, cb) {
+    const uploadOutput =
+      process.env.NODE_ENV === "development"
+        ? path.resolve(__dirname, `../../storage/assets/pfp`)
+        : path.resolve(process.env.STORAGE_DIR, "assets/pfp");
+    fs.mkdirSync(uploadOutput, { recursive: true });
+    return cb(null, uploadOutput);
+  },
+  filename: function (req, file, cb) {
+    const randomFileName = `${v4()}${path.extname(file.originalname)}`;
+    req.randomFileName = randomFileName;
+    cb(null, randomFileName);
+  },
+});
 
-  return { handleLogoUploads: multer({ storage }) };
+// Handle Generic file upload as documents
+function handleFileUpload(request, response, next) {
+  const upload = multer({ storage: fileUploadStorage }).single("file");
+  upload(request, response, function (err) {
+    if (err) {
+      response
+        .status(500)
+        .json({
+          success: false,
+          error: `Invalid file upload. ${err.message}`,
+        })
+        .end();
+      return;
+    }
+    next();
+  });
 }
 
-function setupPfpUploads() {
-  const storage = multer.diskStorage({
-    destination: function (_, __, cb) {
-      const uploadOutput =
-        process.env.NODE_ENV === "development"
-          ? path.resolve(__dirname, `../../storage/assets/pfp`)
-          : path.resolve(process.env.STORAGE_DIR, "assets/pfp");
-      fs.mkdirSync(uploadOutput, { recursive: true });
-      return cb(null, uploadOutput);
-    },
-    filename: function (req, file, cb) {
-      const randomFileName = `${v4()}${path.extname(file.originalname)}`;
-      req.randomFileName = randomFileName;
-      cb(null, randomFileName);
-    },
+// Handle logo asset uploads
+function handleAssetUpload(request, response, next) {
+  const upload = multer({ storage: assetUploadStorage }).single("logo");
+  upload(request, response, function (err) {
+    if (err) {
+      response
+        .status(500)
+        .json({
+          success: false,
+          error: `Invalid file upload. ${err.message}`,
+        })
+        .end();
+      return;
+    }
+    next();
   });
+}
 
-  return { handlePfpUploads: multer({ storage }) };
+// Handle PFP file upload as logos
+function handlePfpUpload(request, response, next) {
+  const upload = multer({ storage: pfpUploadStorage }).single("file");
+  upload(request, response, function (err) {
+    if (err) {
+      response
+        .status(500)
+        .json({
+          success: false,
+          error: `Invalid file upload. ${err.message}`,
+        })
+        .end();
+      return;
+    }
+    next();
+  });
 }
 
 module.exports = {
-  setupMulter,
-  setupLogoUploads,
-  setupPfpUploads,
+  handleFileUpload,
+  handleAssetUpload,
+  handlePfpUpload,
 };
diff --git a/server/utils/helpers/customModels.js b/server/utils/helpers/customModels.js
index c8991ffa67..2a6098796a 100644
--- a/server/utils/helpers/customModels.js
+++ b/server/utils/helpers/customModels.js
@@ -11,6 +11,7 @@ const SUPPORT_CUSTOM_MODELS = [
   "perplexity",
   "openrouter",
   "anythingllm_ollama",
+  "lmstudio",
 ];
 
 async function getCustomModels(provider = "", apiKey = null, basePath = null) {
@@ -36,6 +37,8 @@ async function getCustomModels(provider = "", apiKey = null, basePath = null) {
       return await getOpenRouterModels();
     case "anythingllm_ollama":
       return await getAnythingOllamaModels();
+    case "lmstudio":
+      return await getLMStudioModels(basePath);
     default:
       return { models: [], error: "Invalid provider for custom models" };
   }
@@ -84,6 +87,28 @@ async function localAIModels(basePath = null, apiKey = null) {
   return { models, error: null };
 }
 
+async function getLMStudioModels(basePath = null) {
+  try {
+    const { Configuration, OpenAIApi } = require("openai");
+    const config = new Configuration({
+      basePath: basePath || process.env.LMSTUDIO_BASE_PATH,
+    });
+    const openai = new OpenAIApi(config);
+    const models = await openai
+      .listModels()
+      .then((res) => res.data.data)
+      .catch((e) => {
+        console.error(`LMStudio:listModels`, e.message);
+        return [];
+      });
+
+    return { models, error: null };
+  } catch (e) {
+    console.error(`LMStudio:getLMStudioModels`, e.message);
+    return { models: [], error: "Could not fetch LMStudio Models" };
+  }
+}
+
 async function ollamaAIModels(basePath = null) {
   let url;
   try {
diff --git a/server/utils/helpers/updateENV.js b/server/utils/helpers/updateENV.js
index 5755733dcf..dab26e4452 100644
--- a/server/utils/helpers/updateENV.js
+++ b/server/utils/helpers/updateENV.js
@@ -59,6 +59,10 @@ const KEY_MAPPING = {
     envKey: "LMSTUDIO_BASE_PATH",
     checks: [isNotEmpty, validLLMExternalBasePath, validDockerizedUrl],
   },
+  LMStudioModelPref: {
+    envKey: "LMSTUDIO_MODEL_PREF",
+    checks: [],
+  },
   LMStudioTokenLimit: {
     envKey: "LMSTUDIO_MODEL_TOKEN_LIMIT",
     checks: [nonZero],
@@ -561,6 +565,16 @@ async function dumpENV() {
     "DISABLE_TELEMETRY",
   ];
 
+  // Simple sanitization of each value to prevent ENV injection via newline or quote escaping.
+  function sanitizeValue(value) {
+    const offendingChars =
+      /[\n\r\t\v\f\u0085\u00a0\u1680\u180e\u2000-\u200a\u2028\u2029\u202f\u205f\u3000"'`#]/;
+    const firstOffendingCharIndex = value.search(offendingChars);
+    if (firstOffendingCharIndex === -1) return value;
+
+    return value.substring(0, firstOffendingCharIndex);
+  }
+
   for (const key of protectedKeys) {
     const envValue = process.env?.[key] || null;
     if (!envValue) continue;
@@ -569,9 +583,7 @@ async function dumpENV() {
 
   var envResult = `# Auto-dump ENV from system call on ${new Date().toTimeString()}\n`;
   envResult += Object.entries(frozenEnvs)
-    .map(([key, value]) => {
-      return `${key}='${value}'`;
-    })
+    .map(([key, value]) => `${key}='${sanitizeValue(value)}'`)
     .join("\n");
 
   const envPath = process.env.STORAGE_DIR
diff --git a/server/utils/http/index.js b/server/utils/http/index.js
index 5a19605fca..010e7d4024 100644
--- a/server/utils/http/index.js
+++ b/server/utils/http/index.js
@@ -69,6 +69,15 @@ function safeJsonParse(jsonString, fallback = null) {
   return fallback;
 }
 
+function isValidUrl(urlString = "") {
+  try {
+    const url = new URL(urlString);
+    if (!["http:", "https:"].includes(url.protocol)) return false;
+    return true;
+  } catch (e) {}
+  return false;
+}
+
 module.exports = {
   reqBody,
   multiUserMode,
@@ -78,4 +87,5 @@ module.exports = {
   userFromSession,
   parseAuthHeader,
   safeJsonParse,
+  isValidUrl,
 };
diff --git a/server/utils/middleware/validatedRequest.js b/server/utils/middleware/validatedRequest.js
index 6f3df26dab..551090a07a 100644
--- a/server/utils/middleware/validatedRequest.js
+++ b/server/utils/middleware/validatedRequest.js
@@ -38,9 +38,17 @@ async function validatedRequest(request, response, next) {
 
   const bcrypt = require("bcrypt");
   const { p } = decodeJWT(token);
+
+  if (p === null) {
+    response.status(401).json({
+      error: "Token expired or failed validation.",
+    });
+    return;
+  }
+
   if (!bcrypt.compareSync(p, bcrypt.hashSync(process.env.AUTH_TOKEN, 10))) {
     response.status(401).json({
-      error: "Invalid auth token found.",
+      error: "Invalid auth credentials.",
     });
     return;
   }
