diff --git a/lib/completions/endpoints/base.rb b/lib/completions/endpoints/base.rb
index e86a9a8e7..d9962a5bd 100644
--- a/lib/completions/endpoints/base.rb
+++ b/lib/completions/endpoints/base.rb
@@ -69,7 +69,7 @@ def perform_completion!(dialect, user, model_params = {})
 
           prompt = dialect.translate
 
-          Net::HTTP.start(
+          FinalDestination::HTTP.start(
             model_uri.host,
             model_uri.port,
             use_ssl: true,
diff --git a/lib/inference/cloudflare_workers_ai.rb b/lib/inference/cloudflare_workers_ai.rb
index 42b5039a2..134dc9f62 100644
--- a/lib/inference/cloudflare_workers_ai.rb
+++ b/lib/inference/cloudflare_workers_ai.rb
@@ -14,7 +14,8 @@ def self.perform!(model, content)
 
         endpoint = "#{base_url}#{model}"
 
-        response = Faraday.post(endpoint, content.to_json, headers)
+        conn = Faraday.new { |f| f.adapter FinalDestination::FaradayAdapter }
+        response = conn.post(endpoint, content.to_json, headers)
 
         raise Net::HTTPBadResponse if ![200].include?(response.status)
 
diff --git a/lib/inference/discourse_classifier.rb b/lib/inference/discourse_classifier.rb
index 041b746c5..3784a190c 100644
--- a/lib/inference/discourse_classifier.rb
+++ b/lib/inference/discourse_classifier.rb
@@ -8,7 +8,8 @@ def self.perform!(endpoint, model, content, api_key)
 
         headers["X-API-KEY"] = api_key if api_key.present?
 
-        response = Faraday.post(endpoint, { model: model, content: content }.to_json, headers)
+        conn = Faraday.new { |f| f.adapter FinalDestination::FaradayAdapter }
+        response = conn.post(endpoint, { model: model, content: content }.to_json, headers)
 
         raise Net::HTTPBadResponse if ![200, 415].include?(response.status)
 
diff --git a/lib/inference/discourse_reranker.rb b/lib/inference/discourse_reranker.rb
index 76513886b..35b097995 100644
--- a/lib/inference/discourse_reranker.rb
+++ b/lib/inference/discourse_reranker.rb
@@ -8,8 +8,9 @@ def self.perform!(endpoint, model, content, candidates, api_key)
 
         headers["X-API-KEY"] = api_key if api_key.present?
 
+        conn = Faraday.new { |f| f.adapter FinalDestination::FaradayAdapter }
         response =
-          Faraday.post(
+          conn.post(
             endpoint,
             { model: model, content: content, candidates: candidates }.to_json,
             headers,
diff --git a/lib/inference/gemini_embeddings.rb b/lib/inference/gemini_embeddings.rb
index 933b0fe32..0bd78645f 100644
--- a/lib/inference/gemini_embeddings.rb
+++ b/lib/inference/gemini_embeddings.rb
@@ -11,7 +11,8 @@ def self.perform!(content)
 
         body = { content: { parts: [{ text: content }] } }
 
-        response = Faraday.post(url, body.to_json, headers)
+        conn = Faraday.new { |f| f.adapter FinalDestination::FaradayAdapter }
+        response = conn.post(url, body.to_json, headers)
 
         raise Net::HTTPBadResponse if ![200].include?(response.status)
 
diff --git a/lib/inference/hugging_face_text_embeddings.rb b/lib/inference/hugging_face_text_embeddings.rb
index 09118bcb3..6ec7af88c 100644
--- a/lib/inference/hugging_face_text_embeddings.rb
+++ b/lib/inference/hugging_face_text_embeddings.rb
@@ -18,7 +18,8 @@ def self.perform!(content)
           headers["X-API-KEY"] = SiteSetting.ai_hugging_face_tei_api_key
         end
 
-        response = Faraday.post(api_endpoint, body, headers)
+        conn = Faraday.new { |f| f.adapter FinalDestination::FaradayAdapter }
+        response = conn.post(api_endpoint, body, headers)
 
         raise Net::HTTPBadResponse if ![200].include?(response.status)
 
diff --git a/lib/inference/open_ai_embeddings.rb b/lib/inference/open_ai_embeddings.rb
index 6826a896f..9ffcaa49a 100644
--- a/lib/inference/open_ai_embeddings.rb
+++ b/lib/inference/open_ai_embeddings.rb
@@ -15,7 +15,8 @@ def self.perform!(content, model:, dimensions: nil)
         payload = { model: model, input: content }
         payload[:dimensions] = dimensions if dimensions.present?
 
-        response = Faraday.post(SiteSetting.ai_openai_embeddings_url, payload.to_json, headers)
+        conn = Faraday.new { |f| f.adapter FinalDestination::FaradayAdapter }
+        response = conn.post(SiteSetting.ai_openai_embeddings_url, payload.to_json, headers)
 
         case response.status
         when 200
diff --git a/lib/inference/open_ai_image_generator.rb b/lib/inference/open_ai_image_generator.rb
index f8cc203ba..d91168f4b 100644
--- a/lib/inference/open_ai_image_generator.rb
+++ b/lib/inference/open_ai_image_generator.rb
@@ -28,7 +28,7 @@ def self.perform!(prompt, model: "dall-e-3", size: "1024x1024", api_key: nil, ap
           response_format: "b64_json",
         }
 
-        Net::HTTP.start(
+        FinalDestination::HTTP.start(
           uri.host,
           uri.port,
           use_ssl: uri.scheme == "https",
diff --git a/lib/inference/stability_generator.rb b/lib/inference/stability_generator.rb
index cdd1a7b1d..47bc6814a 100644
--- a/lib/inference/stability_generator.rb
+++ b/lib/inference/stability_generator.rb
@@ -57,7 +57,8 @@ def self.perform!(
 
         endpoint = "v1/generation/#{engine}/text-to-image"
 
-        response = Faraday.post("#{api_url}/#{endpoint}", payload.to_json, headers)
+        conn = Faraday.new { |f| f.adapter FinalDestination::FaradayAdapter }
+        response = conn.post("#{api_url}/#{endpoint}", payload.to_json, headers)
 
         if response.status != 200
           Rails.logger.error(
diff --git a/spec/lib/completions/endpoints/endpoint_compliance.rb b/spec/lib/completions/endpoints/endpoint_compliance.rb
index 0fc3671c0..d26ec91d1 100644
--- a/spec/lib/completions/endpoints/endpoint_compliance.rb
+++ b/spec/lib/completions/endpoints/endpoint_compliance.rb
@@ -99,13 +99,13 @@ def tool
 
   def with_chunk_array_support
     mock = mocked_http
-    @original_net_http = ::Net.send(:remove_const, :HTTP)
-    ::Net.send(:const_set, :HTTP, mock)
+    @original_net_http = ::FinalDestination.send(:remove_const, :HTTP)
+    ::FinalDestination.send(:const_set, :HTTP, mock)
 
     yield
   ensure
-    ::Net.send(:remove_const, :HTTP)
-    ::Net.send(:const_set, :HTTP, @original_net_http)
+    ::FinalDestination.send(:remove_const, :HTTP)
+    ::FinalDestination.send(:const_set, :HTTP, @original_net_http)
   end
 
   protected
@@ -113,7 +113,7 @@ def with_chunk_array_support
   # Copied from https://github.com/bblimke/webmock/issues/629
   # Workaround for stubbing a streamed response
   def mocked_http
-    Class.new(::Net::HTTP) do
+    Class.new(FinalDestination::HTTP) do
       def request(*)
         super do |response|
           response.instance_eval do
