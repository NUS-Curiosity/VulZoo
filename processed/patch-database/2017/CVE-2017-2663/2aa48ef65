diff --git a/Makefile b/Makefile
index 61bbb93c84..f8ce37f519 100644
--- a/Makefile
+++ b/Makefile
@@ -13,18 +13,20 @@
 #   just the fastest or easiest way.
 
 SHELL := /bin/bash
-PREFIX ?=
+PREFIX ?= /
 SYSCONF ?= etc
 INSTALL_DIR = usr/share
 
-PYTHON_SITELIB ?= usr/lib/python2.7/site-packages
-# Note the underscore used instead of a hyphen
-PYTHON_INST_DIR = $(PREFIX)/$(PYTHON_SITELIB)/subscription_manager
-
 OS = $(shell lsb_release -i | awk '{ print $$3 }' | awk -F. '{ print $$1}')
 OS_VERSION = $(shell lsb_release -r | awk '{ print $$2 }' | awk -F. '{ print $$1}')
 OS_DIST ?= $(shell rpm --eval='%dist')
 
+PYTHON_VER ?= $(python -c 'import sys; print("python%s.%s" % sys.version_info[:2])')
+
+PYTHON_SITELIB ?= usr/lib/$(PYTHON_VER)/site-packages
+# Note the underscore used instead of a hyphen
+PYTHON_INST_DIR = $(PREFIX)/$(PYTHON_SITELIB)/subscription_manager
+
 # Where various bits of code live in the git repo
 SRC_DIR := src/subscription_manager
 RCT_SRC_DIR := src/rct
@@ -41,6 +43,7 @@ RHSM_PLUGIN_DIR := $(PREFIX)/usr/share/rhsm-plugins/
 RHSM_PLUGIN_CONF_DIR := $(PREFIX)/etc/rhsm/pluginconf.d/
 ANACONDA_ADDON_INST_DIR := $(PREFIX)/usr/share/anaconda/addons
 INITIAL_SETUP_INST_DIR := $(ANACONDA_ADDON_INST_DIR)/$(ANACONDA_ADDON_NAME)
+POLKIT_ACTIONS_INST_DIR := $(PREFIX)/$(INSTALL_DIR)/polkit-1/actions
 LIBEXEC_DIR ?= $(shell rpm --eval='%_libexecdir')
 
 # If we skip install ostree plugin, unset by default
@@ -53,6 +56,7 @@ ifeq ($(OS_DIST),.el6)
    FIRSTBOOT_MODULES_DIR?=$(PREFIX)/usr/share/rhn/up2date_client/firstboot
    INSTALL_FIRSTBOOT?=true
    INSTALL_INITIAL_SETUP?=false
+   DBUS_SERVICE_FILE_TYPE?=dbus
 else ifeq ($(OS),SUSE)
    GTK_VERSION?=2
    FIRSTBOOT_MODULES_DIR?=$(PREFIX)/usr/share/rhn/up2date_client/firstboot
@@ -63,6 +67,21 @@ else
    FIRSTBOOT_MODULES_DIR?=$(PREFIX)/usr/share/firstboot/modules
    INSTALL_FIRSTBOOT?=true
    INSTALL_INITIAL_SETUP?=true
+   DBUS_SERVICE_FILE_TYPE?=systemd
+endif
+
+DBUS_SERVICES_CONF_INST_DIR := $(PREFIX)/usr/share/dbus-1/system-services
+FACTS_INST_DBUS_SERVICE_FILE = $(DBUS_SERVICES_CONF_INST_DIR)/com.redhat.RHSM1.Facts.service
+MAIN_INST_DBUS_SERVICE_FILE = $(DBUS_SERVICES_CONF_INST_DIR)/com.redhat.RHSM1.service
+# TODO Ideally these service files would be installed by distutils, but the file we actually
+# install depends on the distro we are using.  Add a --without-systemd or similar flag to the
+# custom install_data class we have in setup.py
+ifeq ($(DBUS_SERVICE_FILE_TYPE),dbus)
+FACTS_SRC_DBUS_SERVICE_FILE = etc-conf/dbus/com.redhat.RHSM1.Facts.service-dbus
+MAIN_SRC_DBUS_SERVICE_FILE = etc-conf/dbus/com.redhat.RHSM1.service-dbus
+else
+FACTS_SRC_DBUS_SERVICE_FILE = etc-conf/dbus/com.redhat.RHSM1.Facts.service
+MAIN_SRC_DBUS_SERVICE_FILE = etc-conf/dbus/com.redhat.RHSM1.service
 endif
 
 # always true until fedora is just dnf
@@ -119,17 +138,36 @@ rhsm-icon: $(RHSM_ICON_SRC_DIR)/rhsm_icon.c
 check-syntax:
 	$(CC) -fsyntax-only $(CFLAGS) $(LDFLAGS) $(ICON_FLAGS) `find -name '*.c'`
 
-.PHONY: dbus-service-install
-dbus-service-install:
+dbus-common-install:
 	install -d $(PREFIX)/etc/dbus-1/system.d
+	if [ "$(DBUS_SERVICE_FILE_TYPE)" == "systemd" ]; then \
+		install -d $(SYSTEMD_INST_DIR) ; \
+	fi
 	install -d $(PREFIX)/$(INSTALL_DIR)/dbus-1/system-services
 	install -d $(PREFIX)/$(LIBEXEC_DIR)
-	install -m 644 etc-conf/com.redhat.SubscriptionManager.conf \
-		$(PREFIX)/etc/dbus-1/system.d
-	install -m 644 etc-conf/com.redhat.SubscriptionManager.service \
-		$(PREFIX)/$(INSTALL_DIR)/dbus-1/system-services
-	install -m 744 $(DAEMONS_SRC_DIR)/rhsm_d.py \
-		$(PREFIX)/$(LIBEXEC_DIR)/rhsmd
+	install -d $(PREFIX)/etc/bash_completion.d
+
+dbus-rhsmd-service-install: dbus-common-install
+	install -m 644 etc-conf/dbus/com.redhat.SubscriptionManager.conf $(PREFIX)/etc/dbus-1/system.d
+	install -m 644 etc-conf/dbus/com.redhat.SubscriptionManager.service $(PREFIX)/$(INSTALL_DIR)/dbus-1/system-services
+	install -m 744 $(DAEMONS_SRC_DIR)/rhsm_d.py $(PREFIX)/$(LIBEXEC_DIR)/rhsmd
+
+dbus-facts-service-install: dbus-common-install
+	install -m 644 etc-conf/dbus/com.redhat.RHSM1.Facts.conf $(PREFIX)/etc/dbus-1/system.d
+	if [ "$(DBUS_SERVICE_FILE_TYPE)" == "systemd" ]; then \
+		install -m 644 etc-conf/dbus/rhsm-facts.service $(SYSTEMD_INST_DIR) ; \
+	fi
+	install -m 644 $(FACTS_SRC_DBUS_SERVICE_FILE) $(FACTS_INST_DBUS_SERVICE_FILE)
+
+dbus-main-service-install: dbus-common-install
+	install -m 644 etc-conf/dbus/com.redhat.RHSM1.conf $(PREFIX)/etc/dbus-1/system.d
+	if [ "$(DBUS_SERVICE_FILE_TYPE)" == "systemd" ]; then \
+		install -m 644 etc-conf/dbus/rhsm.service $(SYSTEMD_INST_DIR) ; \
+	fi
+	install -m 644 $(MAIN_SRC_DBUS_SERVICE_FILE) $(MAIN_INST_DBUS_SERVICE_FILE)
+
+.PHONY: dbus-install
+dbus-install: dbus-facts-service-install dbus-rhsmd-service-install dbus-main-service-install
 
 .PHONY: install-conf
 install-conf:
@@ -150,6 +188,9 @@ install-conf:
 	install -m 644 etc-conf/rhsmcertd.completion.sh $(PREFIX)/etc/bash_completion.d/rhsmcertd
 	install -d $(PREFIX)/usr/share/appdata
 	install -m 644 etc-conf/subscription-manager-gui.appdata.xml $(PREFIX)/$(INSTALL_DIR)/appdata/subscription-manager-gui.appdata.xml
+	install -d $(POLKIT_ACTIONS_INST_DIR)
+	install -m 644 etc-conf/dbus/com.redhat.RHSM1.policy $(POLKIT_ACTIONS_INST_DIR)
+	install -m 644 etc-conf/dbus/com.redhat.RHSM1.Facts.policy $(POLKIT_ACTIONS_INST_DIR)
 
 .PHONY: install-plugins
 install-plugins:
@@ -251,7 +292,7 @@ install-via-setup:
 install: install-via-setup install-files
 
 .PHONY: install-files
-install-files: dbus-service-install install-conf install-plugins install-post-boot install-ga
+install-files: dbus-install install-conf install-plugins install-post-boot install-ga
 	install -d $(PREFIX)/var/log/rhsm
 	install -d $(PREFIX)/var/spool/rhsm/debug
 	install -d $(PREFIX)/var/run/rhsm
@@ -260,7 +301,6 @@ install-files: dbus-service-install install-conf install-plugins install-post-bo
 	# Set up rhsmcertd daemon. If installing on Fedora or RHEL 7+
 	# we prefer systemd over sysv as this is the new trend.
 	if [ $(OS) = Fedora ] ; then \
-		install -d $(SYSTEMD_INST_DIR); \
 		install -d $(PREFIX)/usr/lib/tmpfiles.d; \
 		install etc-conf/rhsmcertd.service $(SYSTEMD_INST_DIR); \
 		install etc-conf/subscription-manager.conf.tmpfiles \
@@ -281,7 +321,6 @@ install-files: dbus-service-install install-conf install-plugins install-post-bo
 			install etc-conf/rhsmcertd.init.d \
 				$(PREFIX)/etc/rc.d/init.d/rhsmcertd; \
 		else \
-			install -d $(SYSTEMD_INST_DIR); \
 			install -d $(PREFIX)/usr/lib/tmpfiles.d; \
 			install etc-conf/rhsmcertd.service $(SYSTEMD_INST_DIR); \
 			install etc-conf/subscription-manager.conf.tmpfiles \
diff --git a/bin/rhsm-facts-service b/bin/rhsm-facts-service
new file mode 100755
index 0000000000..973b3c2ab9
--- /dev/null
+++ b/bin/rhsm-facts-service
@@ -0,0 +1,43 @@
+#! /usr/bin/env python
+#
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import logging
+
+# Init logging very early so we can log any issues that occur at import time
+logging.basicConfig(level=logging.DEBUG, format="%(levelname)5s [%(name)s:%(lineno)s] %(message)s")
+log = logging.getLogger('')
+log.setLevel(logging.INFO)
+
+import sys
+from rhsmlib.dbus import service_wrapper
+from rhsmlib.dbus.facts import base, constants
+
+if __name__ == "__main__":
+    try:
+        object_classes = [
+            base.AllFacts,
+        ]
+        sys.exit(service_wrapper.main(
+            sys.argv,
+            object_classes=object_classes,
+            default_bus_name=constants.FACTS_DBUS_NAME)
+        )
+    except Exception:
+        log.exception("DBus service startup failed")
+else:
+    # Importing this module would screw up the importer's logging configuration since
+    # we're setting up logging very early in module scope to catch any log messages that
+    # occur during the loading of the dependent modules.
+    raise ImportError("This module is not meant to be imported")
diff --git a/bin/rhsm-service b/bin/rhsm-service
new file mode 100755
index 0000000000..06e78091e7
--- /dev/null
+++ b/bin/rhsm-service
@@ -0,0 +1,41 @@
+#!/usr/bin/env python
+#
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import logging
+
+# Init logging very early so we can log any issues that occur at import time
+logging.basicConfig(level=logging.DEBUG, format="%(levelname)5s [%(name)s:%(lineno)s] %(message)s")
+log = logging.getLogger('')
+log.setLevel(logging.INFO)
+
+import sys
+from rhsmlib.dbus import service_wrapper
+from rhsmlib.dbus import objects
+
+if __name__ == "__main__":
+    try:
+        object_classes = [
+            objects.ConfigDBusObject,
+            objects.RegisterDBusObject,
+            objects.Main
+        ]
+        sys.exit(service_wrapper.main(sys.argv, object_classes=object_classes))
+    except Exception:
+        log.exception("DBus service startup failed")
+else:
+    # Importing this module would screw up the importer's logging configuration since
+    # we're setting up logging very early in module scope to catch any log messages that
+    # occur during the loading of the dependent modules.
+    raise ImportError("This module is not meant to be imported")
diff --git a/bin/subscription-manager b/bin/subscription-manager
index 36d76246c9..ca7f98584a 100755
--- a/bin/subscription-manager
+++ b/bin/subscription-manager
@@ -57,6 +57,10 @@ try:
     from subscription_manager.injectioninit import init_dep_injection
     init_dep_injection()
 
+    import subscription_manager.injection as inj
+    # Set up DBus mainloop via DBUS_IFACE
+    inj.require(inj.DBUS_IFACE)
+
     from subscription_manager import managercli
     from subscription_manager.managercli import handle_exception
 
diff --git a/bin/subscription-manager-gui b/bin/subscription-manager-gui
index fdc2d7ffe1..d91771ef5c 100755
--- a/bin/subscription-manager-gui
+++ b/bin/subscription-manager-gui
@@ -133,6 +133,10 @@ try:
     from subscription_manager.injectioninit import init_dep_injection
     init_dep_injection()
 
+    import subscription_manager.injection as inj
+    # Set up DBus mainloop via DBUS_IFACE
+    inj.require(inj.DBUS_IFACE)
+
     from subscription_manager.gui import managergui
     from subscription_manager.i18n_optparse import OptionParser, \
         WrappedIndentedHelpFormatter, USAGE
diff --git a/build_ext/lint.py b/build_ext/lint.py
index 7aac9f3263..df8a373094 100644
--- a/build_ext/lint.py
+++ b/build_ext/lint.py
@@ -12,6 +12,7 @@
 # in this software or its documentation.
 import ast
 import re
+import tokenize
 
 from distutils.spawn import spawn
 from distutils.text_file import TextFile
@@ -21,6 +22,9 @@
 # These dependencies aren't available in build environments.  We won't need any
 # linting functionality there though, so just create a dummy class so we can proceed.
 try:
+    # These dependencies aren't available in build environments.  We won't need any
+    # linting functionality there though, so just create a dummy class so we can proceed.
+    import pep8
     import pkg_resources
 except ImportError:
     pass
@@ -364,6 +368,110 @@ def err(self, node, msg=None):
         return ret
 
 
+def detect_overindent(logical_line, tokens, indent_level, hang_closing, indent_char, noqa, verbose):
+    """Flag lines that are overindented.  This includes lines that are indented solely to align
+    vertically with an opening brace.  This rule allows continuation lines to be relatively
+    indented up to 8 spaces and closes braces to be relatively indented up to 4 spaces.  Heavily
+    adapted from pep8's continued_indentation method
+
+    Okay: foo = my_func('hello',
+              'world'
+              )
+    Okay: foo = my_func('hello',
+                  'world')
+
+    Okay: foo = my_func('hello',
+              )
+
+    E198: foo = my_func('hello',
+                       )
+    E199: foo = my_func('hello',
+                        'world')
+    """
+    first_row = tokens[0][2][0]
+    nrows = 1 + tokens[-1][2][0] - first_row
+    if noqa or nrows == 1:
+        return
+
+    row = depth = 0
+
+    # relative indents of physical lines
+    rel_indent = [0] * nrows
+    open_rows = [[0]]
+    last_indent = tokens[0][2]
+    indent = [last_indent[1]]
+
+    last_token_multiline = False
+
+    if verbose >= 3:
+        print(">>> " + tokens[0][4].rstrip())
+
+    for token_type, text, start, end, line in tokens:
+        newline = row < start[0] - first_row
+        if newline:
+            row = start[0] - first_row
+            newline = not last_token_multiline and token_type not in pep8.NEWLINE
+
+        if newline:
+            # this is the beginning of a continuation line.
+            last_indent = start
+            if verbose >= 3:
+                print("... " + line.rstrip())
+
+            # record the initial indent.
+            rel_indent[row] = pep8.expand_indent(line) - indent_level
+
+            # identify closing bracket
+            close_bracket = (token_type == tokenize.OP and text in ']})')
+
+            # is the indent relative to an opening bracket line?
+            for open_row in reversed(open_rows[depth]):
+                hang = rel_indent[row] - rel_indent[open_row]
+
+            if not close_bracket and hang > 8:
+                yield start, "E199 continuation line over-indented"
+
+            if close_bracket and hang > 4:
+                yield (start, "E198 closing bracket over-indented")
+
+        # Keep track of bracket depth to check for proper indentation in nested
+        # brackets
+        # E.g.
+        # Okay: foo = [[
+        #           '1'
+        #       ]]
+        #
+        # but even though we are nested twice, we should only allow one level of indentation, so:
+        #
+        # E199: foo = [[
+        #               '1'
+        #       ]]
+
+        if token_type == tokenize.OP:
+            if text in '([{':
+                depth += 1
+                indent.append(0)
+                if len(open_rows) == depth:
+                    open_rows.append([])
+                open_rows[depth].append(row)
+                if verbose >= 4:
+                    print("bracket depth %s seen, col %s, visual min = %s" %
+                          (depth, start[1], indent[depth]))
+            elif text in ')]}' and depth > 0:
+                # parent indents should not be more than this one
+                prev_indent = indent.pop() or last_indent[1]
+                for d in range(depth):
+                    if indent[d] > prev_indent:
+                        indent[d] = 0
+                del open_rows[depth + 1:]
+                depth -= 1
+            assert len(indent) == depth + 1
+
+        last_token_multiline = (start[0] != end[0])
+        if last_token_multiline:
+            rel_indent[end[0] - first_row] = rel_indent[row]
+
+
 class PluginLoadingFlake8(Flake8):
     """A Flake8 runner that will load our custom plugins.  It's important to note
     that this has to be invoked via `./setup.py flake8`.  Just running `flake8` won't
diff --git a/dev-requirements.txt b/dev-requirements.txt
index f500d32fd1..bba0269a7b 100644
--- a/dev-requirements.txt
+++ b/dev-requirements.txt
@@ -1,3 +1,3 @@
+-r test-requirements.txt
 yanc
-nose-randomly
 xtraceback
diff --git a/etc-conf/dbus/com.redhat.RHSM1.Facts.conf b/etc-conf/dbus/com.redhat.RHSM1.Facts.conf
new file mode 100644
index 0000000000..2a4ec8fd8d
--- /dev/null
+++ b/etc-conf/dbus/com.redhat.RHSM1.Facts.conf
@@ -0,0 +1,37 @@
+<?xml version="1.0" encoding="UTF-8"?> <!-- -*- XML -*- -->
+
+<!DOCTYPE busconfig PUBLIC
+ "-//freedesktop//DTD D-BUS Bus Configuration 1.0//EN"
+ "http://www.freedesktop.org/standards/dbus/1.0/busconfig.dtd">
+<busconfig>
+
+    <policy user="root">
+        <allow own="com.redhat.RHSM1.Facts"/>
+
+        <!-- Basic D-Bus API stuff -->
+        <allow send_destination="com.redhat.RHSM1.Facts"
+            send_interface="org.freedesktop.DBus.Introspectable"/>
+        <allow send_destination="com.redhat.RHSM1.Facts"
+            send_interface="org.freedesktop.DBus.Properties"/>
+        <allow send_destination="com.redhat.RHSM1.Facts"
+            send_interface="org.freedesktop.DBus.ObjectManager"/>
+    </policy>
+
+
+    <policy context="default">
+        <!-- TODO: make these read-only by default -->
+
+        <allow send_destination="com.redhat.RHSM1.Facts"
+          send_interface="com.redhat.RHSM1.Facts"/>
+
+      <!-- Basic D-Bus API stuff -->
+      <allow send_destination="com.redhat.RHSM1.Facts"
+          send_interface="org.freedesktop.DBus.Introspectable"/>
+      <allow send_destination="com.redhat.RHSM1.Facts"
+          send_interface="org.freedesktop.DBus.Properties"/>
+      <allow send_destination="com.redhat.RHSM1.Facts"
+          send_interface="org.freedesktop.DBus.ObjectManager"/>
+  </policy>
+
+</busconfig>
+
diff --git a/etc-conf/dbus/com.redhat.RHSM1.Facts.policy b/etc-conf/dbus/com.redhat.RHSM1.Facts.policy
new file mode 100644
index 0000000000..9618c7e72c
--- /dev/null
+++ b/etc-conf/dbus/com.redhat.RHSM1.Facts.policy
@@ -0,0 +1,29 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!DOCTYPE policyconfig PUBLIC
+ "-//freedesktop//DTD PolicyKit Policy Configuration 1.0//EN"
+ "http://www.freedesktop.org/standards/PolicyKit/1/policyconfig.dtd">
+<policyconfig>
+  <vendor>Red Hat Subscription Management Facts</vendor>
+  <vendor_url>http://redhat.com</vendor_url>
+
+  <action id="com.redhat.RHSM1.Facts.default">
+    <description>RHSM default</description>
+    <message>System policy prevents access to com.redhat.RHSM1.Facts</message>
+    <defaults>
+        <allow_any>yes</allow_any>
+        <allow_inactive>yes</allow_inactive>
+        <allow_active>yes</allow_active>
+
+    </defaults>
+  </action>
+
+   <action id="com.redhat.RHSM1.Facts.collect">
+    <description>RHSM Facts collection</description>
+    <message>System policy prevents collect action to admin Facts service</message>
+    <defaults>
+        <allow_any>yes</allow_any>
+        <allow_inactive>yes</allow_inactive>
+        <allow_active>yes</allow_active>
+    </defaults>
+  </action>
+</policyconfig>
diff --git a/etc-conf/dbus/com.redhat.RHSM1.Facts.service b/etc-conf/dbus/com.redhat.RHSM1.Facts.service
new file mode 100644
index 0000000000..3bc8f8f563
--- /dev/null
+++ b/etc-conf/dbus/com.redhat.RHSM1.Facts.service
@@ -0,0 +1,5 @@
+[D-BUS Service]
+Name=com.redhat.RHSM1.Facts
+Exec=/usr/libexec/rhsm-facts-service
+User=root
+SystemdService=rhsm-facts.service
diff --git a/etc-conf/dbus/com.redhat.RHSM1.Facts.service-dbus b/etc-conf/dbus/com.redhat.RHSM1.Facts.service-dbus
new file mode 100644
index 0000000000..d999b060cb
--- /dev/null
+++ b/etc-conf/dbus/com.redhat.RHSM1.Facts.service-dbus
@@ -0,0 +1,4 @@
+[D-BUS Service]
+Name=com.redhat.RHSM1.Facts
+Exec=/usr/libexec/rhsm-facts-service
+User=root
diff --git a/etc-conf/dbus/com.redhat.RHSM1.conf b/etc-conf/dbus/com.redhat.RHSM1.conf
new file mode 100644
index 0000000000..939208ce32
--- /dev/null
+++ b/etc-conf/dbus/com.redhat.RHSM1.conf
@@ -0,0 +1,35 @@
+<?xml version="1.0" encoding="UTF-8"?> <!-- -*- XML -*- -->
+
+<!DOCTYPE busconfig PUBLIC
+ "-//freedesktop//DTD D-BUS Bus Configuration 1.0//EN"
+ "http://www.freedesktop.org/standards/dbus/1.0/busconfig.dtd">
+<busconfig>
+    <policy user="root">
+        <allow own="com.redhat.RHSM1"/>
+
+        <!-- Basic D-Bus API stuff -->
+        <allow send_destination="com.redhat.RHSM1"
+            send_interface="org.freedesktop.DBus.Introspectable"/>
+        <allow send_destination="com.redhat.RHSM1"
+            send_interface="org.freedesktop.DBus.Properties"/>
+        <allow send_destination="com.redhat.RHSM1"
+            send_interface="org.freedesktop.DBus.ObjectManager"/>
+    </policy>
+
+
+    <policy context="default">
+        <!-- TODO: make these read-only by default -->
+
+        <allow send_destination="com.redhat.RHSM1"
+            send_interface="com.redhat.RHSM1"/>
+
+        <!-- Basic D-Bus API stuff -->
+        <allow send_destination="com.redhat.RHSM1"
+            send_interface="org.freedesktop.DBus.Introspectable"/>
+        <allow send_destination="com.redhat.RHSM1"
+            send_interface="org.freedesktop.DBus.Properties"/>
+        <allow send_destination="com.redhat.RHSM1"
+            send_interface="org.freedesktop.DBus.ObjectManager"/>
+    </policy>
+</busconfig>
+
diff --git a/etc-conf/dbus/com.redhat.RHSM1.policy b/etc-conf/dbus/com.redhat.RHSM1.policy
new file mode 100644
index 0000000000..8d0407d4a8
--- /dev/null
+++ b/etc-conf/dbus/com.redhat.RHSM1.policy
@@ -0,0 +1,18 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!DOCTYPE policyconfig PUBLIC
+ "-//freedesktop//DTD PolicyKit Policy Configuration 1.0//EN"
+ "http://www.freedesktop.org/standards/PolicyKit/1/policyconfig.dtd">
+<policyconfig>
+  <vendor>Red Hat Subscription Management</vendor>
+  <vendor_url>http://redhat.com</vendor_url>
+
+  <action id="com.redhat.RHSM1.default">
+    <description>RHSM default</description>
+    <message>System policy prevents access to com.redhat.RHSM1</message>
+    <defaults>
+        <allow_any>yes</allow_any>
+        <allow_inactive>yes</allow_inactive>
+        <allow_active>yes</allow_active>
+    </defaults>
+  </action>
+</policyconfig>
diff --git a/etc-conf/dbus/com.redhat.RHSM1.service b/etc-conf/dbus/com.redhat.RHSM1.service
new file mode 100644
index 0000000000..66fa4477f7
--- /dev/null
+++ b/etc-conf/dbus/com.redhat.RHSM1.service
@@ -0,0 +1,5 @@
+[D-BUS Service]
+Name=com.redhat.RHSM1
+Exec=/usr/libexec/rhsm-service
+User=root
+SystemdService=rhsm.service
diff --git a/etc-conf/dbus/com.redhat.RHSM1.service-dbus b/etc-conf/dbus/com.redhat.RHSM1.service-dbus
new file mode 100644
index 0000000000..e406c7305a
--- /dev/null
+++ b/etc-conf/dbus/com.redhat.RHSM1.service-dbus
@@ -0,0 +1,4 @@
+[D-BUS Service]
+Name=com.redhat.RHSM1
+Exec=/usr/libexec/rhsm-service
+User=root
diff --git a/etc-conf/com.redhat.SubscriptionManager.conf b/etc-conf/dbus/com.redhat.SubscriptionManager.conf
similarity index 100%
rename from etc-conf/com.redhat.SubscriptionManager.conf
rename to etc-conf/dbus/com.redhat.SubscriptionManager.conf
diff --git a/etc-conf/com.redhat.SubscriptionManager.service b/etc-conf/dbus/com.redhat.SubscriptionManager.service
similarity index 100%
rename from etc-conf/com.redhat.SubscriptionManager.service
rename to etc-conf/dbus/com.redhat.SubscriptionManager.service
diff --git a/etc-conf/dbus/rhsm-facts.service b/etc-conf/dbus/rhsm-facts.service
new file mode 100644
index 0000000000..0467c00e12
--- /dev/null
+++ b/etc-conf/dbus/rhsm-facts.service
@@ -0,0 +1,11 @@
+[Unit]
+Description=RHSM system Facts dbus service
+After=syslog.target network.target
+
+[Service]
+Type=dbus
+BusName=com.redhat.Subscriptions1.Facts
+ExecStart=/usr/libexec/rhsm-facts-service
+
+[Install]
+WantedBy=basic.target
diff --git a/etc-conf/dbus/rhsm.service b/etc-conf/dbus/rhsm.service
new file mode 100644
index 0000000000..d35cb46e63
--- /dev/null
+++ b/etc-conf/dbus/rhsm.service
@@ -0,0 +1,11 @@
+[Unit]
+Description=RHSM dbus service
+After=syslog.target network.target
+
+[Service]
+Type=dbus
+BusName=com.redhat.RHSM1
+ExecStart=/usr/libexec/rhsm-service
+
+[Install]
+WantedBy=basic.target
diff --git a/requirements.txt b/requirements.txt
index 5a4afa087f..8ca6eb28e6 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -1,3 +1,4 @@
 # note there are also rpm packaged deps that aren't
 # setup in pypi or with setup.py
 git+https://github.com/candlepin/python-rhsm.git
+decorator
diff --git a/scripts/dbus-show.sh b/scripts/dbus-show.sh
new file mode 100755
index 0000000000..36bd07cf73
--- /dev/null
+++ b/scripts/dbus-show.sh
@@ -0,0 +1,61 @@
+#!/bin/bash
+
+# For a given bus/service name, find all of it's object paths
+# and show introspection data for each.
+# Uses 'busctl' cli for the heavy work.
+#
+# If a service name isn't specified, default to all the
+# well known names that have been acquired. This potentially
+# doesn't include apps that only use a unique name, or services
+# that need to be activated.
+#
+# Example usage:
+# $ dbus-show org.storaged.Storaged
+
+BUS=${BUS:-"system"}
+
+
+if [ -n "${1}" ]
+then
+    SERVICENAMES=( "$@" )
+else
+    SERVICENAMES=( $(busctl --no-legend "--${BUS}" --acquired | awk -e '{print $1}') )
+fi
+
+
+for service_name in "${SERVICENAMES[@]}"
+do
+
+    dbus_paths=$(busctl "--${BUS}" tree  --list "${service_name}")
+    tree_exit_code="$?"
+
+    if [ "${tree_exit_code}" -eq "1" ]
+    then
+        printf "Service name %s not found on this bus." "${service_name}"
+        continue
+    fi
+
+    printf "service name: %s" "${service_name}"
+    for dbus_path in ${dbus_paths}
+    do
+        declare -a intro_data
+        printf "  object path: %s\n" "${dbus_path}"
+
+        # pull the intro_data into an array, one line per array entry (split on newline via readarray -t)
+        # So that we can indent it slightly for purely cosmetic reasons.
+        intro_data_raw=$(busctl "--${BUS}" "introspect" "--no-legend" "${service_name}" "${dbus_path}")
+        readarray -t intro_data <<<"${intro_data_raw}"
+
+        if [ -n "${intro_data}" ]
+        then
+            for intro_data_line in "${intro_data[@]}"
+            do
+                printf "    %s\n" "${intro_data_line}"
+            done
+            echo
+        fi
+
+    done
+    echo
+done
+
diff --git a/scripts/rhsm-register-service b/scripts/rhsm-register-service
new file mode 100755
index 0000000000..32176ff1d3
--- /dev/null
+++ b/scripts/rhsm-register-service
@@ -0,0 +1,42 @@
+#!/usr/bin/env python
+#
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import logging
+
+# Init logging very early so we can log any issues that occur at import time
+logging.basicConfig(level=logging.DEBUG, format="%(levelname)5s [%(name)s:%(lineno)s] %(message)s")
+log = logging.getLogger('')
+log.setLevel(logging.INFO)
+
+import sys
+import warnings
+
+from rhsmlib.dbus import service_wrapper
+from rhsmlib.dbus import objects
+
+if __name__ == "__main__":
+    try:
+        warnings.warn("This script should only be used for testing purposes. It is not secure.")
+        object_classes = [
+            objects.DomainSocketRegisterDBusObject
+        ]
+        sys.exit(service_wrapper.main(sys.argv, object_classes=object_classes))
+    except Exception:
+        log.exception("DBus service startup failed")
+else:
+    # Importing this module would screw up the importer's logging configuration since
+    # we're setting up logging very early in module scope to catch any log messages that
+    # occur during the loading of the dependent modules.
+    raise ImportError("This module is not meant to be imported")
diff --git a/scripts/smoke_dbus.sh b/scripts/smoke_dbus.sh
new file mode 100755
index 0000000000..0df8064737
--- /dev/null
+++ b/scripts/smoke_dbus.sh
@@ -0,0 +1,46 @@
+#!/bin/bash
+
+FACTS="com.redhat.Subscriptions1.Facts"
+FACTS_PATH="/com/redhat/Subscriptions1/Facts/Host"
+FACTS_INTF="com.redhat.Subscriptions1.Facts"
+PROPS_INTF="org.freedesktop.DBus.Properties"
+INTRO_INTF="org.freedesktop.DBus.Introspectable"
+
+busctl | grep 'rhsm'
+busctl status "${FACTS}"
+
+pkaction | grep 'Subscriptions1'
+
+busctl tree "${FACTS}"
+SERVICE="${FACTS}"
+OBJECT_PATH="${FACTS_PATH}"
+
+# yes, it is using global variables and args
+dbus_call () {
+    local the_rest=$*
+
+    local CALL_ARGS="${SERVICE} ${OBJECT_PATH} ${INTF}"
+
+    busctl call ${CALL_ARGS} ${the_rest}
+}
+
+per_fact_object () {
+    OBJECT_PATH="${1}"
+        
+    busctl introspect "${SERVICE}" "${OBJECT_PATH}"
+    
+    INTF="${PROPS_INTF}"
+    dbus_call GetAll s "${FACTS_INTF}"
+    dbus_call Get ss "${FACTS_INTF}" "version"
+    dbus_call Get ss "${FACTS_INTF}" "some_prop_that_doesnt_exist"
+
+    INTF="${FACTS_INTF}"
+    dbus_call GetFacts
+
+    INTF="${INTRO_INTF}"
+    dbus_call Introspect
+}
+
+per_fact_object "${FACTS_PATH}"
+
+#CALL_ARGS="${SERVICE} ${OBJECT_PATH} ${INTF}"
diff --git a/setup.cfg b/setup.cfg
index 86dd62a3fb..afe65dd2bd 100644
--- a/setup.cfg
+++ b/setup.cfg
@@ -2,6 +2,7 @@
 [nosetests]
 with-xvfb=True
 with-randomly=True
+cover-html=True
 # exclude tests with names that match regex .*ga_impls.*
 # Even though there are no tests with that name, but nose tries
 # to load modules that would have that name, and seems to ignore 'ignore-files'
diff --git a/setup.py b/setup.py
index ec837805d6..7e89deb036 100755
--- a/setup.py
+++ b/setup.py
@@ -274,7 +274,7 @@ def add_icons(self):
     author="Adrian Likins",
     author_email="alikins@redhat.com",
     cmdclass=cmdclass,
-    packages=find_packages('src', exclude=['subscription_manager.gui.firstboot.*', '*.ga_impls', '*.ga_impls.*', '*.plugin.ostree']),
+    packages=find_packages('src', exclude=['subscription_manager.gui.firstboot.*', '*.ga_impls', '*.ga_impls.*', '*.plugin.ostree', '*.services.examples']),
     package_dir={'': 'src'},
     package_data={
         'subscription_manager.gui': ['data/glade/*.glade', 'data/ui/*.ui', 'data/icons/*.svg'],
@@ -282,7 +282,7 @@ def add_icons(self):
     data_files=[
         ('sbin', ['bin/subscription-manager', 'bin/subscription-manager-gui', 'bin/rhn-migrate-classic-to-rhsm']),
         ('bin', ['bin/rct', 'bin/rhsm-debug']),
-        (libexecdir, ['src/daemons/rhsmcertd-worker.py']),
+        (libexecdir, ['src/daemons/rhsmcertd-worker.py', 'bin/rhsm-facts-service', 'bin/rhsm-service']),
         # sat5to6 is packaged separately
         ('share/man/man8', set(glob('man/*.8')) - set(['man/sat5to6.8'])),
         ('share/man/man5', glob('man/*.5')),
diff --git a/src/__init__.py b/src/__init__.py
new file mode 100644
index 0000000000..e69de29bb2
diff --git a/src/daemons/rhsm_d.py b/src/daemons/rhsm_d.py
index 69c5623ed3..f5bb852e1b 100755
--- a/src/daemons/rhsm_d.py
+++ b/src/daemons/rhsm_d.py
@@ -78,8 +78,10 @@ def excepthook_logging(exc_type, exc_value, exc_traceback):
         RHN_CLASSIC, RHSM_REGISTRATION_REQUIRED
 from subscription_manager.utils import print_error
 
-import rhsm.config
-CFG = rhsm.config.initConfig()
+from rhsm.config import initConfig
+from rhsmlib.services import config
+
+conf = config.Config(initConfig())
 
 enable_debug = False
 
diff --git a/src/dnf-plugins/product-id.py b/src/dnf-plugins/product-id.py
index d5d996eda1..3b9f605d48 100644
--- a/src/dnf-plugins/product-id.py
+++ b/src/dnf-plugins/product-id.py
@@ -95,7 +95,7 @@ def get_enabled(self):
                     # We have to look in all repos for productids, not just
                     # the ones we create, or anaconda doesn't install it.
                     self.meta_data_errors.append(repo.id)
-            except Exception, e:
+            except Exception as e:
                 log.warn("Error loading productid metadata for %s." % repo)
                 log.exception(e)
                 self.meta_data_errors.append(repo.id)
diff --git a/src/initial-setup/com_redhat_subscription_manager/gui/spokes/rhsm_gui.py b/src/initial-setup/com_redhat_subscription_manager/gui/spokes/rhsm_gui.py
index 72a5239d1c..255dfa0c1a 100644
--- a/src/initial-setup/com_redhat_subscription_manager/gui/spokes/rhsm_gui.py
+++ b/src/initial-setup/com_redhat_subscription_manager/gui/spokes/rhsm_gui.py
@@ -35,7 +35,6 @@
 from subscription_manager.ga import Gtk as ga_Gtk
 from subscription_manager.gui import managergui
 from subscription_manager.injectioninit import init_dep_injection
-from subscription_manager import injection as inj
 from subscription_manager.gui import registergui
 from subscription_manager import utils
 from subscription_manager.gui import utils as gui_utils
@@ -65,16 +64,16 @@ def initialize(self):
 
         init_dep_injection()
 
-        facts = inj.require(inj.FACTS)
-
         backend = managergui.Backend()
         self.info = registergui.RegisterInfo()
         self.info.connect('notify::register-status', self._on_register_status_change)
         self._status = self.info.get_property('register-status')
 
-        self.register_widget = registergui.RegisterWidget(backend, facts,
-                                                          reg_info=self.info,
-                                                          parent_window=self.main_window)
+        self.register_widget = registergui.RegisterWidget(
+            backend,
+            reg_info=self.info,
+            parent_window=self.main_window
+        )
 
         self.register_box = self.builder.get_object("register_box")
         self.button_box = self.builder.get_object('navigation_button_box')
diff --git a/src/plugins/product-id.py b/src/plugins/product-id.py
index cdc1a5c530..5e7f3c4488 100644
--- a/src/plugins/product-id.py
+++ b/src/plugins/product-id.py
@@ -41,7 +41,7 @@ def posttrans_hook(conduit):
 
     try:
         init_dep_injection()
-    except ImportError, e:
+    except ImportError as e:
         conduit.error(3, str(e))
         return
 
@@ -53,7 +53,7 @@ def posttrans_hook(conduit):
         pm = YumProductManager(conduit._base)
         pm.update_all()
         conduit.info(3, 'Installed products updated.')
-    except Exception, e:
+    except Exception as e:
         conduit.error(3, str(e))
 
 
@@ -80,11 +80,11 @@ def get_enabled(self):
                 if cert is None:
                     continue
                 lst.append((cert, repo.id))
-            except yum.Errors.RepoMDError, e:
+            except yum.Errors.RepoMDError as e:
                 # We have to look in all repos for productids, not just
                 # the ones we create, or anaconda doesn't install it.
                 self.meta_data_errors.append(repo.id)
-            except Exception, e:
+            except Exception as e:
                 log.warn("Error loading productid metadata for %s." % repo)
                 log.exception(e)
                 self.meta_data_errors.append(repo.id)
diff --git a/src/plugins/subscription-manager.py b/src/plugins/subscription-manager.py
index 35cd9b6960..9a069cdff2 100644
--- a/src/plugins/subscription-manager.py
+++ b/src/plugins/subscription-manager.py
@@ -97,7 +97,7 @@ def update(conduit, cache_only):
     if identity.is_valid():
         try:
             connection.UEPConnection(cert_file=cert_file, key_file=key_file)
-        #FIXME: catchall exception
+        # FIXME: catchall exception
         except Exception:
             # log
             conduit.info(2, "Unable to connect to Subscription Management Service")
@@ -174,5 +174,5 @@ def postconfig_hook(conduit):
         update(conduit, cache_only)
         warnOrGiveUsageMessage(conduit)
         warnExpired(conduit)
-    except Exception, e:
+    except Exception as e:
         conduit.error(2, str(e))
diff --git a/src/rhsm_debug/debug_commands.py b/src/rhsm_debug/debug_commands.py
index f10f5fb4eb..3fca1842b2 100644
--- a/src/rhsm_debug/debug_commands.py
+++ b/src/rhsm_debug/debug_commands.py
@@ -30,10 +30,11 @@
 from subscription_manager.cli import InvalidCLIOptionError, system_exit
 from rhsm import ourjson as json
 from rhsm.config import initConfig
+from rhsmlib.services import config
 
 _ = gettext.gettext
 
-cfg = initConfig()
+conf = config.Config(initConfig())
 
 log = logging.getLogger('rhsm-app.' + __name__)
 
@@ -134,7 +135,7 @@ def _do_command(self):
 
             # FIXME: we need to anon proxy passwords?
             sos = self.options.sos
-            defaults = cfg.defaults()
+            defaults = conf.defaults()
             # sosreport collects /etc/rhsm/* and /var/*/rhsm/*, so these would
             # be redundant for sos
             if not sos:
@@ -146,28 +147,28 @@ def _do_command(self):
             if not sos:
                 self._copy_cert_directory('/etc/pki/product-default', content_path)
 
-            if defaults['productcertdir'] != cfg.get('rhsm', 'productCertDir') or not sos:
-                self._copy_cert_directory(cfg.get('rhsm', 'productCertDir'), content_path)
+            if defaults['productcertdir'] != conf['rhsm']['productCertDir'] or not sos:
+                self._copy_cert_directory(conf['rhsm']['productCertDir'], content_path)
 
-            if defaults['entitlementcertdir'] != cfg.get('rhsm', 'entitlementCertDir') or not sos:
-                self._copy_cert_directory(cfg.get('rhsm', 'entitlementCertDir'), content_path)
+            if defaults['entitlementcertdir'] != conf['rhsm']['entitlementCertDir'] or not sos:
+                self._copy_cert_directory(conf['rhsm']['entitlementCertDir'], content_path)
 
-            if defaults['consumercertdir'] != cfg.get('rhsm', 'consumerCertDir') or not sos:
-                self._copy_cert_directory(cfg.get('rhsm', 'consumerCertDir'), content_path)
+            if defaults['consumercertdir'] != conf['rhsm']['consumerCertDir'] or not sos:
+                self._copy_cert_directory(conf['rhsm']['consumerCertDir'], content_path)
 
             # If ca_cert_dir and pluginconfdif are configured as subdirs of /etc/rhsm
             # (as is the default) we will have already copied there contents,
             # so ignore directory exists errors
             try:
-                if defaults['ca_cert_dir'] != cfg.get('rhsm', 'ca_cert_dir') or not sos:
-                    self._copy_cert_directory(cfg.get('rhsm', 'ca_cert_dir'), content_path)
+                if defaults['ca_cert_dir'] != conf['rhsm']['ca_cert_dir'] or not sos:
+                    self._copy_cert_directory(conf['rhsm']['ca_cert_dir'], content_path)
             except EnvironmentError, e:
                 if e.errno != errno.EEXIST:
                     raise
 
             try:
-                if defaults['pluginconfdir'] != cfg.get('rhsm', 'pluginconfdir') or not sos:
-                    self._copy_directory(cfg.get('rhsm', 'pluginconfdir'), content_path)
+                if defaults['pluginconfdir'] != conf['rhsm']['pluginconfdir'] or not sos:
+                    self._copy_directory(conf['rhsm']['pluginconfdir'], content_path)
             except EnvironmentError, e:
                 if e.errno != errno.EEXIST:
                     raise
diff --git a/src/rhsmlib/__init__.py b/src/rhsmlib/__init__.py
new file mode 100644
index 0000000000..9886933057
--- /dev/null
+++ b/src/rhsmlib/__init__.py
@@ -0,0 +1,27 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+import imp
+
+
+def import_class(name):
+    """Load a class from a string.  Thanks http://stackoverflow.com/a/547867/61248 """
+    components = name.split('.')
+    current_level = components[0]
+    module_tuple = imp.find_module(current_level)
+    module = imp.load_module(current_level, *module_tuple)
+    for comp in components[1:-1]:
+        # import all the way down to the class
+        module_tuple = imp.find_module(comp, module.__path__)
+        module = imp.load_module(comp, *module_tuple)
+    # the class will be an attribute on the lowest level module
+    return getattr(module, components[-1])
diff --git a/src/rhsmlib/candlepin/__init__.py b/src/rhsmlib/candlepin/__init__.py
new file mode 100644
index 0000000000..e69de29bb2
diff --git a/src/rhsmlib/candlepin/api.py b/src/rhsmlib/candlepin/api.py
new file mode 100644
index 0000000000..fa7535084a
--- /dev/null
+++ b/src/rhsmlib/candlepin/api.py
@@ -0,0 +1,116 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import logging
+import socket
+from M2Crypto import SSL
+
+import rhsm.connection
+
+log = logging.getLogger(__name__)
+
+
+# Likely needs to subclass RestlibException etc
+class CandlepinApiError(Exception):
+    pass
+
+
+class CandlepinApiSSLError(CandlepinApiError):
+    pass
+
+
+class CandlepinApiRestlibError(CandlepinApiError):
+    pass
+
+
+class CandlepinApiAuthenticationError(CandlepinApiError):
+    pass
+
+
+class CandlepinApiExpiredIDCertError(CandlepinApiError):
+    pass
+
+
+class CandlepinApiNetworkError(CandlepinApiError):
+    pass
+
+
+class Candlepin(object):
+    def __init__(self, uep):
+        self.uep = uep
+        self._default_args = ()
+        self.last_error = None
+
+    @property
+    def default_args(self):
+        # could include the default success/error callbacks
+        return self._default_args
+
+    @property
+    def default_kwargs(self):
+        return self._default_kwargs
+
+    def call(self, rest_method, *args, **kwargs):
+        success_callback = kwargs.get('success_callback', None)
+        error_callback = kwargs.get('error_callback', None)
+
+        log.debug('success_cb=%s', success_callback)
+        log.debug('error_callback=%s', error_callback)
+        log.debug('rest_method=%s %s', rest_method, type(rest_method))
+
+        try:
+            args = self.default_args + args
+            return rest_method(*args, **kwargs)
+        except AttributeError as e:
+            log.exception(e)
+            raise
+        except SSL.SSLError as ex:
+            log.exception(ex)
+            self.last_error = ex
+            log.error("Consumer certificate is invalid")
+            raise CandlepinApiSSLError('SSL related error (consumer identity cert is invalid?): %s' % ex)
+        except rhsm.connection.RestlibException as ex:
+            # Indicates we may be talking to a very old candlepin server
+            # which does not have the necessary API call.
+            log.exception(ex)
+            self.last_error = ex
+            raise CandlepinApiRestlibError('Error from candlepin: %s' % ex)
+        except rhsm.connection.AuthenticationException as ex:
+            log.error("Could not authenticate with server. Check registration status.")
+            log.exception(ex)
+            self.last_error = ex
+            raise CandlepinApiAuthenticationError("Could not authenticate with server. "
+                  "Check registration status.: %s" % ex)
+        except rhsm.connection.ExpiredIdentityCertException as ex:
+            log.exception(ex)
+            self.last_error = ex
+            msg = "Bad identity, unable to connect to server"
+            raise CandlepinApiExpiredIDCertError("%s: %s" % (msg, ex))
+        except rhsm.connection.GoneException:
+            raise
+        # Most of the above are subclasses of ConnectionException that
+        # get handled first
+        except (rhsm.connection.ConnectionException, socket.error) as ex:
+            log.error(ex)
+            self.last_error = ex
+
+            msg = "Unable to reach server."
+            log.warn(msg)
+            raise CandlepinApiNetworkError('%s: %s' % (msg, ex))
+
+
+class CandlepinConsumer(Candlepin):
+    def __init__(self, uep, uuid):
+        self.uep = uep
+        self.uuid = uuid
+        self._default_args = (self.uuid,)
diff --git a/src/rhsmlib/compat/__init__.py b/src/rhsmlib/compat/__init__.py
new file mode 100644
index 0000000000..39becd97a1
--- /dev/null
+++ b/src/rhsmlib/compat/__init__.py
@@ -0,0 +1 @@
+from rhsmlib.compat.subprocess_compat import check_output  # NOQA
diff --git a/src/rhsmlib/compat/subprocess_compat.py b/src/rhsmlib/compat/subprocess_compat.py
new file mode 100644
index 0000000000..55bd111d0e
--- /dev/null
+++ b/src/rhsmlib/compat/subprocess_compat.py
@@ -0,0 +1,43 @@
+# Copyright (c) 2010-2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+#
+# Compat module that implements a subprocess.check_output work-a-like for
+# python 2.6.
+
+import logging
+import subprocess
+
+log = logging.getLogger(__name__)
+
+
+def check_output_2_6(*args, **kwargs):
+    cmd_args = kwargs.get('args', None) or args[0]
+
+    log.debug("Running '%s'" % cmd_args)
+
+    process = subprocess.Popen(*args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, **kwargs)
+    (std_output, std_error) = process.communicate()
+
+    output = std_output.strip()
+
+    returncode = process.poll()
+    if returncode:
+        raise subprocess.CalledProcessError(returncode, cmd_args)
+
+    return output
+
+check_output = check_output_2_6
+
+if hasattr(subprocess, 'check_output'):
+    check_output = subprocess.check_output
diff --git a/src/rhsmlib/dbus/__init__.py b/src/rhsmlib/dbus/__init__.py
new file mode 100644
index 0000000000..c7a4208aec
--- /dev/null
+++ b/src/rhsmlib/dbus/__init__.py
@@ -0,0 +1,3 @@
+from rhsmlib.dbus.constants import *  # NOQA
+from rhsmlib.dbus.exceptions import *  # NOQA
+from rhsmlib.dbus.util import *  # NOQA
diff --git a/src/rhsmlib/dbus/base_object.py b/src/rhsmlib/dbus/base_object.py
new file mode 100644
index 0000000000..709b6359e7
--- /dev/null
+++ b/src/rhsmlib/dbus/base_object.py
@@ -0,0 +1,35 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+
+import logging
+import dbus.service
+
+from rhsmlib.dbus import constants, exceptions
+
+log = logging.getLogger(__name__)
+
+
+class BaseObject(dbus.service.Object):
+    # Name of the DBus interface provided by this object
+    interface_name = constants.INTERFACE_BASE
+    default_dbus_path = constants.ROOT_DBUS_PATH
+
+    def __init__(self, conn=None, object_path=None, bus_name=None):
+        if object_path is None:
+            object_path = self.default_dbus_path
+        super(BaseObject, self).__init__(conn=conn, object_path=object_path, bus_name=bus_name)
+
+    def _check_interface(self, interface_name):
+        if interface_name != self.interface_name:
+            raise exceptions.UnknownInterface(interface_name)
diff --git a/src/rhsmlib/dbus/constants.py b/src/rhsmlib/dbus/constants.py
new file mode 100644
index 0000000000..c0b81ba06a
--- /dev/null
+++ b/src/rhsmlib/dbus/constants.py
@@ -0,0 +1,56 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+import string
+
+__all__ = [
+    'NAME_BASE',
+    'VERSION',
+    'BUS_NAME',
+    'INTERFACE_BASE',
+    'ROOT_DBUS_PATH',
+    'MAIN_INTERFACE',
+    'MAIN_DBUS_PATH',
+    'REGISTER_INTERFACE',
+    'REGISTER_DBUS_PATH',
+    'CONFIG_INTERFACE',
+    'CONFIG_DBUS_PATH',
+]
+
+# The base of the 'well known name' used for bus and service names, as well
+# as interface names and object paths.
+#
+# "com.redhat.RHSM1"
+NAME_BASE = "com.redhat.RHSM"
+VERSION = "1"
+BUS_NAME = NAME_BASE + VERSION
+
+# The default interface name for objects we share on this service.
+INTERFACE_BASE = BUS_NAME
+
+# The root of the objectpath tree for our services.
+# Note: No trailing '/'
+#
+# /com/redhat/RHSM1
+ROOT_DBUS_PATH = '/' + string.replace(BUS_NAME, '.', '/')
+
+MAIN_INTERFACE = INTERFACE_BASE
+MAIN_DBUS_PATH = ROOT_DBUS_PATH
+
+REGISTER_INTERFACE = '%s.%s' % (INTERFACE_BASE, 'RegisterServer')
+REGISTER_DBUS_PATH = '%s/%s' % (ROOT_DBUS_PATH, 'RegisterServer')
+
+PRIVATE_REGISTER_INTERFACE = '%s.%s' % (INTERFACE_BASE, 'Register')
+PRIVATE_REGISTER_DBUS_PATH = '%s/%s' % (ROOT_DBUS_PATH, 'Register')
+
+CONFIG_INTERFACE = '%s.%s' % (INTERFACE_BASE, 'Config')
+CONFIG_DBUS_PATH = '%s/%s' % (ROOT_DBUS_PATH, 'Config')
diff --git a/src/rhsmlib/dbus/dbus_utils.py b/src/rhsmlib/dbus/dbus_utils.py
new file mode 100644
index 0000000000..2dd08d391b
--- /dev/null
+++ b/src/rhsmlib/dbus/dbus_utils.py
@@ -0,0 +1,244 @@
+# -*- coding: utf-8 -*-
+#
+# Copyright (C) 2011,2012 Red Hat, Inc.
+#
+# Authors:
+# Thomas Woerner <twoerner@redhat.com>
+#
+# This program is free software; you can redistribute it and/or modify
+# it under the terms of the GNU General Public License as published by
+# the Free Software Foundation; either version 2 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU General Public License for more details.
+#
+# You should have received a copy of the GNU General Public License
+# along with this program.  If not, see <http://www.gnu.org/licenses/>.
+#
+
+import logging
+import pwd
+import sys
+import xml.etree.ElementTree as Et
+
+import dbus
+
+PY2 = sys.version < '3'
+
+log = logging.getLogger(__name__)
+
+
+def command_of_pid(pid):
+    """ Get command for pid from /proc """
+    try:
+        with open("/proc/%d/cmdline" % pid, "r") as f:
+            cmd = f.readlines()[0].replace('\0', " ").strip()
+    except:
+        return None
+    return cmd
+
+
+def pid_of_sender(bus, sender):
+    """ Get pid from sender string using
+    org.freedesktop.DBus.GetConnectionUnixProcessID """
+
+    dbus_obj = bus.get_object('org.freedesktop.DBus', '/org/freedesktop/DBus')
+    dbus_iface = dbus.Interface(dbus_obj, 'org.freedesktop.DBus')
+
+    try:
+        pid = int(dbus_iface.GetConnectionUnixProcessID(sender))
+    except ValueError:
+        return None
+    return pid
+
+
+def uid_of_sender(bus, sender):
+    """ Get user id from sender string using
+    org.freedesktop.DBus.GetConnectionUnixUser """
+
+    dbus_obj = bus.get_object('org.freedesktop.DBus', '/org/freedesktop/DBus')
+    dbus_iface = dbus.Interface(dbus_obj, 'org.freedesktop.DBus')
+
+    try:
+        uid = int(dbus_iface.GetConnectionUnixUser(sender))
+    except ValueError:
+        return None
+    return uid
+
+
+def user_of_uid(uid):
+    """ Get user for uid from pwd """
+
+    try:
+        pws = pwd.getpwuid(uid)
+    except Exception:
+        return None
+    return pws[0]
+
+
+def context_of_sender(bus, sender):
+    """ Get SELinux context from sender string using
+    org.freedesktop.DBus.GetConnectionSELinuxSecurityContext """
+
+    dbus_obj = bus.get_object('org.freedesktop.DBus', '/org/freedesktop/DBus')
+    dbus_iface = dbus.Interface(dbus_obj, 'org.freedesktop.DBus')
+
+    try:
+        context = dbus_iface.GetConnectionSELinuxSecurityContext(sender)
+    except:
+        return None
+
+    return "".join(map(chr, dbus_to_python(context)))
+
+
+def command_of_sender(bus, sender):
+    """ Return command of D-Bus sender """
+
+    return command_of_pid(pid_of_sender(bus, sender))
+
+
+def user_of_sender(bus, sender):
+    return user_of_uid(uid_of_sender(bus, sender))
+
+
+def dbus_to_python(obj, expected_type=None):
+    if obj is None:
+        python_obj = obj
+    elif isinstance(obj, dbus.Boolean):
+        python_obj = bool(obj)
+    elif isinstance(obj, dbus.String):
+        python_obj = obj.encode('utf-8') if PY2 else str(obj)
+    elif PY2 and isinstance(obj, dbus.UTF8String):  # Python3 has no UTF8String
+        python_obj = str(obj)
+    elif isinstance(obj, dbus.ObjectPath):
+        python_obj = str(obj)
+    elif isinstance(obj, dbus.Byte) or \
+            isinstance(obj, dbus.Int16) or \
+            isinstance(obj, dbus.Int32) or \
+            isinstance(obj, dbus.Int64) or \
+            isinstance(obj, dbus.UInt16) or \
+            isinstance(obj, dbus.UInt32) or \
+            isinstance(obj, dbus.UInt64):
+        python_obj = int(obj)
+    elif isinstance(obj, dbus.Double):
+        python_obj = float(obj)
+    elif isinstance(obj, dbus.Array):
+        python_obj = [dbus_to_python(x) for x in obj]
+    elif isinstance(obj, dbus.Struct):
+        python_obj = tuple([dbus_to_python(x) for x in obj])
+    elif isinstance(obj, dbus.Dictionary):
+        #python_obj = {dbus_to_python(k): dbus_to_python(v) for k, v in obj.items()}
+        python_obj = dict([dbus_to_python(k), dbus_to_python(v)] for k, v in obj.items())
+    elif isinstance(obj, bool) or \
+         isinstance(obj, str) or isinstance(obj, bytes) or \
+         isinstance(obj, int) or isinstance(obj, float) or \
+         isinstance(obj, list) or isinstance(obj, tuple) or \
+         isinstance(obj, dict):
+        python_obj = obj
+    else:
+        raise TypeError("Unhandled %s" % obj)
+
+    if expected_type is not None:
+        if (expected_type == bool and not isinstance(python_obj, bool)) or \
+           (expected_type == str and not isinstance(python_obj, str)) or \
+           (expected_type == int and not isinstance(python_obj, int)) or \
+           (expected_type == float and not isinstance(python_obj, float)) or \
+           (expected_type == list and not isinstance(python_obj, list)) or \
+           (expected_type == tuple and not isinstance(python_obj, tuple)) or \
+           (expected_type == dict and not isinstance(python_obj, dict)):
+            raise TypeError("%s is %s, expected %s" % (python_obj, type(python_obj), expected_type))
+
+    return python_obj
+
+# From lvm-dubstep/lvmdbus/utils.py  (GPLv2, copyright Red Hat)
+# https://github.com/tasleson/lvm-dubstep
+_type_map = dict(
+    s=dbus.String,
+    o=dbus.ObjectPath,
+    t=dbus.UInt64,
+    x=dbus.Int64,
+    u=dbus.UInt32,
+    i=dbus.Int32,
+    n=dbus.Int16,
+    q=dbus.UInt16,
+    d=dbus.Double,
+    y=dbus.Byte,
+    b=dbus.Boolean)
+
+
+def _pass_through(v):
+    """
+    If we have something which is not a simple type we return the original
+    value un-wrapped.
+    :param v:
+    :return:"""
+    return v
+
+
+def _dbus_type(t, value):
+    return _type_map.get(t, _pass_through)(value)
+
+
+def add_properties(xml, interface, props):
+    """
+    Given xml that describes the interface, add property values to the XML
+    for the specified interface.
+    :param xml:         XML to edit
+    :param interface:   Interface to add the properties too
+    :param props:       Output from get_properties
+    :return: updated XML string
+    """
+    root = Et.fromstring(xml)
+
+    if props:
+
+        for c in root:
+            # print c.attrib['name']
+            if c.attrib['name'] == interface:
+                for p in props:
+                    temp = '<property type="%s" name="%s" access="%s"/>\n' % \
+                        (p['p_t'], p['p_name'], p['p_access'])
+                    log.debug("intro xml temp buf=%s", temp)
+                    c.append(Et.fromstring(temp))
+
+        return Et.tostring(root, encoding='utf8')
+    return xml
+
+
+def dict_to_variant_dict(in_dict):
+    # Handle creating dbus.Dictionaries with signatures of 'sv'
+    for key, value in in_dict.iteritems():
+        if isinstance(value, dict):
+            in_dict[key] = dict_to_variant_dict(value)
+    return dbus.Dictionary(in_dict, signature="sv")
+
+
+def _decode_dict(data):
+    rv = {}
+    for key, value in data.iteritems():
+        if isinstance(key, unicode):
+            key = key.encode('utf-8')
+        if isinstance(value, unicode):
+            value = value.encode('utf-8')
+        elif isinstance(value, list):
+            value = _decode_list(value)
+        elif isinstance(value, dict):
+            value = _decode_dict(value)
+        rv[key] = value
+    return rv
+
+
+def _decode_list(data):
+    rv = []
+    for item in data:
+        if isinstance(item, unicode):
+            item = item.encode('utf-8')
+        elif isinstance(item, list):
+            item = _decode_list(item)
+        elif isinstance(item, dict):
+            item = _decode_dict(item)
+        rv.append(item)
+    return rv
diff --git a/src/rhsmlib/dbus/exceptions.py b/src/rhsmlib/dbus/exceptions.py
new file mode 100644
index 0000000000..9483a23543
--- /dev/null
+++ b/src/rhsmlib/dbus/exceptions.py
@@ -0,0 +1,90 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+import dbus
+from rhsmlib.dbus import constants
+
+__all__ = [
+    'RHSM1DBusException',
+    'UnknownProperty',
+    'UnknownInterface',
+    'InvalidArguments',
+    'AccessDenied',
+    'PropertyMissing',
+    'Failed',
+]
+
+
+class RHSM1DBusException(dbus.DBusException):
+    """Base exceptions."""
+    include_traceback = True
+    _dbus_error_name = "%s.Error" % constants.INTERFACE_BASE
+
+
+class UnknownProperty(dbus.DBusException):
+    include_traceback = True
+
+    def __init__(self, property_name):
+        super(UnknownProperty, self).__init__(
+            "Property '%s' does not exist" % property_name,
+            name="org.freedesktop.DBus.Error.UnknownProperty"
+        )
+
+
+class UnknownInterface(dbus.DBusException):
+    include_traceback = True
+
+    def __init__(self, interface_name):
+        super(UnknownInterface, self).__init__(
+            "Interface '%s' is unknown" % interface_name,
+            name="org.freedesktop.DBus.Error.UnknownInterface"
+        )
+
+
+class InvalidArguments(dbus.DBusException):
+    include_traceback = True
+
+    def __init__(self, argument):
+        super(InvalidArguments, self).__init__(
+            "Argument '%s' is invalid" % argument,
+            name="org.freedesktop.DBus.Error.InvalidArgs"
+        )
+
+
+class AccessDenied(dbus.DBusException):
+    include_traceback = True
+
+    def __init__(self, prop, interface):
+        super(AccessDenied, self).__init__(
+            "Property '%s' isn't exported (or does not exist) on interface: %s" % (prop, interface),
+            name="org.freedesktop.DBus.Error.AccessDenied"
+        )
+
+
+class PropertyMissing(dbus.DBusException):
+    include_traceback = True
+
+    def __init__(self, prop, interface):
+        super(PropertyMissing, self).__init__(
+            "Property '%s' does not exist on interface: %s" % (prop, interface),
+            name="org.freedesktop.DBus.Error.AccessDenied"
+        )
+
+
+class Failed(dbus.DBusException):
+    include_traceback = True
+
+    def __init__(self, msg=None):
+        super(Failed, self).__init__(
+            msg or "Operation failed",
+            name="org.freedesktop.DBus.Error.Failed"
+        )
diff --git a/src/rhsmlib/dbus/facts/__init__.py b/src/rhsmlib/dbus/facts/__init__.py
new file mode 100644
index 0000000000..7dde16da9d
--- /dev/null
+++ b/src/rhsmlib/dbus/facts/__init__.py
@@ -0,0 +1,3 @@
+from rhsmlib.dbus.facts.base import HostFacts  # noqa: F401
+from rhsmlib.dbus.facts.client import FactsClient, FactsClientAuthenticationError  # noqa: F401
+from rhsmlib.dbus.facts.constants import FACTS_DBUS_NAME, FACTS_DBUS_INTERFACE, FACTS_DBUS_PATH  # noqa: F401
diff --git a/src/rhsmlib/dbus/facts/base.py b/src/rhsmlib/dbus/facts/base.py
new file mode 100644
index 0000000000..957dddccbc
--- /dev/null
+++ b/src/rhsmlib/dbus/facts/base.py
@@ -0,0 +1,120 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import os
+import logging
+import dbus
+
+import rhsm.config
+
+from rhsmlib.facts import collector, host_collector, hwprobe, custom
+from rhsmlib.dbus import util, base_object
+from rhsmlib.dbus.facts import constants
+
+log = logging.getLogger(__name__)
+
+
+class BaseFacts(base_object.BaseObject):
+    interface_name = constants.FACTS_DBUS_INTERFACE
+    default_props_data = {}
+    facts_collector_class = collector.FactsCollector
+
+    def __init__(self, conn=None, object_path=None, bus_name=None):
+        super(BaseFacts, self).__init__(conn=conn, object_path=object_path, bus_name=bus_name)
+
+        # Default is an empty FactsCollector
+        self.facts_collector = self.facts_collector_class()
+
+    @util.dbus_service_method(
+        dbus_interface=constants.FACTS_DBUS_INTERFACE,
+        out_signature='a{ss}')
+    @util.dbus_handle_exceptions
+    def GetFacts(self, sender=None):
+        collection = self.facts_collector.collect()
+        cleaned = dict([(str(key), str(value)) for key, value in collection.data.items()])
+        return dbus.Dictionary(cleaned, signature="ss")
+
+
+class AllFacts(base_object.BaseObject):
+    interface_name = constants.FACTS_DBUS_INTERFACE
+    default_dbus_path = constants.FACTS_DBUS_PATH
+
+    def __init__(self, conn=None, object_path=None, bus_name=None):
+        super(AllFacts, self).__init__(conn=conn, object_path=object_path, bus_name=bus_name)
+
+        # Why aren't we using a dictionary here? Because we want to control the order and OrderedDict
+        # isn't in Python 2.6.  By controlling the order and putting CustomFacts last, we can ensure
+        # that users can override any fact.
+        collector_definitions = [
+            ("Host", HostFacts),
+            ("Hardware", HardwareFacts),
+            ("Static", StaticFacts),
+            ("Custom", CustomFacts),
+        ]
+
+        self.collectors = []
+        for path, clazz in collector_definitions:
+            sub_path = self.default_dbus_path + "/" + path
+            self.collectors.append(
+                (path, clazz(conn=conn, object_path=sub_path, bus_name=bus_name))
+            )
+
+    @util.dbus_service_method(
+        dbus_interface=constants.FACTS_DBUS_INTERFACE,
+        out_signature='a{ss}')
+    @util.dbus_handle_exceptions
+    def GetFacts(self, sender=None):
+        results = {}
+        for name, fact_collector in self.collectors:
+            results.update(fact_collector.GetFacts())
+        return dbus.Dictionary(results, signature="ss")
+
+    def remove_from_connection(self, connection=None, path=None):
+        # Call remove_from_connection on all the child objects first
+        for sub_path, obj in self.collectors:
+            if path:
+                child_path = path + "/" + sub_path
+            else:
+                child_path = None
+            obj.remove_from_connection(connection, child_path)
+        super(AllFacts, self).remove_from_connection(connection, path)
+
+
+class HostFacts(BaseFacts):
+    def __init__(self, conn=None, object_path=None, bus_name=None):
+        super(HostFacts, self).__init__(conn=conn, object_path=object_path, bus_name=bus_name)
+        self.facts_collector = host_collector.HostCollector()
+
+
+class HardwareFacts(BaseFacts):
+    def __init__(self, conn=None, object_path=None, bus_name=None):
+        super(HardwareFacts, self).__init__(conn=conn, object_path=object_path, bus_name=bus_name)
+        self.facts_collector = hwprobe.HardwareCollector()
+
+
+class CustomFacts(BaseFacts):
+    def __init__(self, conn=None, object_path=None, bus_name=None):
+        super(CustomFacts, self).__init__(conn=conn, object_path=object_path, bus_name=bus_name)
+
+        paths_and_globs = [
+            (os.path.join(rhsm.config.DEFAULT_CONFIG_DIR, 'facts'), '*.facts'),
+        ]
+        self.facts_collector = custom.CustomFactsCollector(path_and_globs=paths_and_globs)
+
+
+class StaticFacts(BaseFacts):
+    def __init__(self, conn=None, object_path=None, bus_name=None):
+        super(StaticFacts, self).__init__(conn=conn, object_path=object_path, bus_name=bus_name)
+        self.facts_collector = collector.StaticFactsCollector({
+            "system.certificate_version": constants.CERT_VERSION
+        })
diff --git a/src/rhsmlib/dbus/facts/client.py b/src/rhsmlib/dbus/facts/client.py
new file mode 100755
index 0000000000..0b18a09d9c
--- /dev/null
+++ b/src/rhsmlib/dbus/facts/client.py
@@ -0,0 +1,61 @@
+# Copyright (c) 2010-2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+
+import logging
+import dbus
+
+from rhsmlib.dbus.facts import constants as facts_constants
+
+log = logging.getLogger(__name__)
+
+
+class FactsClientAuthenticationError(Exception):
+    def __init__(self, *args, **kwargs):
+        action_id = kwargs.pop("action_id")
+        super(FactsClientAuthenticationError, self).__init__(*args, **kwargs)
+        log.debug("FactsClientAuthenticationError created for %s", action_id)
+        self.action_id = action_id
+
+
+class FactsClient(object):
+    bus_name = facts_constants.FACTS_DBUS_NAME
+    object_path = facts_constants.FACTS_DBUS_PATH
+    interface_name = facts_constants.FACTS_DBUS_INTERFACE
+
+    def __init__(self, bus=None, bus_name=None, object_path=None, interface_name=None):
+        self.bus = bus or dbus.SystemBus()
+
+        if bus_name:
+            self.bus_name = bus_name
+
+        if object_path:
+            self.object_path = object_path
+
+        if interface_name:
+            self.interface_name = interface_name
+
+        self.dbus_proxy_object = self.bus.get_object(self.bus_name, self.object_path,
+            follow_name_owner_changes=True)
+
+        self.interface = dbus.Interface(self.dbus_proxy_object,
+            dbus_interface=self.interface_name)
+
+        self.bus.call_on_disconnection(self._on_bus_disconnect)
+
+    def GetFacts(self, *args, **kwargs):
+        return self.interface.GetFacts(*args, **kwargs)
+
+    def _on_bus_disconnect(self, connection):
+        self.dbus_proxy_object = None
+        log.debug("Disconnected from FactsService")
diff --git a/src/rhsmlib/dbus/facts/constants.py b/src/rhsmlib/dbus/facts/constants.py
new file mode 100644
index 0000000000..6bb065c595
--- /dev/null
+++ b/src/rhsmlib/dbus/facts/constants.py
@@ -0,0 +1,38 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+from rhsmlib.dbus import constants
+
+__all__ = [
+    'SUB_SERVICE_NAME',
+    'FACTS_DBUS_NAME',
+    'FACTS_DBUS_INTERFACE',
+    'FACTS_DBUS_PATH',
+    'FACTS_VERSION',
+    'FACTS_NAME',
+]
+
+SUB_SERVICE_NAME = "Facts"
+
+# com.redhat.RHSM1.Facts
+FACTS_DBUS_NAME = constants.BUS_NAME + '.' + SUB_SERVICE_NAME
+
+# also, com.redhat.RHSM1.Facts
+FACTS_DBUS_INTERFACE = constants.BUS_NAME + '.' + SUB_SERVICE_NAME
+
+# /com/redhat/RHSM1/Facts
+FACTS_DBUS_PATH = constants.ROOT_DBUS_PATH + '/' + SUB_SERVICE_NAME
+
+FACTS_VERSION = "1.1e1"
+FACTS_NAME = "Red Hat Subscription Manager facts."
+
+CERT_VERSION = "3.2"
diff --git a/src/rhsmlib/dbus/objects/__init__.py b/src/rhsmlib/dbus/objects/__init__.py
new file mode 100644
index 0000000000..654c51e646
--- /dev/null
+++ b/src/rhsmlib/dbus/objects/__init__.py
@@ -0,0 +1,16 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+from rhsmlib.dbus.objects.config import ConfigDBusObject  # NOQA
+from rhsmlib.dbus.objects.main import Main  # NOQA
+from rhsmlib.dbus.objects.register import RegisterDBusObject, DomainSocketRegisterDBusObject  # NOQA
diff --git a/src/rhsmlib/dbus/objects/config.py b/src/rhsmlib/dbus/objects/config.py
new file mode 100644
index 0000000000..ca70471dfc
--- /dev/null
+++ b/src/rhsmlib/dbus/objects/config.py
@@ -0,0 +1,72 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import dbus
+import logging
+
+from rhsmlib.dbus import constants, base_object, util, dbus_utils
+from rhsmlib.services.config import Config
+
+from dbus import DBusException
+log = logging.getLogger(__name__)
+
+
+class ConfigDBusObject(base_object.BaseObject):
+    default_dbus_path = constants.CONFIG_DBUS_PATH
+    interface_name = constants.CONFIG_INTERFACE
+
+    def __init__(self, conn=None, object_path=None, bus_name=None, parser=None):
+        self.config = Config(parser)
+        super(ConfigDBusObject, self).__init__(conn=conn, object_path=object_path, bus_name=bus_name)
+
+    @util.dbus_service_method(
+        constants.CONFIG_INTERFACE,
+        in_signature='sv')
+    @util.dbus_handle_exceptions
+    def Set(self, property_name, new_value, sender=None):
+        property_name = dbus_utils.dbus_to_python(property_name, str)
+        new_value = dbus_utils.dbus_to_python(new_value, str)
+        section, _dot, property_name = property_name.partition('.')
+
+        if not property_name:
+            raise DBusException("Setting an entire section is not supported.  Use 'section.property' format.")
+
+        self.config[section][property_name] = new_value
+        self.config.persist()
+
+    @util.dbus_service_method(
+        constants.CONFIG_INTERFACE,
+        in_signature='',
+        out_signature='a{sv}')
+    @util.dbus_handle_exceptions
+    def GetAll(self, sender=None):
+        d = dbus.Dictionary({}, signature='sv')
+        for k, v in self.config.iteritems():
+            d[k] = dbus.Dictionary({}, signature='ss')
+            for kk, vv in v.iteritems():
+                d[k][kk] = vv
+
+        return d
+
+    @util.dbus_service_method(
+        constants.CONFIG_INTERFACE,
+        in_signature='s',
+        out_signature='v')
+    @util.dbus_handle_exceptions
+    def Get(self, property_name, sender=None):
+        section, _dot, property_name = property_name.partition('.')
+
+        if property_name:
+            return self.config[section][property_name]
+        else:
+            return dbus.Dictionary(self.config[section], signature='sv')
diff --git a/src/rhsmlib/dbus/objects/main.py b/src/rhsmlib/dbus/objects/main.py
new file mode 100644
index 0000000000..60863f84c8
--- /dev/null
+++ b/src/rhsmlib/dbus/objects/main.py
@@ -0,0 +1,25 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import logging
+
+from rhsmlib.dbus import base_object
+from subscription_manager.injectioninit import init_dep_injection
+
+log = logging.getLogger(__name__)
+init_dep_injection()
+
+
+class Main(base_object.BaseObject):
+    """Just a place holder for now"""
+    pass
diff --git a/src/rhsmlib/dbus/objects/register.py b/src/rhsmlib/dbus/objects/register.py
new file mode 100644
index 0000000000..522d6d3da8
--- /dev/null
+++ b/src/rhsmlib/dbus/objects/register.py
@@ -0,0 +1,201 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import gettext
+import socket
+import json
+import logging
+import dbus.service
+import threading
+
+from rhsmlib.dbus import constants, exceptions, dbus_utils, base_object, server, util, facts
+
+from subscription_manager import managerlib
+from rhsm import connection
+
+from subscription_manager import injection as inj
+from subscription_manager.injectioninit import init_dep_injection
+
+init_dep_injection()
+
+_ = gettext.gettext
+log = logging.getLogger(__name__)
+
+
+class RegisterDBusObject(base_object.BaseObject):
+    default_dbus_path = constants.REGISTER_DBUS_PATH
+    interface_name = constants.REGISTER_INTERFACE
+
+    def __init__(self, conn=None, object_path=None, bus_name=None):
+        super(RegisterDBusObject, self).__init__(conn=conn, object_path=object_path, bus_name=bus_name)
+        self.started_event = threading.Event()
+        self.stopped_event = threading.Event()
+        self.server = None
+        self.lock = threading.Lock()
+
+    @util.dbus_service_method(
+        constants.REGISTER_INTERFACE,
+        in_signature='',
+        out_signature='s')
+    @util.dbus_handle_exceptions
+    def Start(self, sender=None):
+        with self.lock:
+            if self.server:
+                return self.server.address
+
+            log.debug('Attempting to create new domain socket server')
+            self.server = server.DomainSocketServer(
+                object_classes=[DomainSocketRegisterDBusObject],
+            )
+            address = self.server.run()
+            log.debug('DomainSocketServer created and listening on "%s"', address)
+            return address
+
+    @util.dbus_service_method(
+        constants.REGISTER_INTERFACE,
+        in_signature='',
+        out_signature='b')
+    @util.dbus_handle_exceptions
+    def Stop(self, sender=None):
+        with self.lock:
+            if self.server:
+                self.server.shutdown()
+                self.server = None
+                log.debug("Stopped DomainSocketServer")
+                return True
+            else:
+                raise exceptions.Failed("No domain socket server is running")
+
+
+class DomainSocketRegisterDBusObject(base_object.BaseObject):
+    interface_name = constants.PRIVATE_REGISTER_INTERFACE
+    default_dbus_path = constants.PRIVATE_REGISTER_DBUS_PATH
+
+    def __init__(self, conn=None, object_path=None, bus_name=None):
+        # On our DomainSocket DBus server since a private connection is not a "bus", we have to treat
+        # it slightly differently. In particular there are no names, no discovery and so on.
+        super(DomainSocketRegisterDBusObject, self).__init__(
+            conn=conn,
+            object_path=object_path,
+            bus_name=bus_name
+        )
+        self.installed_mgr = inj.require(inj.INSTALLED_PRODUCTS_MANAGER)
+
+    @dbus.service.method(
+        dbus_interface=constants.PRIVATE_REGISTER_INTERFACE,
+        in_signature='sssa{sv}',
+        out_signature='a{sv}'
+    )
+    def Register(self, org, username, password, options):
+        """
+        This method registers the system using basic auth
+        (username and password for a given org).
+        For any option that is required but not included the default will be
+        used.
+
+        Options is a dict of strings that modify the outcome of this method.
+
+        Note this method is registration ONLY.  Auto-attach is a separate process.
+        """
+        options['username'] = username
+        options['password'] = password
+
+        result = self._register(org, None, options)
+        return dbus_utils.dict_to_variant_dict(result)
+
+    @dbus.service.method(dbus_interface=constants.PRIVATE_REGISTER_INTERFACE,
+        in_signature='sa(s)a{ss}',
+        out_signature='a{sv}')
+    def RegisterWithActivationKeys(self, org, activation_keys, options):
+        """
+        Note this method is registration ONLY.  Auto-attach is a separate process.
+        """
+        result = self._register(org, activation_keys, options)
+        return dbus_utils.dict_to_variant_dict(result)
+
+    def _register(self, org, activation_keys, options):
+        options = dbus_utils.dbus_to_python(options)
+        options = self.validate_options(options)
+
+        environment = options.get('environment')
+        facts_client = facts.FactsClient()
+
+        cp = self.build_uep(options)
+        registration_output = cp.registerConsumer(
+            name=options['name'],
+            facts=facts_client.GetFacts(),
+            owner=org,
+            environment=environment,
+            keys=activation_keys,
+            installed_products=self.installed_mgr.format_for_server(),
+            content_tags=self.installed_mgr.tags
+        )
+        self.installed_mgr.write_cache()
+
+        consumer = json.loads(registration_output['content'], object_hook=dbus_utils._decode_dict)
+        managerlib.persist_consumer_cert(consumer)
+
+        if 'idCert' in consumer:
+            del consumer['idCert']
+
+        registration_output['content'] = json.dumps(consumer)
+        return registration_output
+
+    def build_uep(self, options):
+        return connection.UEPConnection(
+            username=options.get('username', None),
+            password=options.get('password', None),
+            host=options.get('host', None),
+            ssl_port=connection.safe_int(options.get('port', None)),
+            handler=options.get('handler', None),
+            insecure=options.get('insecure', None),
+            proxy_hostname=options.get('proxy_hostname', None),
+            proxy_port=options.get('proxy_port', None),
+            proxy_user=options.get('proxy_user', None),
+            proxy_password=options.get('proxy_password', None),
+            restlib_class=connection.BaseRestLib
+        )
+
+    def is_registered(self):
+        return inj.require(inj.IDENTITY).is_valid()
+
+    def validate_options(self, options):
+        # TODO: Rewrite the error messages to be more dbus specific
+        error_msg = None
+        if self.is_registered() and not options.get('force', False):
+            error_msg = _("This system is already registered. Add force to options to override.")
+        elif options.get('name') == '':
+            error_msg = _("Error: system name can not be empty.")
+        elif 'consumerid' in options and 'force' in options:
+            error_msg = _("Error: Can not force registration while attempting to recover registration with consumerid. Please use --force without --consumerid to re-register or use the clean command and try again without --force.")
+
+        if 'activation_keys' in options:
+            # 746259: Don't allow the user to pass in an empty string as an activation key
+            if '' == options['activation_keys']:
+                error_msg = _("Error: Must specify an activation key")
+            elif 'username' in options:
+                error_msg = _("Error: Activation keys do not require user credentials.")
+            elif 'consumerid' in options:
+                error_msg = _("Error: Activation keys can not be used with previously registered IDs.")
+            elif 'environment' in options:
+                error_msg = _("Error: Activation keys do not allow environments to be specified.")
+            elif 'org' not in options:
+                error_msg = _("Error: Must provide --org with activation keys.")
+
+        if error_msg:
+            raise exceptions.Failed(msg=error_msg)
+
+        if 'name' not in options:
+            options['name'] = socket.gethostname()
+
+        return options
diff --git a/src/rhsmlib/dbus/server.py b/src/rhsmlib/dbus/server.py
new file mode 100644
index 0000000000..79f040cdf6
--- /dev/null
+++ b/src/rhsmlib/dbus/server.py
@@ -0,0 +1,179 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import logging
+import dbus.service
+import dbus.server
+import dbus.mainloop.glib
+import threading
+
+from rhsmlib.dbus import constants
+
+from subscription_manager import ga_loader
+ga_loader.init_ga()
+from subscription_manager.ga import GLib
+
+from functools import partial
+
+log = logging.getLogger(__name__)
+
+
+class Server(object):
+    def __init__(self, bus_class=None, bus_name=None, object_classes=None, bus_kwargs=None):
+        """Create a connection to a bus defined by bus_class and bus_kwargs; instantiate objects in
+        object_classes; expose them under bus_name and enter a GLib mainloop.  bus_kwargs are generally
+        only necessary if you're using dbus.bus.BusConnection
+
+        The object_classes argument is a list.  The list can contain either a class or a tuple consisting
+        of a class and a dictionary of arguments to send that class's constructor.
+        """
+
+        # Configure mainloop for threading.  We must do so in GLib and python-dbus.
+        GLib.threads_init()
+        dbus.mainloop.glib.threads_init()
+
+        self.bus_name = bus_name or constants.BUS_NAME
+        bus_class = bus_class or dbus.SystemBus
+        bus_kwargs = bus_kwargs or {}
+        object_classes = object_classes or []
+        self.objects = []
+
+        try:
+            self.bus = bus_class(**bus_kwargs)
+        except dbus.exceptions.DBusException:
+            log.exception("Could not create bus class")
+            raise
+
+        self.connection_name = dbus.service.BusName(self.bus_name, self.bus)
+        self.mainloop = GLib.MainLoop()
+
+        for item in object_classes:
+            try:
+                clazz, kwargs = item[0], item[1]
+            except TypeError:
+                clazz = item
+                kwargs = {}
+
+            self.objects.append(
+                clazz(object_path=clazz.default_dbus_path, bus_name=self.connection_name, **kwargs)
+            )
+
+    def run(self, started_event=None, stopped_event=None):
+        """The two arguments, started_event and stopped_event, should be instances of threading.Event that
+        will be set when the mainloop has finished starting and stopping."""
+        try:
+            GLib.idle_add(self.notify_started, started_event)
+            self.mainloop.run()
+        except KeyboardInterrupt as e:
+            log.exception(e)
+        except SystemExit as e:
+            log.exception(e)
+        except Exception as e:
+            log.exception(e)
+        finally:
+            if stopped_event:
+                stopped_event.set()
+
+    def notify_started(self, started_event):
+        """This callback will be run once the mainloop is up and running.  It's only purpose is to alert
+        other blocked threads that the mainloop is ready."""
+        log.debug("Start notification sent")
+        if started_event:
+            started_event.set()
+        # Only run this callback once
+        return False
+
+    def shutdown(self):
+        """This method is primarily intended for uses of Server in a thread such as during testing since
+        in a single-threaded program, the execution would be blocked on the mainloop and therefore
+        preclude even calling this method."""
+        self.mainloop.quit()
+
+        # Unregister/remove everything.  Note that if you used dbus.SessionBus or dbus.SystemBus,
+        # python-dbus will keep a cache of your old BusName objects even though we are releasing the name
+        # here.  This will create a problem if you attempt to reacquire the BusName since python-dbus will
+        # give you a stale reference.  Use dbus.Connection.BusConnection to avoid this problem.
+        # See http://stackoverflow.com/questions/17446414/dbus-object-lifecycle
+        map(lambda x: x.remove_from_connection(), self.objects)
+        self.bus.release_name(self.bus_name)
+
+
+class DomainSocketServer(object):
+    """This class sets up a DBus server on a domain socket. That server can then be used to perform
+    registration. The issue is that we can't send registration credentials over the regular system or
+    session bus since those aren't really locked down. The work-around is the client asks our service
+    to open another server on a domain socket, gets socket information back, and then connects and sends
+    the register command (with the credentials) to the server on the domain socket."""
+    @staticmethod
+    def connection_added(domain_socket_server, service_class, object_list, conn):
+        object_list.append(service_class(conn=conn))
+        with domain_socket_server.lock:
+            domain_socket_server.connection_count += 1
+        log.info("New connection: %s", conn)
+
+    @staticmethod
+    def connection_removed(domain_socket_server, conn):
+        log.debug("Closed connection: %s", conn)
+        with domain_socket_server.lock:
+            domain_socket_server.connection_count -= 1
+            if domain_socket_server.connection_count == 0:
+                log.debug('No connections remain')
+            else:
+                log.debug('Server still has connections')
+
+    @property
+    def address(self):
+        if self._server:
+            return self._server.address
+        else:
+            return None
+
+    def __init__(self, object_classes=None):
+        """Create a connection to a bus defined by bus_class and bus_kwargs; instantiate objects in
+        object_classes; expose them under bus_name and enter a GLib mainloop.  bus_kwargs are generally
+        only necessary if you're using dbus.bus.BusConnection
+
+        The object_classes argument is a list.  The list can contain either a class or a tuple consisting
+        of a class and a dictionary of arguments to send that class's constructor.
+        """
+        self.object_classes = object_classes or []
+        self.objects = []
+
+        self.lock = threading.Lock()
+        with self.lock:
+            self.connection_count = 0
+
+    def shutdown(self):
+        map(lambda x: x.remove_from_connection(), self.objects)
+        self._server.disconnect()
+
+        # Allow self.objects and self._server to get GCed
+        self.objects = None
+        self._server = None
+
+    def run(self):
+        try:
+            self._server = dbus.server.Server("unix:tmpdir=/var/run")
+
+            for clazz in self.object_classes:
+                self._server.on_connection_added.append(
+                    partial(DomainSocketServer.connection_added, self, clazz, self.objects)
+                )
+
+            self._server.on_connection_removed.append(
+                partial(DomainSocketServer.connection_removed, self)
+            )
+
+            return self.address
+        except Exception as e:
+            log.exception(e)
diff --git a/src/rhsmlib/dbus/service_wrapper.py b/src/rhsmlib/dbus/service_wrapper.py
new file mode 100644
index 0000000000..e86b2031fe
--- /dev/null
+++ b/src/rhsmlib/dbus/service_wrapper.py
@@ -0,0 +1,73 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+import sys
+import optparse
+import dbus
+import dbus.mainloop.glib
+import rhsmlib
+import logging
+
+from rhsmlib.dbus import server
+
+log = logging.getLogger(__name__)
+
+
+def load_bus_class(option, opt_str, value, parser):
+    """OptionParser callback method to load a class from a string"""
+    clazz = rhsmlib.import_class(value)
+    parser.values.bus = clazz
+
+
+def parse_argv(argv, default_dbus_name):
+    parser = optparse.OptionParser(usage="usage: %prog [options] [class name]")
+    parser.add_option("-b", "--bus",
+        action="callback", callback=load_bus_class,
+        type="string", default=dbus.SystemBus,
+        help="Bus to use (defaults to dbus.SystemBus)")
+    parser.add_option("-n", "--bus-name", default=default_dbus_name)
+    parser.add_option("-v", "--verbose", action="store_true")
+    (opts, args) = parser.parse_args(argv[1:])
+    return opts, args
+
+
+def main(argv=sys.argv, object_classes=None, default_bus_name=None):
+    # Set default mainloop
+    dbus.mainloop.glib.DBusGMainLoop(set_as_default=True)
+
+    if not default_bus_name:
+        default_bus_name = rhsmlib.dbus.constants.BUS_NAME
+
+    options, args = parse_argv(argv, default_bus_name)
+
+    if options.verbose:
+        logger = logging.getLogger('')
+        logger.setLevel(logging.DEBUG)
+
+    if not object_classes:
+        # Read the object classes from the command-line if we don't
+        # get anything as a parameter
+        object_classes = []
+        for clazz in args:
+            object_classes.append(rhsmlib.import_class(clazz))
+
+    try:
+        log.debug('Starting DBus service with name %s' % options.bus_name)
+        server.Server(
+            bus_class=options.bus,
+            bus_name=options.bus_name,
+            object_classes=object_classes).run()
+    except dbus.exceptions.DBusException as e:
+        if e._dbus_error_name == "org.freedesktop.DBus.Error.AccessDenied":
+            print("Access to DBus denied.  You need to edit /etc/dbus-1/system.conf to allow %s or run with "
+                "dbus-daemon and a custom config file." % options.bus_name)
+    return 0
diff --git a/src/rhsmlib/dbus/util.py b/src/rhsmlib/dbus/util.py
new file mode 100644
index 0000000000..aca1bbec5b
--- /dev/null
+++ b/src/rhsmlib/dbus/util.py
@@ -0,0 +1,47 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+import logging
+import sys
+import decorator
+import dbus.service
+
+from rhsmlib.dbus import exceptions
+
+log = logging.getLogger(__name__)
+
+__all__ = [
+    'dbus_handle_exceptions',
+    'dbus_service_method',
+]
+
+
+@decorator.decorator
+def dbus_handle_exceptions(func, *args, **kwargs):
+    """Decorator to handle exceptions, log them, and wrap them if necessary"""
+    try:
+        ret = func(*args, **kwargs)
+        return ret
+    except dbus.DBusException as e:
+        log.exception(e)
+        raise
+    except Exception as e:
+        log.exception(e)
+        trace = sys.exc_info()[2]
+        raise exceptions.RHSM1DBusException("%s: %s" % (type(e).__name__, str(e))), None, trace
+
+
+def dbus_service_method(*args, **kwargs):
+    # Tell python-dbus that "sender" will be the keyword to use for the sender unless otherwise
+    # defined.
+    kwargs.setdefault("sender_keyword", "sender")
+    return dbus.service.method(*args, **kwargs)
diff --git a/src/rhsmlib/facts/__init__.py b/src/rhsmlib/facts/__init__.py
new file mode 100644
index 0000000000..e69de29bb2
diff --git a/src/rhsmlib/facts/cleanup.py b/src/rhsmlib/facts/cleanup.py
new file mode 100644
index 0000000000..485c4de12c
--- /dev/null
+++ b/src/rhsmlib/facts/cleanup.py
@@ -0,0 +1,72 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import logging
+
+from rhsmlib.facts import collector
+
+log = logging.getLogger(__name__)
+
+
+class CleanupCollector(collector.FactsCollector):
+    no_uuid_platforms = ['powervm_lx86', 'xen-dom0', 'ibm_systemz']
+
+    def get_all(self):
+        cleanup_facts = {}
+        dmi_socket_info = self.replace_socket_count_with_dmi()
+        cleanup_facts.update(dmi_socket_info)
+        return cleanup_facts
+
+    def explain_lack_of_virt_uuid(self):
+        # No virt.uuid equiv is available for guests on these hypervisors
+        #virt_is_guest = self._collected_hw_info['virt.is_guest']
+        if not self._is_a_virt_host_type_with_virt_uuids():
+            log.debug("we don't sell virt uuids here")
+
+    def _is_a_virt_host_type_with_virt_uuids(self):
+        virt_host_type = self._collected_hw_info['virt.host_type']
+        for no_uuid_platform in self.no_uuid_platforms:
+            if virt_host_type.find(no_uuid_platform) > -1:
+                return False
+        return True
+
+    def replace_socket_count_with_dmi(self):
+        cleanup_info = {}
+        # cpu topology reporting on xen dom0 machines is wrong. So
+        # if we are a xen dom0, and we found socket info in dmiinfo,
+        # replace our normal cpu socket calculation with the dmiinfo one
+        # we have to do it after the virt data and cpu data collection
+        if 'virt.host_type' not in self._collected_hw_info:
+            return cleanup_info
+
+        if not self._host_is_xen_dom0():
+            return cleanup_info
+
+        if 'dmi.meta.cpu_socket_count' not in self._collected_hw_info:
+            return cleanup_info
+
+        # Alright, lets munge up cpu socket info based on the dmi info.
+        socket_count = int(self._collected_hw_info['dmi.meta.cpu_socket_count'])
+        cleanup_info['cpu.cpu_socket(s)'] = socket_count
+
+        if 'cpu.cpu(s)' not in self._collected_hw_info:
+            return cleanup_info
+
+        # And the cores per socket count as well
+        dmi_cpu_cores_per_cpu = int(self._collected_hw_info['cpu.cpu(s)']) / socket_count
+        cleanup_info['cpu.core(s)_per_socket'] = dmi_cpu_cores_per_cpu
+
+        return cleanup_info
+
+    def _host_is_xen_dom0(self):
+        return self._collected_hw_info['virt.host_type'].find('dom0') > -1
diff --git a/src/rhsmlib/facts/collection.py b/src/rhsmlib/facts/collection.py
new file mode 100644
index 0000000000..08b1722e04
--- /dev/null
+++ b/src/rhsmlib/facts/collection.py
@@ -0,0 +1,91 @@
+#
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public
+# License as published by the Free Software Foundation; either version
+# 2 of the License (GPLv2) or (at your option) any later version.
+# There is NO WARRANTY for this software, express or implied,
+# including the implied warranties of MERCHANTABILITY,
+# NON-INFRINGEMENT, or FITNESS FOR A PARTICULAR PURPOSE. You should
+# have received a copy of GPLv2 along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+from datetime import datetime
+import collections
+import logging
+
+log = logging.getLogger(__name__)
+
+
+# TODO: Likely a bit much for this case
+class FactsDict(collections.MutableMapping):
+    """A dict for facts that ignores items in 'graylist' on compares."""
+
+    graylist = set(['cpu.cpu_mhz', 'lscpu.cpu_mhz'])
+
+    def __init__(self, *args, **kwargs):
+        super(FactsDict, self).__init__(*args, **kwargs)
+        self.data = {}
+
+    def __getitem__(self, key):
+        return self.data[key]
+
+    def __setitem__(self, key, value):
+        self.data[key] = value
+
+    def __delitem__(self, key):
+        del self.data[key]
+
+    def __iter__(self):
+        return iter(self.data)
+
+    def __len__(self):
+        return len(self.data)
+
+    def __eq__(self, other):
+        """Compares all of the items in self.data, except it ignores keys in self.graylist."""
+        if not isinstance(other, FactsDict):
+            return NotImplemented
+
+        keys_self = set(self.data).difference(self.graylist)
+        keys_other = set(other.data).difference(self.graylist)
+        if keys_self == keys_other:
+            if all(self.data[k] == other.data[k] for k in keys_self):
+                return True
+
+        return False
+
+    # Maybe total_ordering is a bit overkill for just a custom compare
+    def __lt__(self, other):
+        return len(self) < len(other)
+
+    def __repr__(self):
+        return '%s(%r)' % (self.__class__.__name__, self.items())
+
+
+def compare_with_graylist(dict_a, dict_b, graylist):
+    ka = set(dict_a).difference(graylist)
+    kb = set(dict_b).difference(graylist)
+    return ka == kb and all(dict_a[k] == dict_b[k] for k in ka)
+
+
+class FactsCollection(object):
+    def __init__(self, facts_dict=None):
+        self.data = facts_dict or FactsDict()
+        self.collection_datetime = datetime.now()
+
+    def __repr__(self):
+        buf = "%s(facts_dict=%s, collection_datetime=%s)" % \
+            (self.__class__.__name__, self.data, self.collection_datetime)
+        return buf
+
+    @classmethod
+    def from_facts_collection(cls, facts_collection):
+        """Create a FactsCollection with the data from facts_collection, but new timestamps.
+        ie, a copy(), more or less."""
+        fc = cls()
+        fc.data.update(facts_collection.data)
+        return fc
+
+    def __iter__(self):
+        return self.data
diff --git a/src/rhsmlib/facts/collector.py b/src/rhsmlib/facts/collector.py
new file mode 100644
index 0000000000..6c3eff158c
--- /dev/null
+++ b/src/rhsmlib/facts/collector.py
@@ -0,0 +1,110 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import logging
+import os
+import platform
+
+from rhsmlib.facts import collection
+
+log = logging.getLogger(__name__)
+
+
+def get_arch(prefix=None):
+    """Get the systems architecture.
+
+    This relies on portable means, like uname to determine
+    a high level system arch (ie, x86_64, ppx64,etc).
+
+    We need that so we can decide how to collect the
+    arch specific hardware information.
+
+    Also support a 'prefix' arg that allows us to override
+    the results. The contents of the '/prefix/arch' will
+    override the arch. The 'prefix' arg defaults to None,
+    equiv to '/'. This is intended only for test purposes.
+
+    Returns a string containing the arch."""
+
+    DEFAULT_PREFIX = '/'
+    ARCH_FILE_NAME = 'arch'
+    prefix = prefix or DEFAULT_PREFIX
+
+    if prefix == DEFAULT_PREFIX:
+        return platform.machine()
+
+    arch_file = os.path.join(prefix, ARCH_FILE_NAME)
+    try:
+        with open(arch_file, 'r') as arch_fd:
+            return arch_fd.read().strip()
+    except IOError as e:
+        # If we specify a prefix, and there is no 'arch' file,
+        # consider that fatal.
+        log.exception(e)
+        raise
+
+# An empty FactsCollector should just return an empty dict on get_all()
+
+
+class FactsCollector(object):
+    def __init__(self, arch=None, prefix=None, testing=None,
+                 hardware_methods=None, collected_hw_info=None):
+        """Base class for facts collecting classes.
+
+        self._collected_hw_info will reference the passed collected_hw_info
+        arg. When possible this should be a reference (or copy) to all of the facts
+        collected in this run. Some collection methods need to alter behavior
+        based on facts collector from other modules/classes.
+        self._collected_hw_info isn't meant to be altered as a side effect, but
+        no promises."""
+        self.allhw = {}
+        self.prefix = prefix or ''
+        self.testing = testing or False
+
+        self._collected_hw_info = collected_hw_info
+        # we need this so we can decide which of the
+        # arch specific code bases to follow
+        self.arch = arch or get_arch(prefix=self.prefix)
+
+        self.hardware_methods = hardware_methods or []
+
+    def collect(self):
+        """Return a FactsCollection iterable."""
+        facts_dict = collection.FactsDict()
+        facts_dict.update(self.get_all())
+        facts_collection = collection.FactsCollection(facts_dict=facts_dict)
+        return facts_collection
+
+    def get_all(self):
+        # try each hardware method, and try/except around, since
+        # these tend to be fragile
+        all_hw_info = {}
+        for hardware_method in self.hardware_methods:
+            info_dict = {}
+            try:
+                info_dict = hardware_method()
+            except Exception as e:
+                log.warn("Hardware detection [%s] failed: %s" % (hardware_method.__name__, e))
+
+            all_hw_info.update(info_dict)
+
+        return all_hw_info
+
+
+class StaticFactsCollector(FactsCollector):
+    def __init__(self, static_facts, **kwargs):
+        super(FactsCollector, self).__init__(**kwargs)
+        self.static_facts = static_facts
+
+    def get_all(self):
+        return self.static_facts
diff --git a/src/rhsmlib/facts/cpuinfo.py b/src/rhsmlib/facts/cpuinfo.py
new file mode 100644
index 0000000000..f778cd4405
--- /dev/null
+++ b/src/rhsmlib/facts/cpuinfo.py
@@ -0,0 +1,489 @@
+#
+# Read and parse /proc/cpuinfo
+#
+# Copyright (c) 2015 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+
+# needs to be able to provide a data object for each cpu blob and
+# for the system
+#
+# needs to be able to aggregate multiple cpu data objects and create
+# an exemplar cpuinfo  (ie, if we want to ignore cpus at different
+# speeds, this may be where)
+#
+# needs to work non-root if possible, possibly as a standalone module/cli
+#
+# Expect the info available in cpuinfo to very across arches, and across
+# kernel and cpu versions. Some arches have almost no info. Some have tons.
+# Some provide hex values, most decimal.
+#
+# Expect the field names to change often. Don't expect field names to
+# be unique.
+#
+# Expect some fields to disappear without warning at any oppurtunity
+# (This includes changing arch, version, kernel, os vendor. It also includes
+#  no reason at all. cpus can disappear. cpus can remove fields. they can
+#  reappear).
+#
+# Expect values of cpuinfo fields to change, somethings constantly. cpu speed
+# for example, can actually vary _every_ time it is read.
+#
+# GOTCHAS: the field names are non consistent across arches, and can conflict
+#          semantically.
+#
+#         surprise, some are not even one key: value per line (see s390x)
+#
+# context manager?
+# class CpuinfoFile()
+#     .read()
+#  handle io errors
+#
+# can take file like object or
+# class BaseParseCpuInfo()
+#
+# class FieldNameCanonicalizer()
+#  ie, convert 'model name' to model_name
+#  and 'proccesor' processor
+#  and 'Processor' to... seriously aarch64?
+#    ('Processor' and 'processor' fields...)
+#
+# class CpuInfo() the main interface class
+#     arch = None
+#     cpuinfo_class = None
+#     # avoid, count of cpus/sockets/etc
+#
+#
+# class X86_64():
+#
+# class S390X():
+#   with fun "multiple values per line"
+#
+# class Aarch64():
+#   with hex values and a system stanza
+#
+# class Ppc64():
+#    system stanza and system model
+# factory to init proper one based... uname.machine? 'arch' file?
+
+import collections
+import itertools
+import logging
+import os
+
+# mostly populated from the arm CPUID instruction
+# http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.ddi0432c/Bhccjgga.html
+# http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.ddi0432c/Chdeaeij.html
+#
+# aarch "version" info
+# CPU implementer : 0x50
+# CPU architecture: AArch64
+# CPU variant : 0x0
+# CPU part    : 0x000
+# CPU revision    : 0
+
+# Mostly info from intel CPUID instruction
+# http://en.wikipedia.org/wiki/CPUID
+#
+# intel "version" info
+# processor   : 22
+# vendor_id   : GenuineIntel
+# cpu family  : 6
+# model       : 45
+# model name  : Intel(R) Xeon(R) CPU E5-2630 0 @ 2.30GHz
+# stepping    : 7
+# microcode   : 0x710
+
+log = logging.getLogger('rhsm-app.' + __name__)
+
+
+class DefaultCpuFields(object):
+    """Maps generic cpuinfo fields to the corresponding field from ProcessorModel.
+
+    For, a cpu MODEL (a number or string that the cpu vendor assigns to that model of
+    cpu, '45' for an intel Xeon for example)
+    is in the 'model' field in /proc/cpuinfo, and the
+    'model' in the sluggified field in X86_64ProcessorModel. For aarch64,
+    the field 'cpu_part' is it's MODEL.
+    """
+    MODEL_NAME = "model_name"
+    MODEL = "model"
+
+
+class X86_64Fields(object):
+    MODEL_NAME = 'model_name'
+    MODEL = 'model'
+
+
+class Aarch64Fields(object):
+    MODEL = 'cpu_part'
+    MODEL_NAME = 'model_name'
+
+
+class Ppc64Fields(object):
+    MODEL = 'model'
+    MODEL_NAME = 'machine'
+
+
+# represent the data in /proc/cpuinfo, which may include multiple processors
+class CpuinfoModel(object):
+    fields_class = DefaultCpuFields
+
+    def __init__(self, cpuinfo_data=None):
+        # The contents of /proc/cpuinfo
+        self.cpuinfo_data = cpuinfo_data
+
+        # A iterable of CpuInfoModels, one for each processor in cpuinfo
+        self.processors = []
+
+        # prologues or footnotes not associated with a particular processor
+        self.other = []
+
+        # If were going to pretend all the cpus are the same,
+        # what do they all have in common.
+        self.common = {}
+
+        # model name    : Intel(R) Core(TM) i5 CPU       M 560  @ 2.67GHz
+        self._model_name = None
+
+        # a model number
+        # "45" for intel processor example above
+        self._model = None
+
+    @property
+    def count(self):
+        return len(self.processors)
+
+    @property
+    def model_name(self):
+        if self._model_name:
+            return self._model_name
+
+        if not self.common:
+            return None
+
+        return self.common.get(self.fields_class.MODEL_NAME, None)
+
+    @property
+    def model(self):
+        if self._model:
+            return self._model
+
+        if not self.common:
+            return None
+
+        return self.common.get(self.fields_class.MODEL, None)
+
+    def __str__(self):
+        lines = []
+        lines.append("Processor count: %s" % self.count)
+        lines.append('model_name: %s' % self.model_name)
+        lines.append("")
+        for k in sorted(self.common.keys()):
+            lines.append("%s: %s" % (k, self.common[k]))
+        lines.append("")
+        for k, v in self.other:
+            lines.append("%s: %s" % (k, v))
+        lines.append("")
+        return "\n".join(lines)
+
+
+class Aarch64ProcessorModel(dict):
+    "The info corresponding to the info about each aarch64 processor entry in cpuinfo"
+    pass
+
+
+class X86_64ProcessorModel(dict):
+    "The info corresponding to the info about each X86_64 processor entry in cpuinfo"
+    pass
+
+
+class Ppc64ProcessorModel(dict):
+    "The info corresponding to the info about each ppc64 processor entry in cpuinfo"
+    @classmethod
+    def from_stanza(cls, stanza):
+        cpu_data = cls()
+        cpu_data.update(dict([fact_sluggify_item(item) for item in stanza]))
+        return cpu_data
+
+
+class X86_64CpuinfoModel(CpuinfoModel):
+    """The model for all the cpuinfo data for all processors on the machine.
+
+    ie, all the data in /proc/cpuinfo field as opposed to X86_64ProcessModel which
+    is the info for 1 processor."""
+    fields_class = X86_64Fields
+
+
+class Ppc64CpuinfoModel(CpuinfoModel):
+    fields_class = Ppc64Fields
+
+
+class Aarch64CpuinfoModel(CpuinfoModel):
+    fields_class = Aarch64Fields
+
+
+def fact_sluggify(key):
+    """Encodes an arbitrary string to something that can be used as a fact name.
+
+    ie, 'model_name' instead of 'Model name'
+    whitespace -> _
+    lowercase
+    utf8
+    escape quotes
+
+    In theory, any utf8 would work
+    """
+    # yeah, terrible...
+    return key.lower().strip().replace(' ', '_').replace('.', '_')
+
+
+def fact_sluggify_item(item_tuple):
+    newkey = fact_sluggify(item_tuple[0])
+    return (newkey, item_tuple[1])
+
+
+def split_key_value_generator(file_contents, line_splitter):
+    for line in file_contents.splitlines():
+        parts = line_splitter(line)
+        if parts:
+            yield parts
+
+
+def line_splitter(line):
+    # cpu family    : 6
+    # model name    : Intel(R) Core(TM) i5 CPU       M 560  @ 2.67GHz
+    parts = line.split(':', 1)
+    if parts[0]:
+        parts = [part.strip() for part in parts]
+        return parts
+    return None
+
+
+def accumulate_fields(fields_accum, fields):
+    for field in fields:
+        fields_accum.add(field)
+    return fields_accum
+
+
+def find_shared_key_value_pairs(all_fields, processors):
+    # smashem, last one wins
+    smashed = collections.defaultdict(set)
+
+    # build a dict of fieldname -> list of all the different values
+    # so we can dump the variant ones.
+    for field in all_fields:
+        for k, v in [(field, processor.get(field)) for processor in processors]:
+            if v is None:
+                continue
+            smashed[k].add(v)
+
+    # remove fields that can't be smashed to one value
+    common_cpu_info = dict([(x, smashed[x].pop()) for x in smashed if len(smashed[x]) == 1])
+    return common_cpu_info
+
+
+def split_kv_list_by_field(kv_list, field):
+    """Split the iterable kv_list into chunks by field.
+
+    For a list with repeating stanzas in it, this will
+    return a generate that will return each chunk.
+
+    For something like /proc/cpuinfo, called with
+    field 'processor', each stanza is a different cpu.
+    """
+    current_stanza = None
+    for key, value in kv_list:
+        if key == field:
+            if current_stanza:
+                yield current_stanza
+            current_stanza = [(key, value)]
+            continue
+
+        # if we have garbage in and no start to processor info
+        if current_stanza:
+            current_stanza.append((key, value))
+
+    # end of kv_list
+    if current_stanza:
+        yield current_stanza
+
+"""
+Processor   : AArch64 Processor rev 0 (aarch64)
+processor   : 0
+processor   : 1
+processor   : 2
+processor   : 3
+processor   : 4
+processor   : 5
+processor   : 6
+processor   : 7
+Features    : fp asimd evtstrm
+CPU implementer : 0x50
+CPU architecture: AArch64
+CPU variant : 0x0
+CPU part    : 0x000
+CPU revision    : 0
+
+Hardware    : APM X-Gene Mustang board
+"""
+
+
+class BaseCpuInfo(object):
+    @classmethod
+    def from_proc_cpuinfo_string(cls, proc_cpuinfo_string):
+        """Return a BaseCpuInfo subclass based on proc_cpuinfo_string.
+
+        proc_cpuinfo_string is the string resulting from reading
+        the entire contents of /proc/cpuinfo."""
+        cpu_info = cls()
+        cpu_info._parse(proc_cpuinfo_string)
+
+        return cpu_info
+
+
+class Aarch64CpuInfo(BaseCpuInfo):
+    def __init__(self):
+        self.cpu_info = Aarch64CpuinfoModel()
+
+    def _parse(self, cpuinfo_data):
+        raw_kv_iter = split_key_value_generator(cpuinfo_data, line_splitter)
+
+        # Yes, there is a 'Processor' field and multiple lower case 'processor'
+        # fields.
+        kv_iter = (self._capital_processor_to_model_name(item)
+                   for item in raw_kv_iter)
+
+        slugged_kv_list = [fact_sluggify_item(item) for item in kv_iter]
+
+        # kind of duplicated
+        self.cpu_info.common = self.gather_cpu_info_model(slugged_kv_list)
+        self.cpu_info.processors = self.gather_processor_list(slugged_kv_list)
+
+        # For now, 'hardware' is per
+        self.cpu_info.other = self.gather_cpu_info_other(slugged_kv_list)
+
+    def _capital_processor_to_model_name(self, item):
+        """Use the uppercase Processor field value as the model name.
+
+        For aarch64, the 'Processor' field is the closest to model name,
+        so we sub it in now."""
+        if item[0] == 'Processor':
+            item[0] = "model_name"
+        return item
+
+    def gather_processor_list(self, kv_list):
+        processor_list = []
+        for k, v in kv_list:
+            if k != 'processor':
+                continue
+            # build a ProcessorModel subclass for each processor
+            # to add to CpuInfoModel.processors list
+            cpu_info_model = self.gather_cpu_info_model(kv_list)
+            cpu_info_model['processor'] = v
+            processor_list.append(cpu_info_model)
+        return processor_list
+
+    # FIXME: more generic would be to split the stanzas by empty lines in the
+    # first pass
+    def gather_cpu_info_other(self, kv_list):
+        other_list = []
+        for k, v in kv_list:
+            if k == 'hardware':
+                other_list.append([k, v])
+        return other_list
+
+    def gather_cpu_info_model(self, kv_list):
+        cpu_data = Aarch64ProcessorModel()
+        for k, v in kv_list:
+            if k == 'processor' or k == 'hardware':
+                continue
+            cpu_data[k] = v
+        return cpu_data
+
+
+class X86_64CpuInfo(BaseCpuInfo):
+    def __init__(self):
+        self.cpu_info = X86_64CpuinfoModel()
+
+    def _parse(self, cpuinfo_data):
+        # ordered list
+        kv_iter = split_key_value_generator(cpuinfo_data, line_splitter)
+
+        processors = []
+        all_fields = set()
+        for processor_stanza in split_kv_list_by_field(kv_iter, 'processor'):
+            proc_dict = self.processor_stanza_to_processor_data(processor_stanza)
+            processors.append(proc_dict)
+            # keep track of fields as we see them
+            all_fields = accumulate_fields(all_fields, proc_dict.keys())
+
+        self.cpu_info.common = find_shared_key_value_pairs(all_fields, processors)
+        self.cpu_info.processors = processors
+        self.cpu_info.cpuinfo_data = cpuinfo_data
+
+    def processor_stanza_to_processor_data(self, stanza):
+        "Take a list of k,v tuples, sluggify name, and add to a dict."
+        cpu_data = X86_64ProcessorModel()
+        cpu_data.update(dict([fact_sluggify_item(item) for item in stanza]))
+        return cpu_data
+
+
+class Ppc64CpuInfo(BaseCpuInfo):
+    def __init__(self):
+        self.cpu_info = Ppc64CpuinfoModel()
+
+    def _parse(self, cpuinfo_data):
+        kv_iter = split_key_value_generator(cpuinfo_data, line_splitter)
+
+        processor_iter = itertools.takewhile(self._not_timebase_key, kv_iter)
+        for processor_stanza in split_kv_list_by_field(processor_iter, 'processor'):
+            proc_dict = Ppc64ProcessorModel.from_stanza(processor_stanza)
+            self.cpu_info.processors.append(proc_dict)
+
+        # Treat the rest of the info as shared between all of the processor entries
+        # kv_iter is the rest of cpuinfo that isn't processor stanzas
+        self.cpu_info.common = dict([fact_sluggify_item(item) for item in kv_iter])
+        self.cpu_info.cpuinfo_data = cpuinfo_data
+
+    def _not_timebase_key(self, item):
+        return item[0] != 'timebase'
+
+
+class SystemCpuInfoFactory(object):
+    uname_to_cpuinfo = {'x86_64': X86_64CpuInfo,
+                        'aarch64': Aarch64CpuInfo,
+                        'ppc64': Ppc64CpuInfo,
+                        'ppc64le': Ppc64CpuInfo}
+    proc_cpuinfo_path = '/proc/cpuinfo'
+
+    @classmethod
+    def from_uname_machine(cls, uname_machine, prefix=None):
+        if uname_machine not in SystemCpuInfoFactory.uname_to_cpuinfo:
+            # er?
+            raise NotImplementedError
+
+        proc_cpuinfo_string = cls.open_proc_cpuinfo(prefix)
+
+        arch_class = cls.uname_to_cpuinfo[uname_machine]
+        return arch_class.from_proc_cpuinfo_string(proc_cpuinfo_string)
+
+    @classmethod
+    def open_proc_cpuinfo(cls, prefix=None):
+        proc_cpuinfo_path = cls.proc_cpuinfo_path
+        if prefix:
+            proc_cpuinfo_path = os.path.join(prefix, cls.proc_cpuinfo_path[1:])
+        proc_cpuinfo_buf = ''
+        with open(proc_cpuinfo_path, 'r') as proc_cpuinfo_f:
+            proc_cpuinfo_buf = proc_cpuinfo_f.read()
+        return proc_cpuinfo_buf
diff --git a/src/rhsmlib/facts/custom.py b/src/rhsmlib/facts/custom.py
new file mode 100644
index 0000000000..39fc6728fd
--- /dev/null
+++ b/src/rhsmlib/facts/custom.py
@@ -0,0 +1,113 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import os
+import glob
+import logging
+
+from rhsm import ourjson
+from rhsmlib.facts.collector import FactsCollector
+
+log = logging.getLogger(__name__)
+
+
+class CustomFacts(object):
+    def __init__(self, data=None):
+        self.data = data
+
+    @classmethod
+    def from_json(cls, json_blob):
+        custom_facts = cls
+
+        try:
+            data = ourjson.loads(json_blob)
+        except ValueError:
+            log.warn("Unable to load custom facts file.")
+
+        custom_facts.data = data
+        return custom_facts
+
+    def __iter__(self):
+        return iter(self.data.items())
+
+
+class CustomFactsFileError(Exception):
+    pass
+
+
+class CustomFactsFile(object):
+    def __init__(self, path=None):
+        self.path = path
+        self.buf = None
+
+    def _open_and_read(self):
+        try:
+            with open(self.path, 'r') as fd:
+                return fd.read()
+        except IOError:
+            log.warn("Unable to open custom facts file: %s" % self.path)
+            raise
+
+    def read(self):
+        custom_facts_data = self._open_and_read()
+        return custom_facts_data
+
+    def close(self):
+        pass
+
+
+class CustomFactsDirectory(object):
+    def __init__(self, path=None, glob_pattern=None):
+        self.path = path
+        self.glob_pattern = glob_pattern
+
+    def fact_file_path_iterator(self):
+        facts_file_glob = os.path.join(self.path, self.glob_pattern)
+        return glob.iglob(facts_file_glob)
+
+    def fact_file_iterator(self, fact_file_path_iterator):
+        for fact_file_path in fact_file_path_iterator:
+            log.info("Loading custom facts from: %s" % fact_file_path)
+            yield CustomFactsFile(fact_file_path)
+
+    def __iter__(self):
+        for fact_file in self.fact_file_iterator(self.fact_file_path_iterator()):
+            yield CustomFacts.from_json(fact_file.read())
+
+
+class CustomFactsDirectories(object):
+    def __init__(self, path_and_globs):
+        self.path_and_globs = path_and_globs
+
+    def __iter__(self):
+        for path, glob_pattern in self.path_and_globs:
+            yield CustomFactsDirectory(path, glob_pattern)
+
+
+class CustomFactsCollector(FactsCollector):
+    def __init__(self, prefix=None, testing=None, collected_hw_info=None,
+                 path_and_globs=None):
+        super(CustomFactsCollector, self).__init__(
+            prefix=prefix,
+            testing=testing,
+            collected_hw_info=collected_hw_info
+        )
+        self.path_and_globs = path_and_globs
+        self.facts_directories = CustomFactsDirectories(self.path_and_globs)
+
+    def get_all(self):
+        facts_dict = {}
+        for facts_dir in self.facts_directories:
+            for custom_facts in facts_dir:
+                facts_dict.update(custom_facts.data)
+        return facts_dict
diff --git a/src/rhsmlib/facts/dmiinfo.py b/src/rhsmlib/facts/dmiinfo.py
new file mode 100644
index 0000000000..8a53a5ac8e
--- /dev/null
+++ b/src/rhsmlib/facts/dmiinfo.py
@@ -0,0 +1,119 @@
+# Copyright (c) 2010-2013 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+"""Load and collect DMI data.
+
+Note: This module will fail to import if dmidecode fails to import.
+      firmware_info.py expects that and handles it, and any other
+      module that imports it should handle an import error as well."""
+
+import gettext
+import logging
+import os
+
+log = logging.getLogger(__name__)
+
+try:
+    import dmidecode
+except ImportError:
+    log.warn("Unable to load dmidecode module. No DMI info will be collected")
+    raise
+
+from rhsmlib.facts import collector
+
+_ = gettext.gettext
+
+FIRMWARE_DUMP_FILENAME = "dmi.dump"
+
+
+class DmiFirmwareInfoCollector(collector.FactsCollector):
+    def __init__(self, prefix=None, testing=None, collected_hw_info=None):
+        super(DmiFirmwareInfoCollector, self).__init__(
+            prefix=prefix,
+            testing=testing,
+            collected_hw_info=collected_hw_info
+        )
+
+        self._socket_designation = []
+        self._socket_counter = 0
+
+        self.dump_file = None
+        if testing and prefix:
+            self.dump_file = os.path.join(prefix, FIRMWARE_DUMP_FILENAME)
+            self.use_dump_file()
+
+    def use_dump_file(self):
+        """Set this instances to use a dmidecode dump file.
+
+        WARNING: This involves settings a module global
+        attribute in 'dmidecode', not just for this class
+        or object, but for the lifetime of the dmidecode module.
+
+        To 'unset' it, it can be set back to '/dev/mem', or
+        re set it to another dump file."""
+        if os.access(self.dump_file, os.R_OK):
+            dmidecode.set_dev(self.dump_file)
+
+    # This needs all of the previously collected hwinfo, so it can decide
+    # what is bogus enough that the DMI info is better.
+    def get_all(self):
+        dmiinfo = {}
+        dmi_data = {
+            "dmi.bios.": self._read_dmi(dmidecode.bios),
+            "dmi.processor.": self._read_dmi(dmidecode.processor),
+            "dmi.baseboard.": self._read_dmi(dmidecode.baseboard),
+            "dmi.chassis.": self._read_dmi(dmidecode.chassis),
+            "dmi.slot.": self._read_dmi(dmidecode.slot),
+            "dmi.system.": self._read_dmi(dmidecode.system),
+            "dmi.memory.": self._read_dmi(dmidecode.memory),
+            "dmi.connector.": self._read_dmi(dmidecode.connector),
+        }
+
+        try:
+            for tag, func in dmi_data.items():
+                dmiinfo = self._get_dmi_data(func, tag, dmiinfo)
+        except Exception as e:
+            log.warn(_("Error reading system DMI information: %s"), e)
+
+        return dmiinfo
+
+    def _read_dmi(self, func):
+        try:
+            return func()
+        except Exception as e:
+            log.warn(_("Error reading system DMI information with %s: %s"), func, e)
+            return None
+
+    def _get_dmi_data(self, func, tag, ddict):
+        for key, value in func.items():
+            for key1, value1 in value['data'].items():
+                # FIXME: this loses useful data...
+                if not isinstance(value1, str):
+                    # we are skipping things like int and bool values, as
+                    # well as lists and dicts
+                    continue
+
+                # keep track of any cpu socket info we find, we have to do
+                # it here, since we flatten it and lose the info creating nkey
+                if tag == 'dmi.processor.' and key1 == 'Socket Designation':
+                    self._socket_designation.append(value1)
+
+                nkey = ''.join([tag, key1.lower()]).replace(" ", "_")
+                ddict[nkey] = str(value1)
+
+        # Populate how many socket descriptions we saw in a faux-fact, so we can
+        # use it to munge lscpu info later if needed.
+        if self._socket_designation:
+            ddict['dmi.meta.cpu_socket_count'] = str(len(self._socket_designation))
+
+        return ddict
diff --git a/src/rhsmlib/facts/firmware_info.py b/src/rhsmlib/facts/firmware_info.py
new file mode 100644
index 0000000000..2b4db58b69
--- /dev/null
+++ b/src/rhsmlib/facts/firmware_info.py
@@ -0,0 +1,111 @@
+#
+# Get the right platform specific provider or a null provider
+#
+# Copyright (c) 2010-2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import logging
+
+# The dmiinfo module will raise a ImportError if the 'dmidecode' module
+# fails to import. So expect that.
+try:
+    from rhsmlib.facts import dmiinfo
+except ImportError as e:
+    dmiinfo = None
+
+from rhsmlib.facts import collector
+
+ARCHES_WITHOUT_DMI = ["ppc64", "ppc64le", "s390x"]
+
+log = logging.getLogger(__name__)
+
+
+# This doesn't really do anything other than provide a null/noop provider for
+# non-DMI platforms.
+class NullFirmwareInfoCollector(object):
+    """Default provider for platform without a specific platform info provider.
+
+    ie, all platforms except those with DMI (ie, intel platforms)"""
+    def __init__(self, *args, **kwargs):
+        self.info = {}
+
+    def get_all(self):
+        return self.info
+
+
+class FirmwareCollector(collector.FactsCollector):
+    def __init__(self, prefix=None, testing=None, collected_hw_info=None):
+        super(FirmwareCollector, self).__init__(
+            prefix=prefix,
+            testing=testing,
+            collected_hw_info=collected_hw_info
+        )
+
+    def get_firmware_info(self):
+        """Read and parse data that comes from platform specific interfaces.
+
+        This is only dmi/smbios data for now (which isn't on ppc/s390).
+        """
+        firmware_info_collector = get_firmware_collector(
+            arch=self.arch,
+            prefix=self.prefix,
+            testing=self.testing
+        )
+
+        # Pass in collected hardware so DMI etc can potentially override it
+        firmware_info_dict = firmware_info_collector.get_all()
+        # This can potentially clobber facts that already existed in self.allhw
+        # (and is supposed to).
+        return firmware_info_dict
+
+    def get_all(self):
+        virt_info = {}
+        firmware_info = self.get_firmware_info()
+
+        virt_info.update(firmware_info)
+        return virt_info
+
+
+# TODO/FIXME: As a first pass, move dmi and the generic firmware code here,
+#             even though with kernels with sysfs dmi support, and a recent
+#             version of dmidecode (> 3.0), most of the dmi info is readable
+#             by a user. However, the system-uuid is not readable by a user,
+#             and that is pretty much the only thing from DMI we care about,
+def get_firmware_collector(arch, prefix=None, testing=None,
+                           collected_hw_info=None):
+    """
+    Return a class that can be used to get firmware info specific to
+    this systems platform.
+
+    ie, DmiFirmwareInfoProvider on intel platforms, and a
+    NullFirmwareInfoProvider otherwise.
+    """
+    # we could potential consider /proc/sysinfo as a FirmwareInfoProvider
+    # but at the moment, it is just firmware/dmi stuff.
+
+    if arch in ARCHES_WITHOUT_DMI:
+        log.debug("Not looking for DMI info since it is not available on '%s'" % arch)
+        firmware_provider_class = NullFirmwareInfoCollector
+    else:
+        if dmiinfo:
+            firmware_provider_class = dmiinfo.DmiFirmwareInfoCollector
+        else:
+            firmware_provider_class = NullFirmwareInfoCollector
+
+    firmware_provider = firmware_provider_class(
+        prefix=prefix,
+        testing=testing,
+        collected_hw_info=collected_hw_info
+    )
+
+    return firmware_provider
diff --git a/src/rhsmlib/facts/host_collector.py b/src/rhsmlib/facts/host_collector.py
new file mode 100644
index 0000000000..1974ea507e
--- /dev/null
+++ b/src/rhsmlib/facts/host_collector.py
@@ -0,0 +1,105 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import os
+
+import rhsm.config
+
+from rhsmlib.facts import hwprobe
+from rhsmlib.facts import cleanup
+from rhsmlib.facts import custom
+from rhsmlib.facts import virt
+from rhsmlib.facts import firmware_info
+
+
+from rhsmlib.facts import collector
+
+
+class HostCollector(collector.FactsCollector):
+    """Collect facts for a host system.
+
+    'host' in this case means approx something running
+    a single kernel image. ie, regular x86_64 hardware, a KVM
+    virt guest, a ppc64 lpar guest. And not a cluster, or
+    a container, or an installroot/chroot/mock, or an application,
+    or a data center, or a distributed computing framework, or
+    a non-linux hypervisor, etc.
+
+    This in turns runs:
+        hwprobe.HardwareCollector()      [regular hardware facts]
+        virt.VirtCollector()    [virt facts, results from virt-what etc]
+        firmware_info.FirmwareCollector()  [dmiinfo, devicetree, etc]
+        cleanup.CleanupCollector()  [Collapse redundant facts, alter any
+                                     facts that depend on output of other facts, etc]
+
+
+    Facts collected include DMI info and virt status and virt.uuid."""
+
+    facts_sub_dir = 'facts'
+    facts_glob = '*.facts'
+
+    def get_all(self):
+        host_facts = {}
+        hardware_collector = hwprobe.HardwareCollector(
+            prefix=self.prefix,
+            testing=self.testing,
+            collected_hw_info=self._collected_hw_info
+        )
+        hardware_info = hardware_collector.get_all()
+
+        virt_collector = virt.VirtCollector(
+            prefix=self.prefix,
+            testing=self.testing,
+            collected_hw_info=self._collected_hw_info
+        )
+
+        virt_collector_info = virt_collector.get_all()
+
+        firmware_collector = firmware_info.FirmwareCollector(
+            prefix=self.prefix,
+            testing=self.testing,
+            collected_hw_info=virt_collector_info
+        )
+
+        # rename firmware.py
+        firmware_info_dict = firmware_collector.get_all()
+
+        host_facts.update(hardware_info)
+        host_facts.update(virt_collector_info)
+        host_facts.update(firmware_info_dict)
+
+        default_rhsm_dir = rhsm.config.DEFAULT_CONFIG_DIR.rstrip('/')
+        custom_facts_dir = os.path.join(default_rhsm_dir, self.facts_sub_dir)
+        path_and_globs = [(custom_facts_dir, self.facts_glob)]
+
+        custom_facts = custom.CustomFactsCollector(
+            prefix=self.prefix,
+            testing=self.testing,
+            collected_hw_info=self._collected_hw_info,
+            path_and_globs=path_and_globs
+        )
+        custom_facts_dict = custom_facts.get_all()
+        host_facts.update(custom_facts_dict)
+
+        # Now, munging, kluges, special cases, etc
+        # NOTE: we are passing the facts we've already collected into
+        # cleanup_collector.
+        cleanup_collector = cleanup.CleanupCollector(
+            prefix=self.prefix,
+            testing=self.testing,
+            collected_hw_info=host_facts
+        )
+        cleanup_info = cleanup_collector.get_all()
+
+        host_facts.update(cleanup_info)
+        return host_facts
diff --git a/src/rhsmlib/facts/hwprobe.py b/src/rhsmlib/facts/hwprobe.py
new file mode 100644
index 0000000000..70b2f24abf
--- /dev/null
+++ b/src/rhsmlib/facts/hwprobe.py
@@ -0,0 +1,778 @@
+#
+# Module to probe Hardware info from the system
+#
+# Copyright (c) 2010 Red Hat, Inc.
+#
+# Authors: Pradeep Kilambi <pkilambi@redhat.com>
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+from __future__ import print_function
+
+import gettext
+import logging
+import os
+import platform
+import re
+import socket
+import sys
+
+from rhsmlib.facts import cpuinfo
+from rhsmlib.facts import collector
+
+_ = gettext.gettext
+
+log = logging.getLogger(__name__)
+
+# There is no python3 version of python-ethtool
+ethtool = None
+try:
+    import ethtool
+except ImportError as e:
+    log.warn("Unable to import the 'ethtool' module.")
+
+# For python2.6 that doesn't have subprocess.check_output
+from rhsmlib.compat import check_output as compat_check_output
+from subprocess import CalledProcessError
+
+
+class ClassicCheck:
+    def is_registered_with_classic(self):
+        try:
+            sys.path.append('/usr/share/rhn')
+            from up2date_client import up2dateAuth
+        except ImportError:
+            return False
+
+        return up2dateAuth.getSystemId() is not None
+
+
+# take a string like '1-4' and returns a list of
+# ints like [1,2,3,4]
+# 31-37 return [31,32,33,34,35,36,37]
+def parse_range(range_str):
+    range_list = range_str.split('-')
+    start = int(range_list[0])
+    end = int(range_list[-1])
+
+    return range(start, end + 1)
+
+
+# util to total up the values represented by a cpu siblings list
+# ala /sys/devices/cpu/cpu0/topology/core_siblings_list
+#
+# which can be a comma separated list of ranges
+#  1,2,3,4
+#  1-2, 4-6, 8-10, 12-14
+#
+def gather_entries(entries_string):
+    entries = []
+    entry_parts = entries_string.split(',')
+    for entry_part in entry_parts:
+        # return a list of enumerated items
+        entry_range = parse_range(entry_part)
+        for entry in entry_range:
+            entries.append(entry)
+    return entries
+
+
+class GenericPlatformSpecificInfoProvider(object):
+    """Default provider for platform without a specific platform info provider.
+
+    ie, all platforms except those with DMI (ie, intel platforms)"""
+    def __init__(self, hardware_info, dump_file=None):
+        self.info = {}
+
+    @staticmethod
+    def log_warnings():
+        pass
+
+
+class HardwareCollector(collector.FactsCollector):
+
+    def __init__(self, arch=None, prefix=None, testing=None,
+                 collected_hw_info=None):
+        super(HardwareCollector, self).__init__(arch=arch, prefix=prefix,
+                                       testing=testing,
+                                       collected_hw_info=None)
+
+        self.hardware_methods = [
+            self.get_uname_info,
+            self.get_release_info,
+            self.get_mem_info,
+            self.get_proc_cpuinfo,
+            self.get_cpu_info,
+            self.get_ls_cpu_info,
+            self.get_network_info,
+            self.get_network_interfaces,
+        ]
+
+    def get_uname_info(self):
+        uname_info = {}
+        uname_data = os.uname()
+        uname_keys = (
+            'uname.sysname',
+            'uname.nodename',
+            'uname.release',
+            'uname.version',
+            'uname.machine',
+        )
+        uname_info = dict(zip(uname_keys, uname_data))
+        return uname_info
+
+    def get_release_info(self):
+        distro_info = self.get_distribution()
+        release_info = {
+            'distribution.name': distro_info[0],
+            'distribution.version': distro_info[1],
+            'distribution.id': distro_info[2],
+            'distribution.version.modifier': distro_info[3],
+        }
+        return release_info
+
+    def _open_release(self, filename):
+        return open(filename, 'r')
+
+    # this version os very RHEL/Fedora specific...
+    def get_distribution(self):
+
+        version = 'Unknown'
+        distname = 'Unknown'
+        dist_id = 'Unknown'
+        version_modifier = ''
+
+        if os.path.exists('/etc/os-release'):
+            f = open('/etc/os-release', 'r')
+            os_release = f.readlines()
+            f.close()
+            data = {
+                'PRETTY_NAME': 'Unknown',
+                'NAME': distname,
+                'ID': 'Unknown',
+                'VERSION': dist_id,
+                'VERSION_ID': version,
+                'CPE_NAME': 'Unknown',
+            }
+            for line in os_release:
+                split = map(lambda piece: piece.strip('"\n '), line.split('='))
+                if len(split) != 2:
+                    continue
+                data[split[0]] = split[1]
+
+            version = data['VERSION_ID']
+            distname = data['NAME']
+            dist_id = data['VERSION']
+            dist_id_search = re.search('\((.*?)\)', dist_id)
+            if dist_id_search:
+                dist_id = dist_id_search.group(1)
+            # Split on ':' that is not preceded by '\'
+            vers_mod_data = re.split('(?<!\\\):', data['CPE_NAME'])
+            if len(vers_mod_data) >= 6:
+                version_modifier = vers_mod_data[5].lower().replace('\\:', ':')
+        elif os.path.exists('/etc/redhat-release'):
+            # from platform.py from python2.
+            _lsb_release_version = re.compile(r'(.+) release ([\d.]+)\s*(?!\()(\S*)\s*[^(]*(?:\((.+)\))?')
+            f = self._open_release('/etc/redhat-release')
+            firstline = f.readline()
+            f.close()
+
+            m = _lsb_release_version.match(firstline)
+
+            if m is not None:
+                (distname, version, tmp_modifier, dist_id) = tuple(m.groups())
+                if tmp_modifier:
+                    version_modifier = tmp_modifier.lower()
+
+        elif hasattr(platform, 'linux_distribution'):
+            (distname, version, dist_id) = platform.linux_distribution()
+            version_modifier = 'Unknown'
+
+        return distname, version, dist_id, version_modifier
+
+    def get_mem_info(self):
+        meminfo = {}
+
+        # most of this mem info changes constantly, which makes decding
+        # when to update facts painful, so lets try to just collect the
+        # useful bits
+
+        useful = ["MemTotal", "SwapTotal"]
+        try:
+            parser = re.compile(r'^(?P<key>\S*):\s*(?P<value>\d*)\s*kB')
+            memdata = open('/proc/meminfo')
+            for info in memdata:
+                match = parser.match(info)
+                if not match:
+                    continue
+                key, value = match.groups(['key', 'value'])
+                if key in useful:
+                    nkey = '.'.join(["memory", key.lower()])
+                    meminfo[nkey] = "%s" % int(value)
+        except Exception as e:
+            log.warn("Error reading system memory information: %s", e)
+        return meminfo
+
+    def count_cpumask_entries(self, cpu, field):
+        try:
+            f = open("%s/topology/%s" % (cpu, field), 'r')
+        except IOError:
+            return None
+
+        # ia64 entries seem to be null padded, or perhaps
+        # that's a collection error
+        # FIXME
+        entries = f.read().rstrip('\n\x00')
+        f.close()
+        # these fields can exist, but be empty. For example,
+        # thread_siblings_list from s390x-rhel64-zvm-2cpu-has-topo
+        # test data
+
+        if len(entries):
+            cpumask_entries = gather_entries(entries)
+            return len(cpumask_entries)
+        # that field was empty
+        return None
+
+    # replace/add with getting CPU Totals for s390x
+    def _parse_s390x_sysinfo_topology(self, cpu_count, sysinfo):
+        # to quote lscpu.c:
+        # CPU Topology SW:      0 0 0 4 6 4
+        # /* s390 detects its cpu topology via /proc/sysinfo, if present.
+        # * Using simply the cpu topology masks in sysfs will not give
+        # * usable results since everything is virtualized. E.g.
+        # * virtual core 0 may have only 1 cpu, but virtual core 2 may
+        # * five cpus.
+        # * If the cpu topology is not exported (e.g. 2nd level guest)
+        # * fall back to old calculation scheme.
+        # */
+        for line in sysinfo:
+            if line.startswith("CPU Topology SW:"):
+                parts = line.split(':', 1)
+                s390_topo_str = parts[1]
+                topo_parts = s390_topo_str.split()
+
+                # indexes 3/4/5 being books/sockets_per_book,
+                # and cores_per_socket based on lscpu.c
+                book_count = int(topo_parts[3])
+                sockets_per_book = int(topo_parts[4])
+                cores_per_socket = int(topo_parts[5])
+
+                socket_count = book_count * sockets_per_book
+                cores_count = socket_count * cores_per_socket
+
+                return {
+                    'socket_count': socket_count,
+                    'cores_count': cores_count,
+                    'book_count': book_count,
+                    'sockets_per_book': sockets_per_book,
+                    'cores_per_socket': cores_per_socket
+                }
+        log.debug("Looking for 'CPU Topology SW' in sysinfo, but it was not found")
+        return None
+
+    def has_s390x_sysinfo(self, proc_sysinfo):
+        return os.access(proc_sysinfo, os.R_OK)
+
+    def read_s390x_sysinfo(self, cpu_count, proc_sysinfo):
+        lines = []
+        try:
+            f = open(proc_sysinfo, 'r')
+        except IOError:
+            return lines
+
+        lines = f.readlines()
+        f.close()
+        return lines
+
+    def read_physical_id(self, cpu_file):
+        try:
+            f = open("%s/physical_id" % cpu_file, 'r')
+        except IOError:
+            return None
+
+        buf = f.read().strip()
+        f.close()
+        return buf
+
+    def _ppc64_fallback(self, cpu_files):
+
+        # ppc64, particular POWER5/POWER6 machines, show almost
+        # no cpu information on rhel5. There is a "physical_id"
+        # associated with each cpu that seems to map to a
+        # cpu, in a socket
+        log.debug("trying ppc64 specific cpu topology detection")
+        # try to find cpuN/physical_id
+        physical_ids = set()
+        for cpu_file in cpu_files:
+            physical_id = self.read_physical_id(cpu_file)
+            # offline cpu's show physical id of -1. Normally
+            # we count all present cpu's even if offline, but
+            # in this case, we can't get any cpu info from the
+            # cpu since it is offline, so don't count it
+            if physical_id != '-1':
+                physical_ids.add(physical_id)
+
+        if physical_ids:
+            # For rhel6 or newer, we have more cpu topology info
+            # exposed by the kernel which will override this
+            socket_count = len(physical_ids)
+            # add marker here so we know we fail back to this
+            log.debug("Using /sys/devices/system/cpu/cpu*/physical_id for cpu info on ppc64")
+            return socket_count
+
+        return None
+
+    def check_for_cpu_topo(self, cpu_topo_dir):
+        return os.access(cpu_topo_dir, os.R_OK)
+
+    def get_proc_cpuinfo(self):
+        proc_cpuinfo = {}
+        fact_namespace = 'proc_cpuinfo'
+
+        proc_cpuinfo_source = cpuinfo.SystemCpuInfoFactory.from_uname_machine(
+            self.arch,
+            prefix=self.prefix
+        )
+
+        for key, value in proc_cpuinfo_source.cpu_info.common.items():
+            proc_cpuinfo['%s.common.%s' % (fact_namespace, key)] = value
+
+        # NOTE: cpu_info.other is a potentially ordered non-uniq list, so may
+        # not make sense for shoving into a list.
+        for key, value in proc_cpuinfo_source.cpu_info.other:
+            proc_cpuinfo['%s.system.%s' % (fact_namespace, key)] = value
+
+        # we could enumerate each processor here as proc_cpuinfo.cpu.3.key =
+        # value, but that is a lot of fact table entries
+        return proc_cpuinfo
+
+    def get_cpu_info(self):
+        cpu_info = {}
+        # we also have cpufreq, etc in this dir, so match just the numbs
+        cpu_re = r'cpu([0-9]+$)'
+
+        cpu_files = []
+        sys_cpu_path = self.prefix + "/sys/devices/system/cpu/"
+        for cpu in os.listdir(sys_cpu_path):
+            if re.match(cpu_re, cpu):
+                cpu_topo_dir = os.path.join(sys_cpu_path, cpu, "topology")
+
+                # see rhbz#1070908
+                # ppc64 machines running on LPARs will add
+                # a sys cpu entry for every cpu thread on the
+                # physical machine, regardless of how many are
+                # allocated to the LPAR. This throws off the cpu
+                # thread count, which throws off the cpu socket count.
+                # The entries for the unallocated or offline cpus
+                # do not have topology info however.
+                # So, skip sys cpu entries without topology info.
+                #
+                # NOTE: this assumes RHEL6+, prior to rhel5, on
+                # some arches like ppc and s390, there is no topology
+                # info ever, so this will break.
+                if self.check_for_cpu_topo(cpu_topo_dir):
+                    cpu_files.append("%s/%s" % (sys_cpu_path, cpu))
+
+        # for systems with no cpus
+        if not cpu_files:
+            return cpu_info
+
+        cpu_count = len(cpu_files)
+
+        # see if we have a /proc/sysinfo ala s390, if so
+        # prefer that info
+        proc_sysinfo = self.prefix + "/proc/sysinfo"
+        has_sysinfo = self.has_s390x_sysinfo(proc_sysinfo)
+
+        # s390x can have cpu 'books'
+        books = False
+
+        cores_per_socket = None
+
+        # assume each socket has the same number of cores, and
+        # each core has the same number of threads.
+        #
+        # This is not actually true sometimes... *cough*s390x*cough*
+        # but lscpu makes the same assumption
+
+        threads_per_core = self.count_cpumask_entries(cpu_files[0], 'thread_siblings_list')
+        cores_per_cpu = self.count_cpumask_entries(cpu_files[0], 'core_siblings_list')
+
+        # if we find valid values in cpu/cpuN/topology/*siblings_list
+        # sometimes it's not there, particularly on rhel5
+        if threads_per_core and cores_per_cpu:
+            cores_per_socket = cores_per_cpu / threads_per_core
+            cpu_info["cpu.topology_source"] = "kernel /sys cpu sibling lists"
+
+            # rhel6 s390x can have /sys cpu topo, but we can't make assumption
+            # about it being evenly distributed, so if we also have topo info
+            # in sysinfo, prefer that
+            if self.arch == "s390x" and has_sysinfo:
+                # for s390x on lpar, try to see if /proc/sysinfo has any
+                # topo info
+                log.debug("/proc/sysinfo found, attempting to gather cpu topology info")
+                sysinfo_lines = self.read_s390x_sysinfo(cpu_count, proc_sysinfo)
+                if sysinfo_lines:
+                    sysinfo = self._parse_s390x_sysinfo_topology(cpu_count, sysinfo_lines)
+
+                    # verify the sysinfo has system level virt info
+                    if sysinfo:
+                        cpu_info["cpu.topology_source"] = "s390x sysinfo"
+                        socket_count = sysinfo['socket_count']
+                        book_count = sysinfo['book_count']
+                        sockets_per_book = sysinfo['sockets_per_book']
+                        cores_per_socket = sysinfo['cores_per_socket']
+                        threads_per_core = 1
+
+                        # we can have a mismatch between /sys and /sysinfo. We
+                        # defer to sysinfo in this case even for cpu_count
+                        # cpu_count = sysinfo['cores_count'] * threads_per_core
+                        books = True
+
+        else:
+            # we have found no valid socket information, I only know
+            # the number of cpu's, but no threads, no cores, no sockets
+            log.debug("No cpu socket information found")
+
+            # how do we get here?
+            #   no cpu topology info, ala s390x on rhel5,
+            #   no sysinfo topology info, ala s390x with zvm on rhel5
+            # we have no great topo info here,
+            # assume each cpu thread = 1 core = 1 socket
+            threads_per_core = 1
+            cores_per_cpu = 1
+            cores_per_socket = 1
+            socket_count = None
+
+            # lets try some arch/platform specific approaches
+            if self.arch == "ppc64":
+                socket_count = self._ppc64_fallback(cpu_files)
+
+                if socket_count:
+                    log.debug("Using ppc64 cpu physical id for cpu topology info")
+                    cpu_info["cpu.topology_source"] = "ppc64 physical_package_id"
+
+            else:
+                # all of our usual methods failed us...
+                log.debug("No cpu socket info found for real or virtual hardware")
+                # so we can track if we get this far
+                cpu_info["cpu.topology_source"] = "fallback one socket"
+                socket_count = cpu_count
+
+            # for some odd cases where there are offline ppc64 cpu's,
+            # this can end up not being a whole number...
+            cores_per_socket = cpu_count / socket_count
+
+        if cores_per_socket and threads_per_core:
+            # for s390x with sysinfo topo, we use the sysinfo numbers except
+            # for cpu_count, which takes offline cpus into account. This is
+            # mostly just to match lscpu behaviour here
+            if cpu_info["cpu.topology_source"] != "s390x sysinfo":
+                socket_count = cpu_count / cores_per_socket / threads_per_core
+
+        # s390 etc
+        # for s390, socket calculations are per book, and we can have multiple
+        # books, so multiply socket count by book count
+        # see if we are on a s390 with book info
+        # all s390 platforms show book siblings, even the ones that also
+        # show sysinfo (lpar)... Except on rhel5, where there is no
+        # cpu topology info with lpar
+        #
+        # if we got book info from sysinfo, prefer it
+        book_siblings_per_cpu = None
+        if not books:
+            book_siblings_per_cpu = self.count_cpumask_entries(cpu_files[0], 'book_siblings_list')
+            if book_siblings_per_cpu:
+                book_count = cpu_count / book_siblings_per_cpu
+                sockets_per_book = book_count / socket_count
+                cpu_info["cpu.topology_source"] = "s390 book_siblings_list"
+                books = True
+
+        # we should always know this...
+        cpu_info["cpu.cpu(s)"] = cpu_count
+
+        # these may be unknown...
+        if socket_count:
+            cpu_info['cpu.cpu_socket(s)'] = socket_count
+        if cores_per_socket:
+            cpu_info['cpu.core(s)_per_socket'] = cores_per_socket
+        if threads_per_core:
+            cpu_info["cpu.thread(s)_per_core"] = threads_per_core
+
+        if book_siblings_per_cpu:
+            cpu_info["cpu.book(s)_per_cpu"] = book_siblings_per_cpu
+
+        if books:
+            cpu_info["cpu.socket(s)_per_book"] = sockets_per_book
+            cpu_info["cpu.book(s)"] = book_count
+
+        return cpu_info
+
+    def get_ls_cpu_info(self):
+        lscpu_info = {}
+
+        LSCPU_CMD = '/usr/bin/lscpu'
+
+        # if we have `lscpu`, let's use it for facts as well, under
+        # the `lscpu` name space
+        if not os.access(LSCPU_CMD, os.R_OK):
+            return lscpu_info
+
+        # copy of parent process environment
+        parent_env = dict(os.environ)
+
+        # let us specify a test dir of /sys info for testing
+        # If the user env sets LC_ALL, it overrides a LANG here, so
+        # use LC_ALL here. See rhbz#1225435
+        lscpu_env = parent_env.update({'LC_ALL': 'en_US.UTF-8'})
+        lscpu_cmd = [LSCPU_CMD]
+
+        if self.testing:
+            lscpu_cmd += ['-s', self.prefix]
+
+        # For display/message only
+        lscpu_cmd_string = ' '.join(lscpu_cmd)
+
+        try:
+            lscpu_out = compat_check_output(lscpu_cmd,
+                                            env=lscpu_env)
+        except CalledProcessError as e:
+            log.exception(e)
+            log.warn('Error with lscpu (%s) subprocess: %s', lscpu_cmd_string, e)
+            return lscpu_info
+
+        errors = []
+        try:
+            cpu_data = lscpu_out.strip().split('\n')
+            for info in cpu_data:
+                try:
+                    key, value = info.split(":")
+                    nkey = '.'.join(["lscpu", key.lower().strip().replace(" ", "_")])
+                    lscpu_info[nkey] = "%s" % value.strip()
+                except ValueError as e:
+                    # sometimes lscpu outputs weird things. Or fails.
+                    # But this is per line, so keep track but let it pass.
+                    errors.append(e)
+
+        except Exception as e:
+            log.warn('Error reading system CPU information: %s', e)
+        if errors:
+            log.debug('Errors while parsing lscpu output: %s', errors)
+
+        return lscpu_info
+
+    def get_network_info(self):
+        netinfo = {}
+        try:
+            host = socket.gethostname()
+            netinfo['network.hostname'] = host
+
+            try:
+                info = socket.getaddrinfo(host, None, socket.AF_INET, socket.SOCK_STREAM)
+                ip_list = set([x[4][0] for x in info])
+                netinfo['network.ipv4_address'] = ', '.join(ip_list)
+            except Exception:
+                netinfo['network.ipv4_address'] = "127.0.0.1"
+
+            try:
+                info = socket.getaddrinfo(host, None, socket.AF_INET6, socket.SOCK_STREAM)
+                ip_list = set([x[4][0] for x in info])
+                netinfo['network.ipv6_address'] = ', '.join(ip_list)
+            except Exception:
+                netinfo['network.ipv6_address'] = "::1"
+
+        except Exception as e:
+            log.warn('Error reading networking information: %s', e)
+
+        return netinfo
+
+    def _should_get_mac_address(self, device):
+        return not (device.startswith('sit') or device.startswith('lo'))
+
+    def get_network_interfaces(self):
+        netinfdict = {}
+        old_ipv4_metakeys = ['ipv4_address', 'ipv4_netmask', 'ipv4_broadcast']
+        ipv4_metakeys = ['address', 'netmask', 'broadcast']
+        ipv6_metakeys = ['address', 'netmask']
+        try:
+            interfaces_info = ethtool.get_interfaces_info(ethtool.get_devices())
+            for info in interfaces_info:
+                master = None
+                mac_address = info.mac_address
+                device = info.device
+                # Omit mac addresses for sit and lo device types. See BZ838123
+                # mac address are per interface, not per address
+                if self._should_get_mac_address(device):
+                    key = '.'.join(['net.interface', device, 'mac_address'])
+                    netinfdict[key] = mac_address
+
+                # all of our supported versions of python-ethtool support
+                # get_ipv6_addresses
+                for addr in info.get_ipv6_addresses():
+                    # ethtool returns a different scope for "public" IPv6 addresses
+                    # on different versions of RHEL.  EL5 is "global", while EL6 is
+                    # "universe".  Make them consistent.
+                    scope = addr.scope
+                    if scope == 'universe':
+                        scope = 'global'
+
+                    # FIXME: this doesn't support multiple addresses per interface
+                    # (it finds them, but collides on the key name and loses all
+                    # but the last write). See bz #874735
+                    for mkey in ipv6_metakeys:
+                        key = '.'.join(['net.interface', info.device, 'ipv6_%s' % (mkey), scope])
+                        # we could specify a default here... that could hide
+                        # api breakage though and unit testing hw detect is... meh
+                        attr = getattr(addr, mkey) or 'Unknown'
+                        netinfdict[key] = attr
+
+                # However, old version of python-ethtool do not support
+                # get_ipv4_address
+                #
+                # python-ethtool's api changed between rhel6.3 and rhel6.4
+                # (0.6-1.el6 to 0.6-2.el6)
+                # (without revving the upstream version... bad python-ethtool!)
+                # note that 0.6-5.el5 (from rhel5.9) has the old api
+                #
+                # previously, we got the 'ipv4_address' from the etherinfo object
+                # directly. In the new api, that isn't exposed, so we get the list
+                # of addresses on the interface, and populate the info from there.
+                #
+                # That api change as to address bz #759150. The bug there was that
+                # python-ethtool only showed one ip address per interface. To
+                # accomdate the finer grained info, the api changed...
+                #
+                # FIXME: see FIXME for get_ipv6_address, we don't record multiple
+                # addresses per interface
+                if hasattr(info, 'get_ipv4_addresses'):
+                    for addr in info.get_ipv4_addresses():
+                        for mkey in ipv4_metakeys:
+                            # append 'ipv4_' to match the older interface and keeps facts
+                            # consistent
+                            key = '.'.join(['net.interface', info.device, 'ipv4_%s' % (mkey)])
+                            attr = getattr(addr, mkey) or 'Unknown'
+                            netinfdict[key] = attr
+                # check to see if we are actually an ipv4 interface
+                elif hasattr(info, 'ipv4_address'):
+                    for mkey in old_ipv4_metakeys:
+                        key = '.'.join(['net.interface', device, mkey])
+                        attr = getattr(info, mkey) or 'Unknown'
+                        netinfdict[key] = attr
+                # otherwise we are ipv6 and we handled that already
+
+                # bonded slave devices can have their hwaddr changed
+                #
+                # "master" here refers to the slave's master device.
+                # If we find a master link, we are a  slave, and we need
+                # to check the /proc/net/bonding info to see what the
+                # "permanent" hw address are for this slave
+                try:
+                    master = os.readlink('/sys/class/net/%s/master' % info.device)
+                #FIXME
+                except Exception:
+                    master = None
+
+                if master:
+                    master_interface = os.path.basename(master)
+                    permanent_mac_addr = self._get_slave_hwaddr(master_interface, info.device)
+                    key = '.'.join(['net.interface', info.device, "permanent_mac_address"])
+                    netinfdict[key] = permanent_mac_addr
+
+        except Exception as e:
+            log.exception(e)
+            log.warn("Error reading network interface information: %s", e)
+        return netinfdict
+
+    # from rhn-client-tools  hardware.py
+    # see bz#785666
+    def _get_slave_hwaddr(self, master, slave):
+        hwaddr = ""
+        try:
+            bonding = open('/proc/net/bonding/%s' % master, "r")
+        except:
+            return hwaddr
+
+        slave_found = False
+        for line in bonding.readlines():
+            if slave_found and line.find("Permanent HW addr: ") != -1:
+                hwaddr = line.split()[3].upper()
+                break
+
+            if line.find("Slave Interface: ") != -1:
+                ifname = line.split()[2]
+                if ifname == slave:
+                    slave_found = True
+
+        bonding.close()
+        return hwaddr
+
+
+if __name__ == '__main__':
+    _LIBPATH = "/usr/share/rhsm"
+    # add to the path if need be
+    if _LIBPATH not in sys.path:
+        sys.path.append(_LIBPATH)
+
+    from subscription_manager import logutil
+    logutil.init_logger()
+
+    hw = HardwareCollector(prefix=sys.argv[1], testing=True)
+
+    if len(sys.argv) > 1:
+        hw.prefix = sys.argv[1]
+        hw.testing = True
+    hw_dict = hw.get_all()
+
+    # just show the facts collected, unless we specify data dir and well,
+    # anything else
+    if len(sys.argv) > 2:
+        for hkey, hvalue in sorted(hw_dict.items()):
+            print("'%s' : '%s'" % (hkey, hvalue))
+
+    if not hw.testing:
+        sys.exit(0)
+
+    # verify the cpu socket info collection we use for rhel5 matches lscpu
+    cpu_items = [
+        ('cpu.core(s)_per_socket', 'lscpu.core(s)_per_socket'),
+        ('cpu.cpu(s)', 'lscpu.cpu(s)'),
+        # NOTE: the substring is different for these two folks...
+        # FIXME: follow up to see if this has changed
+        ('cpu.cpu_socket(s)', 'lscpu.socket(s)'),
+        ('cpu.book(s)', 'lscpu.book(s)'),
+        ('cpu.thread(s)_per_core', 'lscpu.thread(s)_per_core'),
+        ('cpu.socket(s)_per_book', 'lscpu.socket(s)_per_book')
+    ]
+    failed = False
+    failed_list = []
+    for cpu_item in cpu_items:
+        value_0 = int(hw_dict.get(cpu_item[0], -1))
+        value_1 = int(hw_dict.get(cpu_item[1], -1))
+
+        #print "%s/%s: %s %s" % (cpu_item[0], cpu_item[1], value_0, value_1)
+
+        if value_0 != value_1 and ((value_0 != -1) and (value_1 != -1)):
+            failed_list.append((cpu_item[0], cpu_item[1], value_0, value_1))
+
+    must_haves = ['cpu.cpu_socket(s)', 'cpu.cpu(s)', 'cpu.core(s)_per_socket', 'cpu.thread(s)_per_core']
+    missing_set = set(must_haves).difference(set(hw_dict))
+
+    if failed:
+        print("cpu detection error")
+    for failed in failed_list:
+        print("The values %s %s do not match (|%s| != |%s|)" % (failed[0], failed[1], failed[2], failed[3]))
+    if missing_set:
+        for missing in missing_set:
+            print("cpu info fact: %s was missing" % missing)
+
+    if failed:
+        sys.exit(1)
diff --git a/src/rhsmlib/facts/virt.py b/src/rhsmlib/facts/virt.py
new file mode 100644
index 0000000000..f83e49a6bd
--- /dev/null
+++ b/src/rhsmlib/facts/virt.py
@@ -0,0 +1,156 @@
+#
+# Probe hardware info that requires root
+#
+# Copyright (c) 2010-2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+
+import gettext
+import logging
+
+from rhsmlib.facts import collector
+
+# For python2.6 that doesn't have subprocess.check_output
+from rhsmlib.compat import check_output as compat_check_output
+
+log = logging.getLogger(__name__)
+
+_ = gettext.gettext
+
+
+class VirtWhatCollector(collector.FactsCollector):
+    def get_all(self):
+        return self.get_virt_info()
+
+    # NOTE/TODO/FIXME: Not all platforms require admin privs to determine virt type or uuid
+    def get_virt_info(self):
+        virt_dict = {}
+
+        try:
+            host_type = compat_check_output('virt-what')
+            # BZ1018807 xen can report xen and xen-hvm.
+            # Force a single line
+            host_type = ", ".join(host_type.splitlines())
+
+            # If this is blank, then not a guest
+            virt_dict['virt.is_guest'] = bool(host_type)
+            if bool(host_type):
+                virt_dict['virt.is_guest'] = True
+                virt_dict['virt.host_type'] = host_type
+            else:
+                virt_dict['virt.is_guest'] = False
+                virt_dict['virt.host_type'] = "Not Applicable"
+        # TODO:  Should this only catch OSErrors?
+        except Exception as e:
+            # Otherwise there was an error running virt-what - who knows
+            log.exception(e)
+            virt_dict['virt.is_guest'] = 'Unknown'
+
+        # xen dom0 is a guest for virt-what's purposes, but is a host for
+        # our purposes. Adjust is_guest accordingly. (#757697)
+        try:
+            if virt_dict['virt.host_type'].find('dom0') > -1:
+                virt_dict['virt.is_guest'] = False
+        except KeyError:
+            # if host_type is not defined, do nothing (#768397)
+            pass
+
+        return virt_dict
+
+
+class VirtUuidCollector(collector.FactsCollector):
+    # Note: unlike system uuid in DMI info, the virt.uuid is
+    # available to non-root users on ppc64*
+    # ppc64 LPAR has it's virt.uuid in /proc/devicetree
+    # so parts of this don't need to be in AdminHardware
+    devicetree_vm_uuid_arches = ['ppc64', 'ppc64le']
+
+    # No virt.uuid equiv is available for guests on these hypervisors
+    no_uuid_platforms = ['powervm_lx86', 'xen-dom0', 'ibm_systemz']
+
+    def get_all(self):
+        return self.get_virt_uuid()
+
+    def get_virt_uuid(self):
+        """
+        Given a populated fact list, add on a virt.uuid fact if appropriate.
+        Partially adapted from Spacewalk's rhnreg.py, example hardware reporting
+        found in virt-what tests
+        """
+
+        # For 99% of uses, virt.uuid will actually be from dmi info
+        # See dmiinfo.py and cleanup.py
+
+        virt_uuid_dict = {}
+
+        # For ppc64, virt uuid is in /proc/device-tree/vm,uuid
+        # just the uuid in txt, one line
+
+        # ie, ppc64/ppc64le
+        if self.arch in self.devicetree_vm_uuid_arches:
+            virt_uuid_dict.update(self._get_devicetree_vm_uuid())
+
+        # potentially override DMI-determined UUID with
+        # what is on the file system (xen para-virt)
+        # Does this need root access?
+        try:
+            uuid_file = open('/sys/hypervisor/uuid', 'r')
+            uuid = uuid_file.read()
+            uuid_file.close()
+            virt_uuid_dict['virt.uuid'] = uuid.rstrip("\r\n")
+        except IOError:
+            pass
+
+        return virt_uuid_dict
+
+    def _get_devicetree_vm_uuid(self):
+        """Collect the virt.uuid fact from device-tree/vm,uuid
+
+        For ppc64/ppc64le systems running KVM or PowerKVM, the
+        virt uuid is found in /proc/device-tree/vm,uuid.
+
+        (In contrast to use of DMI on x86_64)."""
+
+        virt_dict = {}
+
+        vm_uuid_path = "%s/proc/device-tree/vm,uuid" % self.prefix
+
+        try:
+            with open(vm_uuid_path) as fo:
+                contents = fo.read()
+                vm_uuid = contents.strip()
+                virt_dict['virt.uuid'] = vm_uuid
+        except IOError as e:
+            log.warn("Tried to read %s but there was an error: %s", vm_uuid_path, e)
+
+        return virt_dict
+
+
+class VirtCollector(collector.FactsCollector):
+    def get_all(self):
+        virt_what_collector = VirtWhatCollector(prefix=self.prefix, testing=self.testing)
+
+        virt_what_info = virt_what_collector.get_all()
+
+        # Pass virt_what_info to the uuid collector since it needs to know
+        # what hypervisor the host is.
+        virt_uuid_collector = VirtUuidCollector(
+            prefix=self.prefix,
+            testing=self.testing,
+            collected_hw_info=virt_what_info
+        )
+        virt_uuid_info = virt_uuid_collector.get_all()
+        virt_info = {}
+        virt_info.update(virt_what_info)
+        virt_info.update(virt_uuid_info)
+        return virt_info
diff --git a/src/rhsmlib/services/__init__.py b/src/rhsmlib/services/__init__.py
new file mode 100644
index 0000000000..e69de29bb2
diff --git a/src/rhsmlib/services/config.py b/src/rhsmlib/services/config.py
new file mode 100644
index 0000000000..1525b678a5
--- /dev/null
+++ b/src/rhsmlib/services/config.py
@@ -0,0 +1,141 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+import rhsm.config
+import collections
+
+
+class Config(collections.MutableMapping):
+    def __init__(self, parser=None, auto_persist=False):
+        if parser:
+            self._parser = parser
+        else:
+            self._parser = rhsm.config.initConfig()
+
+        self.auto_persist = auto_persist
+
+        self._sections = {}
+        for s in self._parser.sections():
+            self._sections[s] = ConfigSection(self, self._parser, s, self.auto_persist)
+        super(Config, self).__init__()
+
+    def persist(self):
+        self._parser.save()
+
+    def defaults(self):
+        return self._parser.defaults()
+
+    def __getitem__(self, name):
+        if name in self:
+            return self._sections[name]
+        raise KeyError("No configuration section '%s' exists" % name)
+
+    def __setitem__(self, key, value):
+        try:
+            value.iteritems()
+        except Exception:
+            raise
+
+        if key in self:
+            # Similar to __delitem__ but with no persistence
+            self._parser.remove_section(key)
+            # Be aware that RhsmConfigParser is very diligent about keeping
+            # default values in the configuration.  Deleting the section will result
+            # in all the section's values being reset to the defaults.
+            del self._sections[key]
+
+        self._parser.add_section(key)
+        self._sections[key] = ConfigSection(self, self._parser, key, self.auto_persist)
+
+        for k, v in value.iteritems():
+            self._sections[key][k] = v
+
+        if self.auto_persist:
+            self.persist()
+
+    def __delitem__(self, key):
+        self._parser.remove_section(key)
+        del self._sections[key]
+        if self.auto_persist:
+            self.persist()
+
+    def __contains__(self, key):
+        return key in self._sections
+
+    def __iter__(self):
+        return iter(self._parser.sections())
+
+    def iter_sections(self):
+        """An iterator that yields the actual ConfigSection objects instead of just
+        the names of the sections."""
+        for s in self._parser.sections():
+            yield self[s]
+
+    def __len__(self):
+        return len(self._parser.sections())
+
+    def __repr__(self):
+        result = {}
+        for name, s in self._sections.items():
+            result[name] = repr(s)
+        return "%s" % result
+
+
+class ConfigSection(collections.MutableMapping):
+    def __init__(self, wrapper, parser, section, auto_persist=False):
+        self._wrapper = wrapper
+        self._parser = parser
+        self._section = section
+        self.auto_persist = auto_persist
+
+    def __iter__(self):
+        return iter(self._parser.options(self._section))
+
+    def __getitem__(self, key):
+        if key in self:
+            return self._parser.get(self._section, key)
+        raise KeyError("Property '%s' does not exist in section '%s'" % (key, self._section))
+
+    def __setitem__(self, key, value):
+        self._parser.set(self._section, key, value)
+        if self.auto_persist:
+            self._wrapper.persist()
+
+    def __delitem__(self, key):
+        if key in self:
+            self._parser.remove_option(self._section, key)
+            if self.auto_persist:
+                self._persist()
+        else:
+            raise KeyError("Property '%s' does not exist in section '%s'" % (key, self._section))
+
+    def __contains__(self, key):
+        return self._parser.has_option(self._section, key)
+
+    def __len__(self):
+        return len(self._parser.options(self._section))
+
+    def _persist(self):
+        self._wrapper.persist()
+
+    def __repr__(self):
+        return "%s" % self._parser.items(self._section)
+
+    def get_int(self, key):
+        return self._parser.get_int(self._section, key)
+
+    def get_default(self, key):
+        return self._parser.get_default(self._section, key)
+
+    def has_default(self, key):
+        return self._parser.has_default(self._section, key)
diff --git a/src/subscription_manager/action_client.py b/src/subscription_manager/action_client.py
index 74261cb794..a256fe0472 100644
--- a/src/subscription_manager/action_client.py
+++ b/src/subscription_manager/action_client.py
@@ -39,6 +39,7 @@ class ActionClient(base_action_client.BaseActionClient):
 
     def _get_libset(self):
 
+        # TODO: replace with FSM thats progress through this async and wait/joins if needed
         self.entcertlib = EntCertActionInvoker()
         self.content_client = ContentActionClient()
         self.factlib = FactsActionInvoker()
diff --git a/src/subscription_manager/async.py b/src/subscription_manager/async.py
index 41a9aab9f6..4d7e52d27b 100644
--- a/src/subscription_manager/async.py
+++ b/src/subscription_manager/async.py
@@ -18,6 +18,7 @@
 import Queue
 import threading
 import gettext
+import sys
 
 from subscription_manager.ga import GObject as ga_GObject
 from subscription_manager.entcertlib import Disconnected
@@ -41,8 +42,8 @@ def _run_refresh(self, active_on, callback, data):
         try:
             self.pool.refresh(active_on)
             self.queue.put((callback, data, None))
-        except Exception, e:
-            self.queue.put((callback, data, e))
+        except Exception:
+            self.queue.put((callback, data, sys.exc_info()))
 
     def _watch_thread(self):
         """
@@ -84,8 +85,8 @@ def _run_bind(self, pool, quantity, bind_callback, cert_callback, except_callbac
             fetch_certificates(self.certlib)
             if cert_callback:
                 ga_GObject.idle_add(cert_callback)
-        except Exception, e:
-            ga_GObject.idle_add(except_callback, e)
+        except Exception:
+            ga_GObject.idle_add(except_callback, sys.exc_info())
 
     def _run_unbind(self, serial, selection, callback, except_callback):
         """
@@ -96,13 +97,13 @@ def _run_unbind(self, serial, selection, callback, except_callback):
             self.cp_provider.get_consumer_auth_cp().unbindBySerial(self.identity.uuid, serial)
             try:
                 self.certlib.update()
-            except Disconnected, e:
+            except Disconnected:
                 pass
 
             if callback:
                 ga_GObject.idle_add(callback)
-        except Exception, e:
-            ga_GObject.idle_add(except_callback, e, selection)
+        except Exception:
+            ga_GObject.idle_add(except_callback, sys.exc_info(), selection)
 
     def bind(self, pool, quantity, except_callback, bind_callback=None, cert_callback=None):
         threading.Thread(target=self._run_bind, name="AsyncBindBindThread",
@@ -130,8 +131,8 @@ def _load_data(self, success_callback, except_callback):
             current_repos = self.overrides_api.repo_lib.get_repos(apply_overrides=False)
 
             self._process_callback(success_callback, current_overrides, current_repos)
-        except Exception, e:
-            self._process_callback(except_callback, e)
+        except Exception:
+            self._process_callback(except_callback, sys.exc_info())
 
     def _update(self, to_add, to_remove, success_callback, except_callback):
         '''
@@ -156,8 +157,8 @@ def _update(self, to_add, to_remove, success_callback, except_callback):
             current_repos = self.overrides_api.repo_lib.get_repos(apply_overrides=False)
 
             self._process_callback(success_callback, current_overrides, current_repos)
-        except Exception, e:
-            self._process_callback(except_callback, e)
+        except Exception:
+            self._process_callback(except_callback, sys.exc_info())
 
     def _remove_all(self, repo_ids, success_callback, except_callback):
         try:
@@ -170,8 +171,8 @@ def _remove_all(self, repo_ids, success_callback, except_callback):
             current_repos = self.overrides_api.repo_lib.get_repos(apply_overrides=False)
 
             self._process_callback(success_callback, current_overrides, current_repos)
-        except Exception, e:
-            self._process_callback(except_callback, e)
+        except Exception:
+            self._process_callback(except_callback, sys.exc_info())
 
     def _process_callback(self, callback, *args):
         ga_GObject.idle_add(callback, *args)
diff --git a/src/subscription_manager/base_action_client.py b/src/subscription_manager/base_action_client.py
index 4b44c2cbc8..1faea37fd4 100644
--- a/src/subscription_manager/base_action_client.py
+++ b/src/subscription_manager/base_action_client.py
@@ -27,10 +27,7 @@ class BaseActionClient(object):
     An object used to update the certficates, yum repos, and facts for the system.
     """
 
-    # can we inject both of these?
-    def __init__(self, facts=None):
-
-        self.facts = facts
+    def __init__(self):
 
         self._libset = self._get_libset()
         self.lock = inj.require(inj.ACTION_LOCK)
diff --git a/src/subscription_manager/cache.py b/src/subscription_manager/cache.py
index ddfb5ab9ca..dc4f59ae92 100644
--- a/src/subscription_manager/cache.py
+++ b/src/subscription_manager/cache.py
@@ -33,12 +33,14 @@
 from subscription_manager.jsonwrapper import PoolWrapper
 from rhsm import ourjson as json
 
+from rhsmlib.services import config
+
 _ = gettext.gettext
 log = logging.getLogger(__name__)
 
 PACKAGES_RESOURCE = "packages"
 
-cfg = initConfig()
+conf = config.Config(initConfig())
 
 
 class CacheManager(object):
@@ -362,7 +364,7 @@ def __init__(self, current_profile=None):
         # Could be None, we'll read the system's current profile later once
         # we're sure we actually need the data.
         self._current_profile = current_profile
-        self._report_package_profile = cfg.get_int('rhsm', 'report_package_profile')
+        self._report_package_profile = conf['rhsm'].get_int('report_package_profile')
 
     # give tests a chance to use something other than RPMProfile
     def _get_profile(self, profile_type):
diff --git a/src/subscription_manager/certdirectory.py b/src/subscription_manager/certdirectory.py
index aeb4fa7ef6..1176700390 100644
--- a/src/subscription_manager/certdirectory.py
+++ b/src/subscription_manager/certdirectory.py
@@ -23,11 +23,12 @@
 from rhsm.config import initConfig
 from subscription_manager.injection import require, ENT_DIR
 
-log = logging.getLogger(__name__)
+from rhsmlib.services import config
 
+log = logging.getLogger(__name__)
 _ = gettext.gettext
 
-cfg = initConfig()
+conf = config.Config(initConfig())
 
 DEFAULT_PRODUCT_CERT_DIR = "/etc/pki/product-default"
 
@@ -59,7 +60,7 @@ def list(self):
 
     def listdirs(self):
         dirs = []
-        for p, fn in self.list_all():
+        for _p, fn in self.list_all():
             path = self.abspath(fn)
             if Path.isdir(path):
                 dirs.append(Directory(path))
@@ -114,7 +115,7 @@ def list(self):
         if self._listing is not None:
             return self._listing
         listing = []
-        for p, fn in Directory.list(self):
+        for _p, fn in Directory.list(self):
             if not fn.endswith('.pem') or fn.endswith(self.KEY):
                 continue
             path = self.abspath(fn)
@@ -219,7 +220,7 @@ def get_installed_products(self):
 
 class ProductDirectory(ProductCertificateDirectory):
     def __init__(self, path=None, default_path=None):
-        installed_prod_path = path or cfg.get('rhsm', 'productCertDir')
+        installed_prod_path = path or conf['rhsm']['productCertDir']
         default_prod_path = default_path or DEFAULT_PRODUCT_CERT_DIR
         self.installed_prod_dir = ProductCertificateDirectory(path=installed_prod_path)
         self.default_prod_dir = ProductCertificateDirectory(path=default_prod_path)
@@ -252,7 +253,7 @@ def path(self):
 
 class EntitlementDirectory(CertificateDirectory):
 
-    PATH = cfg.get('rhsm', 'entitlementCertDir')
+    PATH = conf['rhsm']['entitlementCertDir']
     PRODUCT = 'product'
 
     @classmethod
diff --git a/src/subscription_manager/cpuinfo.py b/src/subscription_manager/cpuinfo.py
index d33fa191aa..d584344f68 100644
--- a/src/subscription_manager/cpuinfo.py
+++ b/src/subscription_manager/cpuinfo.py
@@ -483,7 +483,5 @@ def open_proc_cpuinfo(cls, prefix=None):
         proc_cpuinfo_path = cls.proc_cpuinfo_path
         if prefix:
             proc_cpuinfo_path = os.path.join(prefix, cls.proc_cpuinfo_path[1:])
-        proc_cpuinfo_buf = ''
         with open(proc_cpuinfo_path, 'r') as proc_cpuinfo_f:
-            proc_cpuinfo_buf = proc_cpuinfo_f.read()
-        return proc_cpuinfo_buf
+            return proc_cpuinfo_f.read()
diff --git a/src/subscription_manager/dbus_interface.py b/src/subscription_manager/dbus_interface.py
index c92ece6455..a2befe463d 100644
--- a/src/subscription_manager/dbus_interface.py
+++ b/src/subscription_manager/dbus_interface.py
@@ -14,6 +14,9 @@
 #
 
 import dbus
+import dbus.mainloop
+import dbus.mainloop.glib
+
 import inspect
 import logging
 import subscription_manager.injection as inj
@@ -29,6 +32,8 @@ def __init__(self):
         try:
             # Only follow names if there is a default main loop
             self.has_main_loop = self._get_main_loop() is not None
+            log.debug("self.has_main_loop=%s", self.has_main_loop)
+            dbus.mainloop.glib.DBusGMainLoop(set_as_default=True)
 
             self.bus = dbus.SystemBus()
             validity_obj = self._get_validity_object(self.service_name,
diff --git a/src/subscription_manager/entbranding.py b/src/subscription_manager/entbranding.py
index d1a93ca0bc..b724e11fae 100644
--- a/src/subscription_manager/entbranding.py
+++ b/src/subscription_manager/entbranding.py
@@ -174,10 +174,8 @@ def write(self, brand_info):
             brand_file.write(brand_info)
 
     def read(self):
-        brand_info = None
         with open(self.path, 'r') as brand_file:
-            brand_info = brand_file.read()
-        return brand_info
+            return brand_file.read()
 
     def __str__(self):
         return "<BrandFile path=%s>" % self.path
diff --git a/src/subscription_manager/entcertlib.py b/src/subscription_manager/entcertlib.py
index d8452a6b28..a637424ed6 100644
--- a/src/subscription_manager/entcertlib.py
+++ b/src/subscription_manager/entcertlib.py
@@ -17,7 +17,6 @@
 import logging
 import socket
 
-from rhsm.config import initConfig
 from rhsm.certificate import Key, create_from_pem
 
 from subscription_manager.certdirectory import Writer
@@ -28,13 +27,9 @@
 from subscription_manager import rhelentbranding
 import subscription_manager.injection as inj
 
-
 log = logging.getLogger(__name__)
-
 _ = gettext.gettext
 
-cfg = initConfig()
-
 
 class EntCertActionInvoker(certlib.BaseActionInvoker):
     """Invoker for entitlement certificate updating actions."""
diff --git a/src/subscription_manager/factlib.py b/src/subscription_manager/factlib.py
index 68577bbd93..e1a87d3db8 100644
--- a/src/subscription_manager/factlib.py
+++ b/src/subscription_manager/factlib.py
@@ -21,6 +21,9 @@
 from certlib import Locker, ActionReport
 from subscription_manager import injection as inj
 
+import rhsmlib.dbus.facts as facts
+import rhsmlib.candlepin.api as candlepin_api
+
 _ = gettext.gettext
 
 log = logging.getLogger(__name__)
@@ -78,31 +81,32 @@ class FactsActionCommand(object):
     Returns a FactsActionReport.
     """
     def __init__(self):
-        self.cp_provider = inj.require(inj.CP_PROVIDER)
-        self.uep = self.cp_provider.get_consumer_auth_cp()
         self.report = FactsActionReport()
-        self.facts = inj.require(inj.FACTS)
-
-    def perform(self):
+        self.facts_client = facts.FactsClient()
 
-        # figure out the diff between latest facts and
-        # report that as updates
+    def collect_facts(self):
+        return self.facts_client.GetFacts()
 
-        if self.facts.has_changed():
-            fact_updates = self.facts.get_facts()
-            self.report.fact_updates = fact_updates
+    def sync_facts_to_server(self, fact_updates):
+        consumer_identity = inj.require(inj.IDENTITY)
+        if not consumer_identity.is_valid():
+            return self.report
 
-            consumer_identity = inj.require(inj.IDENTITY)
-            if not consumer_identity.is_valid():
-                # FIXME: more info
-                return self.report
+        cp_provider = inj.require(inj.CP_PROVIDER)
+        uep = cp_provider.get_consumer_auth_cp()
 
-            # CacheManager.update_check calls self.has_changed,
-            # is the self.facts.has_changed above redundant?
-            self.facts.update_check(self.uep, consumer_identity.uuid)
-            log.info("Facts have been updated.")
-        else:
-            log.debug("Facts have not changed, skipping upload.")
+        consumer_api = candlepin_api.CandlepinConsumer(uep, consumer_identity.uuid)
+        res = consumer_api.call(uep.updateConsumer, fact_updates)
+        log.debug("sync_facts_to_server candlepin api res=%s", res)
 
-        # FIXME: can populate this with more info later
+    def perform(self):
+        # figure out the diff between latest facts and
+        # report that as updates
+        self.update()
         return self.report
+
+    def update(self):
+        """This will collect the facts from the dbus service and push them to the server."""
+        collected_facts = self.collect_facts()
+        self.report.fact_updates = collected_facts
+        self.sync_facts_to_server(collected_facts)
diff --git a/src/subscription_manager/facts.py b/src/subscription_manager/facts.py
index c8cfa0ad23..a8b5fe0b89 100644
--- a/src/subscription_manager/facts.py
+++ b/src/subscription_manager/facts.py
@@ -13,25 +13,18 @@
 
 from datetime import datetime
 import gettext
-import glob
 import logging
 import os
 
-import rhsm.config
-
 from subscription_manager.injection import PLUGIN_MANAGER, require
 from subscription_manager.cache import CacheManager
-import subscription_manager.injection as inj
 from rhsm import ourjson as json
 
-_ = gettext.gettext
+from rhsmlib.dbus.facts import FactsClient
 
+_ = gettext.gettext
 log = logging.getLogger(__name__)
 
-# Hardcoded value for the version of certificates this version of the client
-# prefers:
-CERT_VERSION = "3.2"
-
 
 class Facts(CacheManager):
     """
@@ -43,11 +36,9 @@ class Facts(CacheManager):
     """
     CACHE_FILE = "/var/lib/rhsm/facts/facts.json"
 
-    def __init__(self, ent_dir=None, prod_dir=None):
+    def __init__(self):
         self.facts = {}
 
-        self.entitlement_dir = ent_dir or inj.require(inj.ENT_DIR)
-        self.product_dir = prod_dir or inj.require(inj.PROD_DIR)
         # see bz #627962
         # we would like to have this info, but for now, since it
         # can change constantly on laptops, it makes for a lot of
@@ -75,80 +66,22 @@ def has_changed(self):
 
         cached_facts = self._read_cache() or {}
         # In order to accurately check for changes, we must refresh local data
-        self.facts = self.get_facts(True)
+        self.facts = self.get_facts()
 
         for key in (set(self.facts) | set(cached_facts)) - set(self.graylist):
             if self.facts.get(key) != cached_facts.get(key):
                 return True
         return False
 
-    def get_facts(self, refresh=False):
-        if ((len(self.facts) == 0) or refresh):
-            facts = {}
-            facts.update(self._load_hw_facts())
-
-            # Set the preferred entitlement certificate version:
-            facts.update({"system.certificate_version": CERT_VERSION})
-
-            facts.update(self._load_custom_facts())
-            self.plugin_manager.run('post_facts_collection', facts=facts)
-            self.facts = facts
+    def get_facts(self):
+        facts_dbus_client = FactsClient()
+        self.facts = facts_dbus_client.GetFacts()
+        self.plugin_manager.run('post_facts_collection', facts=self.facts)
         return self.facts
 
     def to_dict(self):
         return self.get_facts()
 
-    def _load_hw_facts(self):
-        import hwprobe
-        return hwprobe.Hardware().get_all()
-
-    def _parse_facts_json(self, json_buffer, file_path):
-        custom_facts = None
-
-        try:
-            custom_facts = json.loads(json_buffer)
-        except ValueError:
-            log.warn("Unable to load custom facts file: %s" % file_path)
-
-        return custom_facts
-
-    def _open_custom_facts(self, file_path):
-        if not os.access(file_path, os.R_OK):
-            log.warn("Unable to access custom facts file: %s" % file_path)
-            return None
-
-        try:
-            f = open(file_path)
-        except IOError:
-            log.warn("Unable to open custom facts file: %s" % file_path)
-            return None
-
-        json_buffer = f.read()
-        f.close()
-
-        return json_buffer
-
-    def _load_custom_facts(self):
-        """
-        Load custom facts from .facts files in /etc/rhsm/facts.
-        """
-        # BZ 1112326 don't double the '/'
-        facts_file_glob = "%s/facts/*.facts" % rhsm.config.DEFAULT_CONFIG_DIR.rstrip('/')
-        file_facts = {}
-        for file_path in glob.glob(facts_file_glob):
-            log.info("Loading custom facts from: %s" % file_path)
-            json_buffer = self._open_custom_facts(file_path)
-
-            if json_buffer is None:
-                continue
-
-            custom_facts = self._parse_facts_json(json_buffer, file_path)
-
-            if custom_facts:
-                file_facts.update(custom_facts)
-
-        return file_facts
-
     def _sync_with_server(self, uep, consumer_uuid):
         log.debug("Updating facts on server")
         uep.updateConsumer(consumer_uuid, facts=self.get_facts())
diff --git a/src/subscription_manager/ga_impls/ga_gtk2/GLib.py b/src/subscription_manager/ga_impls/ga_gtk2/GLib.py
index 6f778a0364..c624bd6513 100644
--- a/src/subscription_manager/ga_impls/ga_gtk2/GLib.py
+++ b/src/subscription_manager/ga_impls/ga_gtk2/GLib.py
@@ -2,5 +2,7 @@
 
 timeout_add = gobject.timeout_add
 idle_add = gobject.idle_add
+MainLoop = gobject.MainLoop
+threads_init = gobject.threads_init
 
-__all__ = [timeout_add, idle_add]
+__all__ = [timeout_add, idle_add, MainLoop, threads_init]
diff --git a/src/subscription_manager/gui/allsubs.py b/src/subscription_manager/gui/allsubs.py
index 8964f4761c..a27171c9f7 100644
--- a/src/subscription_manager/gui/allsubs.py
+++ b/src/subscription_manager/gui/allsubs.py
@@ -44,7 +44,7 @@ class AllSubscriptionsTab(widgets.SubscriptionManagerTab):
                         'filter_options_button', 'applied_filters_label']
     gui_file = "allsubs"
 
-    def __init__(self, backend, facts, parent_win):
+    def __init__(self, backend, parent_win):
 
         super(AllSubscriptionsTab, self).__init__()
 
@@ -59,13 +59,12 @@ def __init__(self, backend, facts, parent_win):
         self.parent_win = parent_win
         self.backend = backend
         self.identity = require(IDENTITY)
-        self.facts = facts
 
         # Progress bar
         self.pb = None
         self.timer = 0
 
-        self.pool_stash = managerlib.PoolStash(self.facts)
+        self.pool_stash = managerlib.PoolStash()
 
         self.async_bind = async.AsyncBind(self.backend.certlib)
 
diff --git a/src/subscription_manager/gui/factsgui.py b/src/subscription_manager/gui/factsgui.py
index 9fc2ac9a74..738d14496c 100644
--- a/src/subscription_manager/gui/factsgui.py
+++ b/src/subscription_manager/gui/factsgui.py
@@ -22,6 +22,8 @@
 from subscription_manager.gui.utils import handle_gui_exception, linkify
 from subscription_manager import injection as inj
 
+import rhsmlib.dbus.facts as facts
+
 _ = gettext.gettext
 
 log = logging.getLogger(__name__)
@@ -38,15 +40,16 @@ class SystemFactsDialog(widgets.SubmanBaseWidget):
                     'system_id_label', 'system_id_title']
     gui_file = "factsdialog"
 
-    def __init__(self, facts, update_callback=None):
-
+    def __init__(self, update_callback=None):
         super(SystemFactsDialog, self).__init__()
 
         #self.consumer = consumer
         self.update_callback = update_callback
         self.identity = inj.require(inj.IDENTITY)
         self.cp_provider = inj.require(inj.CP_PROVIDER)
-        self.facts = facts
+
+        self.facts = facts.FactsClient()
+
         self.connect_signals({
                 "on_system_facts_dialog_delete_event": self._hide_callback,
                 "on_close_button_clicked": self._hide_callback,
@@ -93,23 +96,20 @@ def _display_system_id(self, identity):
             self.system_id_title.hide()
             self.system_id_label.hide()
 
-    def display_facts(self):
-        """Updates the list store with the current system facts."""
-        self.facts_store.clear()
-
-        last_update = self.facts.get_last_update()
-        if last_update:
-            self.last_update_label.set_text(last_update.strftime("%c"))
-        else:
-            self.last_update_label.set_text(_('No previous update'))
+    def _on_get_facts_error_handler(self, exception):
+        log.debug(exception)
+        raise exception
 
-        # make sure we get fresh facts, since entitlement validity status could         # change
-        system_facts_dict = self.facts.get_facts()
+    def _on_get_facts_reply_handler(self, facts_dict):
+        self.update_facts_store(facts_dict)
 
-        system_facts = system_facts_dict.items()
+    def update_facts_store(self, facts_dict):
+        self.facts_store.clear()
+        system_facts = facts_dict.items()
 
         system_facts.sort()
         group = None
+
         for fact, value in system_facts:
             new_group = fact.split(".", 1)[0]
             if new_group != group:
@@ -119,6 +119,20 @@ def display_facts(self):
                 value = _("Unknown")
             self.facts_store.append(parent, [str(fact), str(value)])
 
+    def display_facts(self):
+        """Updates the list store with the current system facts."""
+        # make sure we get fresh facts, since entitlement validity status could
+        self.facts.GetFacts(reply_handler=self._on_get_facts_reply_handler,
+                            error_handler=self._on_get_facts_error_handler)
+
+        # make last_update a Facts dbus property?
+        #last_update = self.facts.get_last_update()
+        last_update = None
+        if last_update:
+            self.last_update_label.set_text(last_update.strftime("%c"))
+        else:
+            self.last_update_label.set_text(_('No previous update'))
+
         identity = inj.require(inj.IDENTITY)
         self._display_system_id(identity)
 
diff --git a/src/subscription_manager/gui/firstboot/rhsm_login.py b/src/subscription_manager/gui/firstboot/rhsm_login.py
index 7719342f61..83f6ad2c53 100644
--- a/src/subscription_manager/gui/firstboot/rhsm_login.py
+++ b/src/subscription_manager/gui/firstboot/rhsm_login.py
@@ -2,6 +2,7 @@
 import gettext
 import sys
 import logging
+import dbus.mainloop.glib
 
 _ = lambda x: gettext.ldgettext("rhsm", x)
 
@@ -9,7 +10,7 @@
 ga_loader.init_ga()
 
 from subscription_manager.ga import Gtk as ga_Gtk
-from subscription_manager.ga import gtk_compat
+from subscription_manager.ga import gtk_compat, GLib
 
 gtk_compat.threads_init()
 
@@ -30,7 +31,6 @@
 
 from subscription_manager import injection as inj
 
-from subscription_manager.facts import Facts
 from subscription_manager.hwprobe import Hardware
 from subscription_manager.gui import managergui
 from subscription_manager.gui import registergui
@@ -61,6 +61,10 @@ def __init__(self):
         """
         super(moduleClass, self).__init__()
 
+        dbus.mainloop.glib.DBusGMainLoop(set_as_default=True)
+        GLib.threads_init()
+        dbus.mainloop.glib.threads_init()
+
         self.mode = constants.MODE_REGULAR
         self.title = _("Subscription Management Registration")
         self.sidebarTitle = _("Subscription Registration")
@@ -74,7 +78,7 @@ def __init__(self):
         reg_info = registergui.RegisterInfo()
         self.backend = managergui.Backend()
         self.plugin_manager = inj.require(inj.PLUGIN_MANAGER)
-        self.register_widget = registergui.FirstbootWidget(self.backend, Facts(), reg_info)
+        self.register_widget = registergui.FirstbootWidget(self.backend, reg_info)
         self.register_widget.connect("notify::screen-ready", self._on_screen_ready_change)
 
         # Will be False if we are on an older RHEL version where
diff --git a/src/subscription_manager/gui/installedtab.py b/src/subscription_manager/gui/installedtab.py
index e131ed1a2c..ceb2d40d45 100644
--- a/src/subscription_manager/gui/installedtab.py
+++ b/src/subscription_manager/gui/installedtab.py
@@ -59,7 +59,7 @@ class InstalledProductsTab(widgets.SubscriptionManagerTab):
                  'update_certificates_button', 'register_button']
     gui_file = "installed"
 
-    def __init__(self, backend, facts, tab_icon,
+    def __init__(self, backend, tab_icon,
                  parent, ent_dir, prod_dir):
         # The row striping in this TreeView is handled automatically
         # because we have the rules_hint set to True in the Glade file.
@@ -71,7 +71,6 @@ def __init__(self, backend, facts, tab_icon,
         self.product_dir = prod_dir
         self.entitlement_dir = ent_dir
 
-        self.facts = facts
         self.backend = backend
 
         # Product column
diff --git a/src/subscription_manager/gui/managergui.py b/src/subscription_manager/gui/managergui.py
index 45a60b5022..a2b35cab2f 100644
--- a/src/subscription_manager/gui/managergui.py
+++ b/src/subscription_manager/gui/managergui.py
@@ -38,7 +38,6 @@
 
 from subscription_manager.branding import get_branding
 from subscription_manager.entcertlib import EntCertActionInvoker
-from subscription_manager.facts import Facts
 from subscription_manager.hwprobe import ClassicCheck
 from subscription_manager import managerlib
 from subscription_manager.utils import get_client_versions, get_server_versions, parse_baseurl_info, restart_virt_who
@@ -176,7 +175,7 @@ def _on_proxy_error_dialog_response(self, window, response):
     def _exit(self, *args):
         system_exit(0)
 
-    def __init__(self, backend=None, facts=None,
+    def __init__(self, backend=None,
                  ent_dir=None, prod_dir=None,
                  auto_launch_registration=False):
         super(MainWindow, self).__init__()
@@ -193,14 +192,6 @@ def __init__(self, backend=None, facts=None,
         self.backend = backend or Backend()
         self.identity = require(IDENTITY)
 
-        self.facts = facts or Facts(self.backend.entitlement_dir,
-                self.backend.product_dir)
-        # We need to make sure facts are loaded immediately, some GUI operations
-        # are done in separate threads, and if facts try to load in another
-        # thread the virt guest detection code breaks due to hwprobe's use of
-        # signals.
-        self.facts.get_facts()
-
         log.debug("Client Versions: %s " % get_client_versions())
         # Log the server version asynchronously
         ga_GLib.idle_add(self.log_server_version, self.backend.cp_provider.get_consumer_auth_cp())
@@ -220,7 +211,7 @@ def __init__(self, backend=None, facts=None,
         self.product_dir = prod_dir or self.backend.product_dir
         self.entitlement_dir = ent_dir or self.backend.entitlement_dir
 
-        self.system_facts_dialog = factsgui.SystemFactsDialog(self.facts, update_callback=self._handle_facts_updated)
+        self.system_facts_dialog = factsgui.SystemFactsDialog(update_callback=self._handle_facts_updated)
 
         self.preferences_dialog = PreferencesDialog(self.backend,
                                                     self._get_window())
@@ -239,18 +230,17 @@ def __init__(self, backend=None, facts=None,
                 ga_Gtk.IconSize.MENU)
 
         self.installed_tab = InstalledProductsTab(self.backend,
-                                                  self.facts,
                                                   self.installed_tab_icon,
                                                   self,
                                                   ent_dir=self.entitlement_dir,
                                                   prod_dir=self.product_dir)
+
         self.my_subs_tab = MySubscriptionsTab(self.backend,
                                               self.main_window,
                                               ent_dir=self.entitlement_dir,
                                               prod_dir=self.product_dir)
 
         self.all_subs_tab = AllSubscriptionsTab(self.backend,
-                                                self.facts,
                                                 self.main_window)
 
         hbox = ga_Gtk.HBox(spacing=6)
@@ -432,7 +422,7 @@ def _should_show_redeem(self):
         return can_redeem
 
     def _register_item_clicked(self, widget):
-        registration_dialog = registergui.RegisterDialog(self.backend, self.facts)
+        registration_dialog = registergui.RegisterDialog(self.backend)
         registration_dialog.register_dialog.connect('destroy',
                                                     self._on_dialog_destroy,
                                                     widget)
@@ -513,7 +503,7 @@ def _import_cert_item_clicked(self, widget):
         self.import_sub_dialog.show()
 
     def _update_certificates_button_clicked(self, widget):
-        autobind_wizard = registergui.AutobindWizardDialog(self.backend, self.facts)
+        autobind_wizard = registergui.AutobindWizardDialog(self.backend)
         autobind_wizard.register_dialog.connect('destroy',
                                                 self._on_dialog_destroy,
                                                 widget)
diff --git a/src/subscription_manager/gui/registergui.py b/src/subscription_manager/gui/registergui.py
index 358ef944f0..1d388b9fbb 100644
--- a/src/subscription_manager/gui/registergui.py
+++ b/src/subscription_manager/gui/registergui.py
@@ -23,10 +23,13 @@
 import sys
 import threading
 
+from subscription_manager import ga_loader
+ga_loader.init_ga()
+
 from subscription_manager.ga import Gtk as ga_Gtk
 from subscription_manager.ga import GObject as ga_GObject
 
-import rhsm.config as config
+import rhsm.config as base_config
 from rhsm.utils import ServerUrlParseError
 from rhsm.connection import GoneException, RestlibException, UEPConnection, \
         ProxyException
@@ -47,13 +50,15 @@
         NoProductsException
 from subscription_manager.jsonwrapper import PoolWrapper
 
+import rhsmlib.dbus.facts as facts
+
 _ = lambda x: gettext.ldgettext("rhsm", x)
 
 gettext.textdomain("rhsm")
-
 log = logging.getLogger(__name__)
 
-CFG = config.initConfig()
+from rhsmlib.services import config
+conf = config.Config(base_config.initConfig())
 
 
 class RegisterState(object):
@@ -122,13 +127,13 @@ def reset_resolver():
 
 def server_info_from_config(config):
     return {
-            "host": config.get('server', 'hostname'),
-            "ssl_port": config.get_int('server', 'port'),
-            "handler": config.get('server', 'prefix'),
-            "proxy_hostname": config.get('server', 'proxy_hostname'),
-            "proxy_port": config.get_int('server', 'proxy_port'),
-            "proxy_user": config.get('server', 'proxy_user'),
-            "proxy_password": config.get('server', 'proxy_password')
+            "host": conf['server']['hostname'],
+            "ssl_port": conf['server'].get_int('port'),
+            "handler": conf['server']['prefix'],
+            "proxy_hostname": conf['server']['proxy_hostname'],
+            "proxy_port": conf['server'].get_int('proxy_port'),
+            "proxy_user": conf['server']['proxy_user'],
+            "proxy_password": conf['server']['proxy_password']
            }
 
 
@@ -219,9 +224,9 @@ def __init__(self):
 
     def _defaults_from_config(self):
         """Load the current server values from configuration (rhsm.conf)."""
-        self.set_property('hostname', CFG.get('server', 'hostname'))
-        self.set_property('port', CFG.get('server', 'port'))
-        self.set_property('prefix', CFG.get('server', 'prefix'))
+        self.set_property('hostname', conf['server']['hostname'])
+        self.set_property('port', conf['server']['port'])
+        self.set_property('prefix', conf['server']['prefix'])
 
     def _initial_registration_status(self):
         msg = _("This system is currently not registered.")
@@ -259,12 +264,10 @@ class RegisterWidget(widgets.SubmanBaseWidget):
     register_button_label = ga_GObject.property(type=str, default=_('Register'))
     # TODO: a prop equivalent to initial-setups 'completed' and 'status' props
 
-    def __init__(self, backend, facts, reg_info=None,
-                 parent_window=None):
+    def __init__(self, backend, reg_info=None, parent_window=None):
         super(RegisterWidget, self).__init__()
 
         self.backend = backend
-        self.facts = facts
 
         self.async = AsyncBackend(self.backend)
 
@@ -340,7 +343,6 @@ def __init__(self, backend, facts, reg_info=None,
     def add_screen(self, idx, screen_class):
         screen = screen_class(reg_info=self.info,
                               async_backend=self.async,
-                              facts=self.facts,
                               parent_window=self.parent_window)
 
         # add the index of the screen in self._screens to the class itself
@@ -402,8 +404,8 @@ def do_register_message(self, msg, msg_type=None):
     def do_register_finished(self):
         msg = _("System '%s' successfully registered.\n") % self.info.identity.name
         self.info.set_property('register-status', msg)
-        CFG.save()
-        last_server_info = server_info_from_config(CFG)
+        conf.persist()
+        last_server_info = server_info_from_config(conf)
         last_server_info['cert_file'] = self.backend.cp_provider.cert_file
         last_server_info['key_file'] = self.backend.cp_provider.key_file
         self.info.set_property('server-info', last_server_info)
@@ -700,7 +702,7 @@ class RegisterDialog(widgets.SubmanBaseWidget):
     gui_file = "register_dialog"
     __gtype_name__ = 'RegisterDialog'
 
-    def __init__(self, backend, facts=None, callbacks=None):
+    def __init__(self, backend, callbacks=None):
         """
         Callbacks will be executed when registration status changes.
         """
@@ -711,7 +713,7 @@ def __init__(self, backend, facts=None, callbacks=None):
         self.reg_info = RegisterInfo()
 
         # RegisterWidget is a oect, but not a Gtk.Widget
-        self.register_widget = self.create_wizard_widget(backend, facts, self.reg_info,
+        self.register_widget = self.create_wizard_widget(backend, self.reg_info,
                                                          self.register_dialog)
 
         # But RegisterWidget.register_widget is a Gtk.Widget, so add it to
@@ -746,15 +748,14 @@ def __init__(self, backend, facts=None, callbacks=None):
         self.window = self.register_dialog
         self.back_button.set_sensitive(False)
 
-    def create_wizard_widget(self, backend, facts, reg_info, parent_window):
+    def create_wizard_widget(self, backend, reg_info, parent_window):
         """Create a RegisterWidget or subclass and use it for our content."""
 
         # FIXME: Need better error handling in general, but it's kind of
         # annoying to have to pass the top level widget all over the place
         register_widget = RegisterWidget(backend=backend,
-                                       facts=facts,
-                                       reg_info=reg_info,
-                                       parent_window=parent_window)
+                                         reg_info=reg_info,
+                                         parent_window=parent_window)
 
         return register_widget
 
@@ -827,9 +828,9 @@ class AutoBindWidget(RegisterWidget):
 
     initial_screen = SELECT_SLA_PAGE
 
-    def __init__(self, backend, facts, reg_info=None,
+    def __init__(self, backend, reg_info=None,
                  parent_window=None):
-        super(AutoBindWidget, self).__init__(backend, facts, reg_info,
+        super(AutoBindWidget, self).__init__(backend, reg_info,
                                              parent_window)
 
     def choose_initial_screen(self):
@@ -855,15 +856,14 @@ def choose_initial_screen(self):
 class AutobindWizardDialog(RegisterDialog):
     __gtype_name__ = "AutobindWizardDialog"
 
-    def __init__(self, backend, facts):
-        super(AutobindWizardDialog, self).__init__(backend, facts)
+    def __init__(self, backend):
+        super(AutobindWizardDialog, self).__init__(backend)
 
-    def create_wizard_widget(self, backend, facts, reg_info, parent_window):
+    def create_wizard_widget(self, backend, reg_info, parent_window):
 
         # FIXME: Need better error handling in general, but it's kind of
         # annoying to have to pass the top level widget all over the place
         autobind_widget = AutoBindWidget(backend=backend,
-                                         facts=facts,
                                          reg_info=reg_info,
                                          parent_window=parent_window)
 
@@ -899,7 +899,7 @@ class Screen(widgets.SubmanBaseWidget):
 
     ready = ga_GObject.property(type=bool, default=True)
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
+    def __init__(self, reg_info, async_backend, parent_window):
         super(Screen, self).__init__()
 
         self.pre_message = ""
@@ -911,7 +911,6 @@ def __init__(self, reg_info, async_backend, facts, parent_window):
         self.parent_window = parent_window
         self.info = reg_info
         self.async = async_backend
-        self.facts = facts
 
     def stay(self):
         self.emit('stay-on-screen')
@@ -966,13 +965,12 @@ class NoGuiScreen(ga_GObject.GObject):
 
     ready = ga_GObject.property(type=bool, default=True)
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
+    def __init__(self, reg_info, async_backend, parent_window):
         ga_GObject.GObject.__init__(self)
 
         self.parent_window = parent_window
         self.info = reg_info
         self.async = async_backend
-        self.facts = facts
 
         self.button_label = None
         self.needs_gui = False
@@ -1012,8 +1010,8 @@ def stay(self):
 class PerformRegisterScreen(NoGuiScreen):
     screen_enum = PERFORM_REGISTER_PAGE
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
-        super(PerformRegisterScreen, self).__init__(reg_info, async_backend, facts, parent_window)
+    def __init__(self, reg_info, async_backend, parent_window):
+        super(PerformRegisterScreen, self).__init__(reg_info, async_backend, parent_window)
 
     def _on_registration_finished_cb(self, new_account, error=None):
         if error is not None:
@@ -1051,7 +1049,6 @@ def pre(self):
         self.info.set_property('register-status', msg)
 
         self.async.register_consumer(self.info.get_property('consumername'),
-                                     self.facts,
                                      self.info.get_property('owner-key'),
                                      self.info.get_property('environment'),
                                      self.info.get_property('activation-keys'),
@@ -1110,8 +1107,8 @@ def back_handler(self):
 class PerformPackageProfileSyncScreen(NoGuiScreen):
     screen_enum = UPLOAD_PACKAGE_PROFILE_PAGE
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
-        super(PerformPackageProfileSyncScreen, self).__init__(reg_info, async_backend, facts, parent_window)
+    def __init__(self, reg_info, async_backend, parent_window):
+        super(PerformPackageProfileSyncScreen, self).__init__(reg_info, async_backend, parent_window)
         self.pre_message = _("Uploading package profile")
 
     def _on_update_package_profile_finished_cb(self, result, error=None):
@@ -1151,8 +1148,8 @@ def pre(self):
 class PerformSubscribeScreen(NoGuiScreen):
     screen_enum = PERFORM_SUBSCRIBE_PAGE
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
-        super(PerformSubscribeScreen, self).__init__(reg_info, async_backend, facts, parent_window)
+    def __init__(self, reg_info, async_backend, parent_window):
+        super(PerformSubscribeScreen, self).__init__(reg_info, async_backend, parent_window)
         self.pre_message = _("Attaching subscriptions")
 
     def _on_subscribing_finished_cb(self, unused, error=None):
@@ -1185,8 +1182,8 @@ class ConfirmSubscriptionsScreen(Screen):
 
     gui_file = "confirmsubs"
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
-        super(ConfirmSubscriptionsScreen, self).__init__(reg_info, async_backend, facts, parent_window)
+    def __init__(self, reg_info, async_backend, parent_window):
+        super(ConfirmSubscriptionsScreen, self).__init__(reg_info, async_backend, parent_window)
         self.button_label = _("_Attach")
 
         self.store = ga_Gtk.ListStore(str, bool, str)
@@ -1249,8 +1246,8 @@ class SelectSLAScreen(Screen):
                                           'owner_treeview']
     gui_file = "selectsla"
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
-        super(SelectSLAScreen, self).__init__(reg_info, async_backend, facts, parent_window)
+    def __init__(self, reg_info, async_backend, parent_window):
+        super(SelectSLAScreen, self).__init__(reg_info, async_backend, parent_window)
 
         self.pre_message = _("Finding suitable service levels")
         self.button_label = _("_Next")
@@ -1409,7 +1406,6 @@ def pre(self):
         self.info.identity.reload()
 
         self.async.find_service_levels(self.info.identity.uuid,
-                                       self.facts,
                                        self._on_get_service_levels_cb)
         return True
 
@@ -1428,8 +1424,8 @@ class EnvironmentScreen(Screen):
     widget_names = Screen.widget_names + ['environment_treeview']
     gui_file = "environment"
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
-        super(EnvironmentScreen, self).__init__(reg_info, async_backend, facts, parent_window)
+    def __init__(self, reg_info, async_backend, parent_window):
+        super(EnvironmentScreen, self).__init__(reg_info, async_backend, parent_window)
 
         self.pre_message = _("Fetching list of possible environments")
         renderer = ga_Gtk.CellRendererText()
@@ -1497,8 +1493,8 @@ class OrganizationScreen(Screen):
     widget_names = Screen.widget_names + ['owner_treeview']
     gui_file = "organization"
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
-        super(OrganizationScreen, self).__init__(reg_info, async_backend, facts, parent_window)
+    def __init__(self, reg_info, async_backend, parent_window):
+        super(OrganizationScreen, self).__init__(reg_info, async_backend, parent_window)
 
         self.pre_message = _("Fetching list of possible organizations")
 
@@ -1575,8 +1571,8 @@ class CredentialsScreen(Screen):
     gui_file = "credentials"
     screen_enum = CREDENTIALS_PAGE
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
-        super(CredentialsScreen, self).__init__(reg_info, async_backend, facts, parent_window)
+    def __init__(self, reg_info, async_backend, parent_window):
+        super(CredentialsScreen, self).__init__(reg_info, async_backend, parent_window)
 
         self._initialize_consumer_name()
         self.registration_tip_label.set_label("<small>%s</small>" %
@@ -1673,14 +1669,14 @@ def back_handler(self):
 class ActivationKeyScreen(Screen):
     screen_enum = ACTIVATION_KEY_PAGE
     widget_names = Screen.widget_names + [
-                'activation_key_entry',
-                'organization_entry',
-                'consumer_entry',
-        ]
+        'activation_key_entry',
+        'organization_entry',
+        'consumer_entry',
+    ]
     gui_file = "activation_key"
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
-        super(ActivationKeyScreen, self).__init__(reg_info, async_backend, facts, parent_window)
+    def __init__(self, reg_info, async_backend, parent_window):
+        super(ActivationKeyScreen, self).__init__(reg_info, async_backend, parent_window)
         self._initialize_consumer_name()
 
     def _initialize_consumer_name(self):
@@ -1756,8 +1752,8 @@ def back_handler(self):
 
 class RefreshSubscriptionsScreen(NoGuiScreen):
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
-        super(RefreshSubscriptionsScreen, self).__init__(reg_info, async_backend, facts, parent_window)
+    def __init__(self, reg_info, async_backend, parent_window):
+        super(RefreshSubscriptionsScreen, self).__init__(reg_info, async_backend, parent_window)
         self.pre_message = _("Attaching subscriptions")
 
     def _on_refresh_cb(self, msg, error=None):
@@ -1785,15 +1781,15 @@ class ChooseServerScreen(Screen):
                                           'activation_key_checkbox']
     gui_file = "choose_server"
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
-        super(ChooseServerScreen, self).__init__(reg_info, async_backend, facts, parent_window)
+    def __init__(self, reg_info, async_backend, parent_window):
+        super(ChooseServerScreen, self).__init__(reg_info, async_backend, parent_window)
 
         self.button_label = _("_Next")
 
         callbacks = {
-                "on_default_button_clicked": self._on_default_button_clicked,
-                "on_proxy_button_clicked": self._on_proxy_button_clicked,
-            }
+            "on_default_button_clicked": self._on_default_button_clicked,
+            "on_proxy_button_clicked": self._on_proxy_button_clicked,
+        }
 
         self.connect_signals(callbacks)
 
@@ -1802,9 +1798,9 @@ def __init__(self, reg_info, async_backend, facts, parent_window):
     def _on_default_button_clicked(self, widget):
         # Default port and prefix are fine, so we can be concise and just
         # put the hostname for RHN:
-        self.server_entry.set_text("%s:%s%s" % (config.DEFAULT_HOSTNAME,
-            config.DEFAULT_PORT,
-            config.DEFAULT_PREFIX))
+        self.server_entry.set_text("%s:%s%s" % (base_config.DEFAULT_HOSTNAME,
+            base_config.DEFAULT_PORT,
+            base_config.DEFAULT_PREFIX))
 
     def _on_proxy_button_clicked(self, widget):
         # proxy dialog may attempt to resolve proxy and server names, so
@@ -1840,7 +1836,7 @@ def apply(self):
         self.stay()
         server = self.server_entry.get_text()
         try:
-            (hostname, port, prefix) = parse_server_info(server, CFG)
+            (hostname, port, prefix) = parse_server_info(server, conf)
             self.info.set_property('hostname', hostname)
             self.info.set_property('port', port)
             self.info.set_property('prefix', prefix)
@@ -1856,8 +1852,8 @@ def apply(self):
 
     def set_server_entry(self, hostname, port, prefix):
         # No need to show port and prefix for hosted:
-        if hostname == config.DEFAULT_HOSTNAME:
-            self.server_entry.set_text(config.DEFAULT_HOSTNAME)
+        if hostname == base_config.DEFAULT_HOSTNAME:
+            self.server_entry.set_text(base_config.DEFAULT_HOSTNAME)
         else:
             self.server_entry.set_text("%s:%s%s" % (hostname,
                                        port, prefix))
@@ -1896,9 +1892,9 @@ def _on_validate_server(self, info, error=None):
                       None)
             self.pre_done()
             return
-        CFG.set('server', 'hostname', hostname)
-        CFG.set('server', 'port', port)
-        CFG.set('server', 'prefix', prefix)
+        conf['server']['hostname'] = hostname
+        conf['server']['port'] = port
+        conf['server']['prefix'] = prefix
 
         self.pre_done()
         if self.info.get_property('use_activation_keys'):
@@ -1996,36 +1992,70 @@ def _get_environment_list(self, owner_key, callback):
         except Exception:
             self.queue.put((callback, None, sys.exc_info()))
 
-    def _register_consumer(self, name, facts, owner, env, activation_keys, callback):
+    def _register_consumer(self, name, owner, env, activation_keys, callback):
         """
         method run in the worker thread.
         """
         try:
+            # We've got several steps here that all happen in this thread
+            #
+            # Behing a 'gather system info' screen?
+            #  get installed prods
+            #  get facts (local collection or facts dbus service)
+            #
+            # run pre_register plugin (in main?)
+            # ACTUALLY REGISTER (the network call)
+            # run post_register plugin (in main?)
+            #
+            # persist identity
+            #  # These could move to call back
+            # reload identity
+            # persist new installed products info ?
+            # persist facts cache (for now)
+            # persist new consumer cert
+            # # already branch to make this a seperate page/thread
+            # update package profile (ie, read rpmdb, slow...)
+            #   which can make a package profile upload request
+            # restart virt-who   (wat?)
+            #
+            # We should probably split that up some.
+            #
             installed_mgr = require(INSTALLED_PRODUCTS_MANAGER)
 
-            # TODO: not sure why we pass in a facts.Facts, and call it's
-            #       get_facts() three times. The two bracketing plugin calls
-            #       are meant to be able to enhance/tweak facts
-            #
-            # TODO: plugin hooks could run in the main thread
-            #       Really anything that doesn't use retval.
+            # A proxy to the dbus service
+            facts_dbus_client = facts.FactsClient()
+
+            # Note: for now, this is blocking. Maybe we should do it
+            #       in the gui mainthread async and pass it in?
+
+            log.debug("about to dbus GetFacts")
+            facts_dict = facts_dbus_client.GetFacts()
+            log.debug("finished doing dbus GetFacts")
+
+            # TODO: We end up calling plugins from threads, which is a little weird.
+            #       Seems like a reasonable place to go back to main thread, run the
+            #       plugin, run the network request in a thread, come back to main, run post
+            #       plugin, etc.
+
             self.plugin_manager.run("pre_register_consumer", name=name,
-                                    facts=facts.get_facts())
+                                    facts=facts_dict)
 
             cp = self.backend.cp_provider.get_basic_auth_cp()
-            retval = cp.registerConsumer(name=name, facts=facts.get_facts(),
+            retval = cp.registerConsumer(name=name, facts=facts_dict,
                                          owner=owner, environment=env,
                                          keys=activation_keys,
                                          installed_products=installed_mgr.format_for_server())
 
             self.plugin_manager.run("post_register_consumer", consumer=retval,
-                                    facts=facts.get_facts())
+                                    facts=facts_dict)
 
             # TODO: split persisting info into it's own thread
             require(IDENTITY).reload()
+
+            # TODO: This will be rhsm-facts.services problem now
             # Facts and installed products went out with the registration
             # request, manually write caches to disk:
-            facts.write_cache()
+            # facts.write_cache()
             installed_mgr.write_cache()
 
             # Write the identity cert to disk
@@ -2119,7 +2149,7 @@ def _subscribe(self, uuid, current_sla, dry_run_result, callback):
     #    update_other_action_client_stuff
     # for sla in available_slas:
     #   get_dry_run_bind for sla
-    def _find_suitable_service_levels(self, consumer_uuid, facts):
+    def _find_suitable_service_levels(self, consumer_uuid):
 
         # FIXME:
         self.backend.update()
@@ -2155,7 +2185,7 @@ def _find_suitable_service_levels(self, consumer_uuid, facts):
         suitable_slas = {}
 
         # eek, in a thread
-        action_client = ActionClient(facts=facts)
+        action_client = ActionClient()
         action_client.update()
 
         for sla in available_slas:
@@ -2178,12 +2208,12 @@ def _find_suitable_service_levels(self, consumer_uuid, facts):
         # why do we call cert_sorter stuff in the return?
         return (current_sla, self.backend.cs.unentitled_products.values(), suitable_slas)
 
-    def _find_service_levels(self, consumer_uuid, facts, callback):
+    def _find_service_levels(self, consumer_uuid, callback):
         """
         method run in the worker thread.
         """
         try:
-            suitable_slas = self._find_suitable_service_levels(consumer_uuid, facts)
+            suitable_slas = self._find_suitable_service_levels(consumer_uuid)
             self.queue.put((callback, suitable_slas, None))
         except Exception:
             self.queue.put((callback, None, sys.exc_info()))
@@ -2237,34 +2267,36 @@ def get_environment_list(self, owner_key, callback):
                                             name="GetEnvironmentListThread",
                                             args=(owner_key, callback)))
 
-    def register_consumer(self, name, facts, owner, env, activation_keys, callback):
+    def register_consumer(self, name, owner, env, activation_keys, callback):
         """
         Run consumer registration asyncronously
         """
         ga_GObject.idle_add(self._watch_thread)
-        self._start_thread(threading.Thread(target=self._register_consumer,
-                                            name="RegisterConsumerThread",
-                                            args=(name, facts, owner,
-                                                  env, activation_keys, callback)))
+        self._start_thread(threading.Thread(
+            target=self._register_consumer,
+            name="RegisterConsumerThread",
+            args=(name, owner, env, activation_keys, callback)))
 
     def update_package_profile(self, uuid, callback):
         ga_GObject.idle_add(self._watch_thread)
-        self._start_thread(threading.Thread(target=self._update_package_profile,
-                                            name="UpdatePackageProfileThread",
-                                            args=(uuid, callback)))
+        self._start_thread(threading.Thread(
+            target=self._update_package_profile,
+            name="UpdatePackageProfileThread",
+            args=(uuid, callback)))
 
     def subscribe(self, uuid, current_sla, dry_run_result, callback):
         ga_GObject.idle_add(self._watch_thread)
-        self._start_thread(threading.Thread(target=self._subscribe,
-                                            name="SubscribeThread",
-                                            args=(uuid, current_sla,
-                                                  dry_run_result, callback)))
+        self._start_thread(threading.Thread(
+            target=self._subscribe,
+            name="SubscribeThread",
+            args=(uuid, current_sla, dry_run_result, callback)))
 
-    def find_service_levels(self, consumer_uuid, facts, callback):
+    def find_service_levels(self, consumer_uuid, callback):
         ga_GObject.idle_add(self._watch_thread)
-        self._start_thread(threading.Thread(target=self._find_service_levels,
-                                            name="FindServiceLevelsThread",
-                                            args=(consumer_uuid, facts, callback)))
+        self._start_thread(threading.Thread(
+            target=self._find_service_levels,
+            name="FindServiceLevelsThread",
+            args=(consumer_uuid, callback)))
 
     def refresh(self, callback):
         ga_GObject.idle_add(self._watch_thread)
@@ -2291,8 +2323,8 @@ def validate_server(self, hostname, port, prefix, callback):
 class DoneScreen(Screen):
     gui_file = "done_box"
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
-        super(DoneScreen, self).__init__(reg_info, async_backend, facts, parent_window)
+    def __init__(self, reg_info, async_backend, parent_window):
+        super(DoneScreen, self).__init__(reg_info, async_backend, parent_window)
         self.pre_message = "We are done."
 
     def pre(self):
@@ -2310,14 +2342,14 @@ class InfoScreen(Screen):
     Also allows the user to skip registration if they wish.
     """
     widget_names = Screen.widget_names + [
-                'register_radio',
-                'skip_radio',
-                'why_register_dialog'
-        ]
+        'register_radio',
+        'skip_radio',
+        'why_register_dialog'
+    ]
     gui_file = "registration_info"
 
-    def __init__(self, reg_info, async_backend, facts, parent_window):
-        super(InfoScreen, self).__init__(reg_info, async_backend, facts, parent_window)
+    def __init__(self, reg_info, async_backend, parent_window):
+        super(InfoScreen, self).__init__(reg_info, async_backend, parent_window)
         self.button_label = _("_Next")
         callbacks = {"on_why_register_button_clicked":
                      self._on_why_register_button_clicked,
diff --git a/src/subscription_manager/gui/utils.py b/src/subscription_manager/gui/utils.py
index cbda08da2f..f6dc78c68e 100644
--- a/src/subscription_manager/gui/utils.py
+++ b/src/subscription_manager/gui/utils.py
@@ -63,6 +63,9 @@ def handle_gui_exception(e, msg, parent, format_msg=True, log_msg=None):
     format_msg = if true, string sub the exception error in the msg
     """
     if isinstance(e, tuple):
+        if not log_msg:
+            log_msg = str(e[1])
+
         log.error(log_msg, exc_info=e)
         # Get the class instance of the exception
         e = e[1]
diff --git a/src/subscription_manager/identity.py b/src/subscription_manager/identity.py
index f1f59f956a..db759ce6c9 100644
--- a/src/subscription_manager/identity.py
+++ b/src/subscription_manager/identity.py
@@ -20,8 +20,9 @@
 from rhsm.config import initConfig
 from subscription_manager.certdirectory import Path
 
-CFG = initConfig()
+from rhsmlib.services import config
 
+conf = config.Config(initConfig())
 log = logging.getLogger(__name__)
 
 
@@ -31,7 +32,7 @@ class ConsumerIdentity:
     Includes helpers for reading/writing consumer identity certificates
     from disk."""
 
-    PATH = CFG.get('rhsm', 'consumerCertDir')
+    PATH = conf['rhsm']['consumerCertDir']
     KEY = 'key.pem'
     CERT = 'cert.pem'
 
@@ -147,7 +148,7 @@ def reload(self):
             self.consumer = None
             self.name = None
             self.uuid = None
-            self.cert_dir_path = CFG.get('rhsm', 'consumerCertDir')
+            self.cert_dir_path = conf['rhsm']['consumerCertDir']
 
     def _get_consumer_identity(self):
         # FIXME: wrap in exceptions, catch IOErrors etc, raise anything else
diff --git a/src/subscription_manager/lock.py b/src/subscription_manager/lock.py
index 1b4388539e..909415483d 100644
--- a/src/subscription_manager/lock.py
+++ b/src/subscription_manager/lock.py
@@ -101,7 +101,7 @@ def __init__(self, path):
         self.lockdir = None
         self.blocking = None
 
-        lock_dir, fn = os.path.split(self.path)
+        lock_dir, _fn = os.path.split(self.path)
         try:
             if not os.path.exists(lock_dir):
                 os.makedirs(lock_dir)
diff --git a/src/subscription_manager/managercli.py b/src/subscription_manager/managercli.py
index 2616c8e2b9..df50e8f604 100644
--- a/src/subscription_manager/managercli.py
+++ b/src/subscription_manager/managercli.py
@@ -41,6 +41,7 @@
 
 from subscription_manager.branding import get_branding
 from subscription_manager.entcertlib import EntCertActionInvoker
+from subscription_manager.factlib import FactsActionCommand
 from subscription_manager.action_client import ActionClient, UnregisterActionClient
 from subscription_manager.cert_sorter import ComplianceManager, FUTURE_SUBSCRIBED, \
         SUBSCRIBED, NOT_SUBSCRIBED, EXPIRED, PARTIALLY_SUBSCRIBED, UNKNOWN
@@ -63,11 +64,14 @@
 from subscription_manager.printing_utils import columnize, format_name, \
         none_wrap_columnize_callback, echo_columnize_callback, highlight_by_filter_string_columnize_callback
 
+import rhsmlib.dbus.facts as facts
+
 _ = gettext.gettext
 
 log = logging.getLogger(__name__)
 
-cfg = rhsm.config.initConfig()
+from rhsmlib.services import config
+conf = config.Config(rhsm.config.initConfig())
 
 SM = "subscription-manager"
 ERR_NOT_REGISTERED_MSG = _("This system is not yet registered. Try 'subscription-manager register --help' for more information.")
@@ -315,12 +319,12 @@ def _get_logger(self):
 
     def test_proxy_connection(self):
         result = None
-        if not self.proxy_hostname and not cfg.get("server", "proxy_hostname"):
+        if not self.proxy_hostname and not conf["server"]["proxy_hostname"]:
             return True
         try:
             s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
             s.settimeout(10)
-            result = s.connect_ex((self.proxy_hostname or cfg.get("server", "proxy_hostname"), int(self.proxy_port or rhsm.config.DEFAULT_PROXY_PORT)))
+            result = s.connect_ex((self.proxy_hostname or conf["server"]["proxy_hostname"], int(self.proxy_port or rhsm.config.DEFAULT_PROXY_PORT)))
         except Exception as e:
             log.info("Attempted bad proxy: %s" % e)
             return False
@@ -422,21 +426,21 @@ def main(self, args=None):
             system_exit(os.EX_USAGE)
 
         if hasattr(self.options, "insecure") and self.options.insecure:
-            cfg.set("server", "insecure", "1")
+            conf["server"]["insecure"] = "1"
             config_changed = True
 
         if hasattr(self.options, "server_url") and self.options.server_url:
             try:
                 (self.server_hostname,
                  self.server_port,
-                 self.server_prefix) = parse_server_info(self.options.server_url, cfg)
+                 self.server_prefix) = parse_server_info(self.options.server_url, conf)
             except ServerUrlParseError, e:
                 print _("Error parsing serverurl:")
                 handle_exception("Error parsing serverurl:", e)
 
-            cfg.set("server", "hostname", self.server_hostname)
-            cfg.set("server", "port", self.server_port)
-            cfg.set("server", "prefix", self.server_prefix)
+            conf["server"]["hostname"] = self.server_hostname
+            conf["server"]["port"] = self.server_port
+            conf["server"]["prefix"] = self.server_prefix
             if self.server_port:
                 self.server_port = int(self.server_port)
             config_changed = True
@@ -450,9 +454,10 @@ def main(self, args=None):
                 print _("Error parsing baseurl:")
                 handle_exception("Error parsing baseurl:", e)
 
-            cfg.set("rhsm", "baseurl", format_baseurl(baseurl_server_hostname,
-                                                      baseurl_server_port,
-                                                      baseurl_server_prefix))
+            conf["rhsm"]["baseurl"] = format_baseurl(
+                baseurl_server_hostname,
+                baseurl_server_port,
+                baseurl_server_prefix)
             config_changed = True
 
         # support foo.example.com:3128 format
@@ -464,7 +469,7 @@ def main(self, args=None):
                 self.proxy_port = int(parts[1])
             else:
                 # if no port specified, use the one from the config, or fallback to the default
-                self.proxy_port = cfg.get_int('server', 'proxy_port') or rhsm.config.DEFAULT_PROXY_PORT
+                self.proxy_port = conf['server'].get_int('proxy_port') or rhsm.config.DEFAULT_PROXY_PORT
             config_changed = True
 
         if hasattr(self.options, "proxy_user") and self.options.proxy_user:
@@ -538,7 +543,7 @@ def main(self, args=None):
 
             # Only persist the config changes if there was no exception
             if config_changed and self.persist_server_options():
-                cfg.save()
+                conf.persist()
 
             if return_code is not None:
                 return return_code
@@ -1104,22 +1109,27 @@ def _do_command(self):
 
         self.cp_provider.clean()
 
-        facts = inj.require(inj.FACTS)
+        # A proxy to the dbus service
+        facts_dbus_client = facts.FactsClient()
 
         # Proceed with new registration:
         try:
             if not self.options.activation_keys:
                 print _("Registering to: %s:%s%s") % \
-                    (cfg.get("server", "hostname"), cfg.get("server", "port"), cfg.get("server", "prefix"))
+                    (conf["server"]["hostname"], conf["server"]["port"], conf["server"]["prefix"])
                 self.cp_provider.set_user_pass(self.username, self.password)
                 admin_cp = self.cp_provider.get_basic_auth_cp()
             else:
                 admin_cp = self.cp_provider.get_no_auth_cp()
 
-            facts_dic = facts.get_facts()
+            # TODO/FIXME: revisit register cli refactor branch and combine it and
+            #             AsyncBackend to run this as a series of states triggered by events
+            # This is blocking and not async, which aside from blocking here, also
+            # means things like following name owner changes gets weird.
+            facts_dict = facts_dbus_client.GetFacts()
 
             self.plugin_manager.run("pre_register_consumer", name=consumername,
-                                    facts=facts_dic)
+                                    facts=facts_dict)
 
             if self.options.consumerid:
                 # TODO remove the username/password
@@ -1142,14 +1152,14 @@ def _do_command(self):
                         self.options.environment)
 
                 consumer = admin_cp.registerConsumer(name=consumername,
-                     type=self.options.consumertype, facts=facts_dic,
+                     type=self.options.consumertype, facts=facts_dict,
                      owner=owner_key, environment=environment_id,
                      keys=self.options.activation_keys,
                      installed_products=self.installed_mgr.format_for_server(),
                      content_tags=self.installed_mgr.tags)
                 self.installed_mgr.write_cache()
             self.plugin_manager.run("post_register_consumer", consumer=consumer,
-                                    facts=facts_dic)
+                                    facts=facts_dict)
         except connection.RestlibException, re:
             log.exception(re)
             system_exit(os.EX_SOFTWARE, re.msg)
@@ -1177,7 +1187,11 @@ def _do_command(self):
         # Must update facts to clear out the old ones:
         if self.options.consumerid:
             log.info("Updating facts")
-            facts.update_check(self.cp, consumer['uuid'], force=True)
+            #
+            # FIXME: Need a ConsumerFacts.sync or update or something
+            # TODO: We register, with facts, then update facts again...?
+            #       Are we trying to sync potential new or dynamic facts?
+            #facts.update_check(self.cp, consumer['uuid'], force=True)
 
         profile_mgr = inj.require(inj.PROFILE_MANAGER)
         # 767265: always force an upload of the packages when registering
@@ -1185,7 +1199,8 @@ def _do_command(self):
 
         # Facts and installed products went out with the registration request,
         # manually write caches to disk:
-        facts.write_cache()
+        # facts service job now(soon)
+        #facts.write_cache()
         self.installed_mgr.update_check(self.cp, consumer['uuid'])
 
         if self.options.release:
@@ -1369,9 +1384,14 @@ def _do_command(self):
         try:
             # FIXME: why just facts and package profile update here?
             # update facts first, if we need to
-            facts = inj.require(inj.FACTS)
-            facts.update_check(self.cp, self.identity.uuid)
 
+            # FIXME: either do above, or add a ConsumerFacts model and populate
+            #        it from dbus call, and update_check() to send to candlepin
+            #facts = inj.require(inj.FACTS)
+            #facts.update_check(self.cp, self.identity.uuid)
+
+            # ie, don't forget to fix me
+            raise Exception('facts syncing not implemented yet, so this should fail tests.')
             profile_mgr = inj.require(inj.PROFILE_MANAGER)
             profile_mgr.update_check(self.cp, self.identity.uuid)
 
@@ -1426,9 +1446,9 @@ def show_current_release(self):
 
     def _do_command(self):
 
-        cdn_url = cfg.get('rhsm', 'baseurl')
+        cdn_url = conf['rhsm']['baseurl']
         # note: parse_baseurl_info will populate with defaults if not found
-        (cdn_hostname, cdn_port, cdn_prefix) = parse_baseurl_info(cdn_url)
+        (cdn_hostname, cdn_port, _cdn_prefix) = parse_baseurl_info(cdn_url)
 
         # Base CliCommand has already setup proxy info etc
         self.cp_provider.set_content_connection_info(cdn_hostname=cdn_hostname,
@@ -1495,11 +1515,11 @@ def __init__(self):
         _("All installed products are covered by valid entitlements.")
         _("No need to update subscriptions at this time.")
 
-    def _read_pool_ids(self, file):
+    def _read_pool_ids(self, f):
         if not self.options.pool:
             self.options.pool = []
 
-        for line in fileinput.input(file):
+        for line in fileinput.input(f):
             for pool in filter(bool, re.split(r"\s+", line.strip())):
                 self.options.pool.append(pool)
 
@@ -1848,31 +1868,26 @@ def _validate_options(self):
     def _do_command(self):
         self._validate_options()
 
-        identity = inj.require(inj.IDENTITY)
         if self.options.list:
-            facts = inj.require(inj.FACTS)
-            fact_dict = facts.get_facts()
-            fact_keys = fact_dict.keys()
-            fact_keys.sort()
-            for key in fact_keys:
-                value = fact_dict[key]
+            # A proxy to the dbus service
+            facts_dbus_client = facts.FactsClient()
+
+            facts_dict = facts_dbus_client.GetFacts()
+            facts_keys = facts_dict.keys()
+            facts_keys.sort()
+
+            for key in facts_keys:
+                value = facts_dict[key]
                 if str(value).strip() == "":
                     value = _("Unknown")
                 print "%s: %s" % (key, value)
 
         if self.options.update:
-            facts = inj.require(inj.FACTS)
-            try:
-                facts.update_check(self.cp, identity.uuid, force=True)
-            except connection.RestlibException, re:
-                log.exception(re)
-                system_exit(os.EX_SOFTWARE, re.msg)
-            log.info("Succesfully updated the system facts.")
-            print _("Successfully updated the system facts.")
+            facts_action_command = FactsActionCommand()
+            facts_action_command.update()
 
 
 class ImportCertCommand(CliCommand):
-
     def __init__(self):
         shortdesc = _("Import certificates which were provided outside of the tool")
         super(ImportCertCommand, self).__init__("import", shortdesc, False)
@@ -2169,10 +2184,11 @@ def __init__(self):
                                help=_("list the configuration for this system"))
         self.parser.add_option("--remove", dest="remove", action="append",
                                help=_("remove configuration entry by section.name"))
-        for section in cfg.sections():
-            for name, value in cfg.items(section):
-                self.parser.add_option("--" + section + "." + name, dest=(section + "." + name),
-                    help=_("Section: %s, Name: %s") % (section, name))
+        for s in conf.keys():
+            section = conf[s]
+            for name, _value in section.items():
+                self.parser.add_option("--" + s + "." + name, dest=(s + "." + name),
+                    help=_("Section: %s, Name: %s") % (s, name))
 
     def _validate_options(self):
         if self.options.list:
@@ -2180,9 +2196,10 @@ def _validate_options(self):
             if self.options.remove:
                 too_many = True
             else:
-                for section in cfg.sections():
-                    for name, value in cfg.items(section):
-                        if getattr(self.options, section + "." + name):
+                for s in conf.keys():
+                    section = conf[s]
+                    for name, _value in section.items():
+                        if getattr(self.options, s + "." + name):
                             too_many = True
                             break
             if too_many:
@@ -2190,9 +2207,10 @@ def _validate_options(self):
 
         if not (self.options.list or self.options.remove):
             has = False
-            for section in cfg.sections():
-                for name, value in cfg.items(section):
-                    test = "%s" % getattr(self.options, section + "." + name)
+            for s in conf.keys():
+                section = conf[s]
+                for name, _value in section.items():
+                    test = "%s" % getattr(self.options, s + "." + name)
                     has = has or (test != 'None')
             if not has:
                 # if no options are given, default to --list
@@ -2200,14 +2218,14 @@ def _validate_options(self):
 
         if self.options.remove:
             for r in self.options.remove:
-                if not "." in r:
+                if not "." in r:  # pragma: noqa
                     system_exit(os.EX_USAGE, _("Error: configuration entry designation for removal must be of format [section.name]"))
 
                 section = r.split('.')[0]
                 name = r.split('.')[1]
                 found = False
-                if cfg.has_section(section):
-                    for key, value in cfg.items(section):
+                if section in conf.keys():
+                    for key, _value in conf[section].items():
                         if name == key:
                             found = True
                 if not found:
@@ -2217,14 +2235,15 @@ def _do_command(self):
         self._validate_options()
 
         if self.options.list:
-            for section in cfg.sections():
-                print '[%s]' % (section)
-                source_list = cfg.items(section)
+            for s in conf.keys():
+                section = conf[s]
+                print '[%s]' % s
+                source_list = section.items()
                 source_list.sort()
                 for (name, value) in source_list:
                     indicator1 = ''
                     indicator2 = ''
-                    if (value == cfg.get_default(section, name)):
+                    if value == section.get_default(name):
                         indicator1 = '['
                         indicator2 = ']'
                     print '   %s = %s%s%s' % (name, indicator1, value, indicator2)
@@ -2236,23 +2255,24 @@ def _do_command(self):
                 section = r.split('.')[0]
                 name = r.split('.')[1]
                 try:
-                    if not cfg.has_default(section, name):
-                        cfg.set(section, name, '')
+                    if not conf[section].has_default(name):
+                        conf[section][name] = ''
                         print _("You have removed the value for section %s and name %s.") % (section, name)
                     else:
-                        cfg.set(section, name, cfg.get_default(section, name))
+                        conf[section][name] = conf[section].get_default(name)
                         print _("You have removed the value for section %s and name %s.") % (section, name)
                         print _("The default value for %s will now be used.") % (name)
                 except Exception:
                     print _("Section %s and name %s cannot be removed.") % (section, name)
-            cfg.save()
+            conf.persist()
         else:
-            for section in cfg.sections():
-                for name, value in cfg.items(section):
-                    value = "%s" % getattr(self.options, section + "." + name)
+            for s in conf.keys():
+                section = conf[s]
+                for name, value in section.items():
+                    value = "%s" % getattr(self.options, s + "." + name)
                     if not value == 'None':
-                        cfg.set(section, name, value)
-            cfg.save()
+                        section[name] = value
+            conf.persist()
 
     def require_connection(self):
         return False
@@ -2342,9 +2362,7 @@ def _do_command(self):
                     system_exit(os.EX_DATAERR,
                                 msg.format(dateexample=dateexample))
 
-            facts = inj.require(inj.FACTS)
-            epools = managerlib.get_available_entitlements(facts=facts,
-                                                           get_all=self.options.all,
+            epools = managerlib.get_available_entitlements(get_all=self.options.all,
                                                            active_on=on_date,
                                                            overlapping=self.options.no_overlap,
                                                            uninstalled=self.options.match_installed,
@@ -2532,8 +2550,7 @@ def print_consumed(self, service_level=None, filter_string=None, pid_only=False)
                             pool_type,
                             managerlib.format_date(cert.valid_range.begin()),
                             managerlib.format_date(cert.valid_range.end()),
-                            system_type, **kwargs
-                        ) + "\n"
+                            system_type, **kwargs) + "\n"
             elif not pid_only:
                 if filter_string and service_level:
                     print(
@@ -2578,7 +2595,7 @@ def _colon_split(self, option, opt_str, value, parser):
         if value.strip() == '':
             raise OptionValueError(_("You must specify an override in the form of \"name:value\" with --add."))
 
-        k, colon, v = value.partition(':')
+        k, _colon, v = value.partition(':')
         if not v or not k:
             raise OptionValueError(_("--add arguments should be in the form of \"name:value\""))
 
diff --git a/src/subscription_manager/managerlib.py b/src/subscription_manager/managerlib.py
index b206c01bdf..46903e5b16 100644
--- a/src/subscription_manager/managerlib.py
+++ b/src/subscription_manager/managerlib.py
@@ -31,11 +31,10 @@
 import subscription_manager.cache as cache
 from subscription_manager.cert_sorter import StackingGroupSorter, ComplianceManager
 from subscription_manager import identity
-from subscription_manager.facts import Facts
 from subscription_manager.injection import require, CERT_SORTER, \
         IDENTITY, ENTITLEMENT_STATUS_CACHE, \
         PROD_STATUS_CACHE, ENT_DIR, PROD_DIR, CP_PROVIDER, OVERRIDE_STATUS_CACHE, \
-        POOLTYPE_CACHE, RELEASE_STATUS_CACHE
+        POOLTYPE_CACHE, RELEASE_STATUS_CACHE, FACTS
 from subscription_manager import isodate
 from subscription_manager.jsonwrapper import PoolWrapper
 from subscription_manager.repolib import RepoActionInvoker
@@ -84,8 +83,7 @@ def __init__(self, errors):
         self.errors = errors
 
     def __str__(self, reason=""):
-        msg = 'Entitlement Certificate(s) update failed due to the following reasons:\n' + \
-        '\n'.join(self.errors)
+        msg = 'Entitlement Certificate(s) update failed due to the following reasons:\n' + '\n'.join(self.errors)
         return msg
 
 
@@ -259,14 +257,30 @@ def filter_subscribed_pools(self, pools, subscribed_pool_ids,
         return filtered_pools
 
 
-def list_pools(uep, consumer_uuid, facts, list_all=False, active_on=None, filter_string=None):
+def list_pools(uep, consumer_uuid, list_all=False, active_on=None, filter_string=None):
     """
     Wrapper around the UEP call to fetch pools, which forces a facts update
     if anything has changed before making the request. This ensures the
     rule checks server side will have the most up to date info about the
     consumer possible.
     """
-    facts.update_check(uep, consumer_uuid)
+
+    # client tells service 'look for facts again'
+    # if service finds new facts:
+    #     -emit a signal?
+    #     - or just update properties
+    #       - and set a 'been_synced' property to False
+    # client waits for facts check to finish
+    # if no changes or been_synced=True, continue
+    # if changes or unsynced:
+    #    subman updates candlepin with the latest version of services GetFacts() [blocking]
+    #    when finished, subman emit's 'factsSyncFinished'
+    #        - then service flops 'been_synced' property
+    #    -or- subman calls 'here_are_the_latest_facts_to_the_server()' on service
+    #         then service flops 'been_synced' property
+    # subman gets signal that props changed, and that been_synced is now true
+    # since it's been synced, then subman continues
+    require(FACTS).update_check(uep, consumer_uuid)
 
     profile_mgr = cache.ProfileManager()
     profile_mgr.update_check(uep, consumer_uuid)
@@ -281,14 +295,11 @@ def list_pools(uep, consumer_uuid, facts, list_all=False, active_on=None, filter
 # TODO: This method is morphing the actual pool json and returning a new
 # dict which does not contain all the pool info. Not sure if this is really
 # necessary. Also some "view" specific things going on in here.
-def get_available_entitlements(facts, get_all=False, active_on=None,
-        overlapping=False, uninstalled=False, text=None, filter_string=None):
+def get_available_entitlements(get_all=False, active_on=None, overlapping=False,
+                               uninstalled=False, text=None, filter_string=None):
     """
     Returns a list of entitlement pools from the server.
 
-    Facts will be updated if appropriate before making the request, to ensure
-    the rules on the server will pass if appropriate.
-
     The 'all' setting can be used to return all pools, even if the rules do
     not pass. (i.e. show pools that are incompatible for your hardware)
     """
@@ -309,7 +320,7 @@ def get_available_entitlements(facts, get_all=False, active_on=None,
         'management_enabled'
     ]
 
-    pool_stash = PoolStash(Facts(require(ENT_DIR), require(PROD_DIR)))
+    pool_stash = PoolStash()
     dlist = pool_stash.get_filtered_pools_list(active_on, not get_all,
            overlapping, uninstalled, text, filter_string)
 
@@ -444,9 +455,8 @@ class PoolStash(object):
     Object used to fetch pools from the server, sort them into compatible,
     incompatible, and installed lists. Also does filtering based on name.
     """
-    def __init__(self, facts):
+    def __init__(self):
         self.identity = require(IDENTITY)
-        self.facts = facts
         self.sorter = None
 
         # Pools which passed rules server side for this consumer:
@@ -477,7 +487,7 @@ def refresh(self, active_on):
         self.compatible_pools = {}
         log.debug("Refreshing pools from server...")
         for pool in list_pools(require(CP_PROVIDER).get_consumer_auth_cp(),
-                self.identity.uuid, self.facts, active_on=active_on):
+                self.identity.uuid, active_on=active_on):
             self.compatible_pools[pool['id']] = pool
             self.all_pools[pool['id']] = pool
 
@@ -485,7 +495,7 @@ def refresh(self, active_on):
         # Sadly this currently requires a second query to the server.
         self.incompatible_pools = {}
         for pool in list_pools(require(CP_PROVIDER).get_consumer_auth_cp(),
-                self.identity.uuid, self.facts, list_all=True, active_on=active_on):
+                self.identity.uuid, list_all=True, active_on=active_on):
             if not pool['id'] in self.compatible_pools:
                 self.incompatible_pools[pool['id']] = pool
                 self.all_pools[pool['id']] = pool
@@ -516,11 +526,11 @@ def get_filtered_pools_list(self, active_on, incompatible,
 
         if incompatible:
             for pool in list_pools(require(CP_PROVIDER).get_consumer_auth_cp(),
-                    self.identity.uuid, self.facts, active_on=active_on, filter_string=filter_string):
+                    self.identity.uuid, active_on=active_on, filter_string=filter_string):
                 self.compatible_pools[pool['id']] = pool
         else:  # --all has been used
             for pool in list_pools(require(CP_PROVIDER).get_consumer_auth_cp(),
-                    self.identity.uuid, self.facts, list_all=True, active_on=active_on, filter_string=filter_string):
+                    self.identity.uuid, list_all=True, active_on=active_on, filter_string=filter_string):
                 self.all_pools[pool['id']] = pool
 
         return self._filter_pools(incompatible, overlapping, uninstalled, False, text)
@@ -862,7 +872,9 @@ def clean_all_data(backup=True):
     # for deleting persistent caches
     cache.ProfileManager.delete_cache()
     cache.InstalledProductsManager.delete_cache()
-    Facts.delete_cache()
+
+    # FIXME: implement as dbus client to facts service DeleteCache() once implemented
+    #Facts.delete_cache()
 
     # WrittenOverridesCache is also a subclass of cache.CacheManager, but
     # it is deleted in RepoActionInvoker.delete_repo_file() below.
diff --git a/src/subscription_manager/migrate/migrate.py b/src/subscription_manager/migrate/migrate.py
index 32b80014b0..a3d9ee45f6 100755
--- a/src/subscription_manager/migrate/migrate.py
+++ b/src/subscription_manager/migrate/migrate.py
@@ -25,8 +25,6 @@
 import subprocess
 import sys
 
-import rhsm.config
-
 from datetime import datetime
 from rhsm.https import ssl
 
@@ -46,6 +44,9 @@
 from rhsm.utils import parse_url
 from rhsm import ourjson as json
 
+from rhsm.config import initConfig
+from rhsmlib.services import config
+
 _RHNLIBPATH = "/usr/share/rhn"
 if _RHNLIBPATH not in sys.path:
     sys.path.append(_RHNLIBPATH)
@@ -157,7 +158,7 @@ def __init__(self, username, password):
 class MigrationEngine(object):
     def __init__(self, options):
         self.rhncfg = initUp2dateConfig()
-        self.rhsmcfg = rhsm.config.initConfig()
+        self.rhsmcfg = config.Config(initConfig())
 
         # Sometimes we need to send up the entire contents of the system id file
         # which is referred to in Satellite 5 nomenclature as a "certificate"
@@ -226,25 +227,25 @@ def transfer_http_proxy_settings(self):
             if self.options.noproxy:
                 # If the user doesn't want to use a proxy to connect to their subscription
                 # management server, then remove any proxy information that may have crept in.
-                self.rhsmcfg.set('server', 'proxy_hostname', '')
-                self.rhsmcfg.set('server', 'proxy_port', '')
-                self.rhsmcfg.set('server', 'proxy_user', '')
-                self.rhsmcfg.set('server', 'proxy_password', '')
+                self.rhsmcfg['server']['proxy_hostname'] = ''
+                self.rhsmcfg['server']['proxy_port'] = ''
+                self.rhsmcfg['server']['proxy_user'] = ''
+                self.rhsmcfg['server']['proxy_password'] = ''
             else:
-                self.rhsmcfg.set('server', 'proxy_hostname', self.proxy_host)
-                self.rhsmcfg.set('server', 'proxy_port', self.proxy_port)
-                self.rhsmcfg.set('server', 'proxy_user', self.proxy_user or '')
-                self.rhsmcfg.set('server', 'proxy_password', self.proxy_pass or '')
-            self.rhsmcfg.save()
+                self.rhsmcfg['server']['proxy_hostname'] = self.proxy_host
+                self.rhsmcfg['server']['proxy_port'] = self.proxy_port
+                self.rhsmcfg['server']['proxy_user'] = self.proxy_user or ''
+                self.rhsmcfg['server']['proxy_password'] = self.proxy_pass or ''
+            self.rhsmcfg.persist()
 
     def _get_connection_info(self):
         url_parse_error = os.EX_USAGE
         try:
             if self.options.destination_url is None:
                 url_parse_error = os.EX_CONFIG
-                hostname = self.rhsmcfg.get('server', 'hostname')
-                port = self.rhsmcfg.get_int('server', 'port')
-                prefix = self.rhsmcfg.get('server', 'prefix')
+                hostname = self.rhsmcfg['server']['hostname']
+                port = self.rhsmcfg['server'].get_int('port')
+                prefix = self.rhsmcfg['server']['prefix']
             else:
                 (_user, _password, hostname, port, prefix) = parse_url(self.options.destination_url, default_port=443)
         except ServerUrlParseError, e:
@@ -961,8 +962,8 @@ def validate_options(options):
 
 
 def is_hosted():
-    rhsmcfg = rhsm.config.initConfig()
-    hostname = rhsmcfg.get('server', 'hostname')
+    rhsmcfg = config.Config(initConfig())
+    hostname = rhsmcfg['server']['hostname']
     return bool(re.search('subscription\.rhn\.(.*\.)*redhat\.com', hostname) or
                 re.search('subscription\.rhsm\.(.*\.)*redhat\.com', hostname))
 
diff --git a/src/subscription_manager/plugin/ostree/config.py b/src/subscription_manager/plugin/ostree/config.py
index fcf6a3e690..c13b7786f7 100644
--- a/src/subscription_manager/plugin/ostree/config.py
+++ b/src/subscription_manager/plugin/ostree/config.py
@@ -16,8 +16,10 @@
 import logging
 import os
 
-from rhsm import config
+from rhsm.config import initConfig, RhsmConfigParser
+from rhsm.config import NoSectionError  # noqa: F401 Imported so we can catch elsewhere
 from subscription_manager import utils
+from rhsmlib.services import config
 
 # iniparse.utils isn't in old versions
 # but it's always there if ostree is
@@ -29,7 +31,7 @@
 
 log = logging.getLogger(__name__)
 
-CFG = config.initConfig()
+conf = config.Config(initConfig())
 
 """Ostree has two config files, both based on the freedesktop.org
 Desktop Entry spec. This defines a file format based on "ini" style
@@ -63,7 +65,7 @@ class RefspecFormatException(Exception):
 
 
 # KeyFile is the desktop.org name for ini files, more or less
-class KeyFileConfigParser(config.RhsmConfigParser):
+class KeyFileConfigParser(RhsmConfigParser):
     """A ini/ConfigParser subclass based on RhsmConfigParser.
 
     This impl removes the RhsmConfigParser support for rhsm.config.DEFAULTS.
@@ -76,8 +78,8 @@ class KeyFileConfigParser(config.RhsmConfigParser):
     # but we also don't want to monkeypatch our config module.
     #
     # why? useful convience methods on RhsmConfigParser
-    # why not pyxdg xdg.IniFile? woudl still have to add type casts
-    # why noy pyxdg xdg.DesktopEntry?  the repo configs are not actually
+    # why not pyxdg xdg.IniFile? would still have to add type casts
+    # why not pyxdg xdg.DesktopEntry?  the repo configs are not actually
     #    desktop files, just that format, so that class throws exceptions
     #    in that case.
     def defaults(self):
@@ -173,11 +175,11 @@ def set(self, section, key, value):
         return self.config_parser.set(section, key, value)
 
     def get_proxy(self):
-        proxy_host = CFG.get('server', 'proxy_hostname')
+        proxy_host = conf['server']['proxy_hostname']
         # proxy_port as string is fine here
-        proxy_port = CFG.get('server', 'proxy_port')
-        proxy_user = CFG.get('server', 'proxy_user')
-        proxy_password = CFG.get('server', 'proxy_password')
+        proxy_port = conf['server']['proxy_port']
+        proxy_user = conf['server']['proxy_user']
+        proxy_password = conf['server']['proxy_password']
 
         proxy_uri = None
         if proxy_host == "":
@@ -205,8 +207,8 @@ def set_remote(self, ostree_remote):
         # Assume all remotes will share the same cdn
         # This is really info about a particular CDN, we just happen
         # to only support one at the moment.
-        baseurl = CFG.get('rhsm', 'baseurl')
-        ca_cert = CFG.get('rhsm', 'repo_ca_cert')
+        baseurl = conf['rhsm']['baseurl']
+        ca_cert = conf['rhsm']['repo_ca_cert']
 
         full_url = utils.url_base_join(baseurl, ostree_remote.url)
 
diff --git a/src/subscription_manager/plugins.py b/src/subscription_manager/plugins.py
index 4fd96adb75..35b24df5ce 100644
--- a/src/subscription_manager/plugins.py
+++ b/src/subscription_manager/plugins.py
@@ -631,7 +631,7 @@ def is_plugin(c):
         # find all the plugin classes with valid configs first
         # then add them, so we skip the module if a class has a bad config
         found_plugin_classes = []
-        for name, clazz in sorted(plugin_classes):
+        for _name, clazz in sorted(plugin_classes):
 
             # We could have the module conf here, and check in that
             # instead of a per class config. We would not be able to
diff --git a/src/subscription_manager/productid.py b/src/subscription_manager/productid.py
index 99b9d911e5..4ec5c73207 100644
--- a/src/subscription_manager/productid.py
+++ b/src/subscription_manager/productid.py
@@ -604,7 +604,7 @@ def _list_has_workstation_and_desktop_cert(self, product_cert_list):
         """determine if product cert list has desktop and workstation certs"""
         has_workstation = False
         has_desktop = False
-        for product, product_cert in product_cert_list:
+        for product, _product_cert in product_cert_list:
             if self._is_workstation(product):
                 has_workstation = True
             if self._is_desktop(product):
diff --git a/src/subscription_manager/repolib.py b/src/subscription_manager/repolib.py
index 8a5569808b..9b1bd66840 100644
--- a/src/subscription_manager/repolib.py
+++ b/src/subscription_manager/repolib.py
@@ -36,10 +36,11 @@
 
 from subscription_manager.certlib import ActionReport, BaseActionInvoker
 from subscription_manager.certdirectory import Path
+from rhsmlib.services import config
 
 log = logging.getLogger(__name__)
 
-CFG = initConfig()
+conf = config.Config(initConfig())
 
 ALLOWED_CONTENT_TYPES = ["yum"]
 
@@ -49,7 +50,7 @@
 def manage_repos_enabled():
     manage_repos = True
     try:
-        manage_repos = CFG.get_int('rhsm', 'manage_repos')
+        manage_repos = conf['rhsm'].get_int('manage_repos')
     except ValueError, e:
         log.exception(e)
         return True
@@ -316,8 +317,8 @@ def get_unique_content(self):
 
         # baseurl and ca_cert could be "CDNInfo" or
         # bundle with "ConnectionInfo" etc
-        baseurl = CFG.get('rhsm', 'baseurl')
-        ca_cert = CFG.get('rhsm', 'repo_ca_cert')
+        baseurl = conf['rhsm']['baseurl']
+        ca_cert = conf['rhsm']['repo_ca_cert']
 
         content_list = self.get_all_content(baseurl, ca_cert)
 
@@ -325,7 +326,7 @@ def get_unique_content(self):
         return set(content_list)
 
     # Expose as public API for RepoActionInvoker.is_managed, since that
-    # is used by openshift tooling.
+    # is used by Openshift tooling.
     # See https://bugzilla.redhat.com/show_bug.cgi?id=1223038
     def matching_content(self):
         return model.find_content(self.ent_source,
@@ -390,7 +391,7 @@ def update_repo(self, old_repo, new_repo):
         """
         changes_made = 0
 
-        for key, (mutable, default) in self._build_props(old_repo, new_repo).items():
+        for key, (mutable, _default) in self._build_props(old_repo, new_repo).items():
             new_val = new_repo.get(key)
 
             # Mutable properties should be added if not currently defined,
@@ -522,7 +523,7 @@ def __init__(self, repo_id, existing_values=None):
         # NOTE: This sets the above properties to the default values even if
         # they are not defined on disk. i.e. these properties will always
         # appear in this dict, but their values may be None.
-        for k, (m, d) in self.PROPERTIES.items():
+        for k, (_m, d) in self.PROPERTIES.items():
             if k not in self.keys():
                 self[k] = d
 
@@ -575,9 +576,9 @@ def _set_proxy_info(repo):
 
         # Worth passing in proxy config info to from_ent_cert_content()?
         # That would decouple Repo some
-        proxy_host = CFG.get('server', 'proxy_hostname')
+        proxy_host = conf['server']['proxy_hostname']
         # proxy_port as string is fine here
-        proxy_port = CFG.get('server', 'proxy_port')
+        proxy_port = conf['server']['proxy_port']
         if proxy_host != "":
             proxy = "https://%s" % proxy_host
             if proxy_port != "":
@@ -586,8 +587,8 @@ def _set_proxy_info(repo):
         # These could be empty string, in which case they will not be
         # set in the yum repo file:
         repo['proxy'] = proxy
-        repo['proxy_username'] = CFG.get('server', 'proxy_user')
-        repo['proxy_password'] = CFG.get('server', 'proxy_password')
+        repo['proxy_username'] = conf['server']['proxy_user']
+        repo['proxy_password'] = conf['server']['proxy_password']
 
         return repo
 
diff --git a/src/subscription_manager/rhelentbranding.py b/src/subscription_manager/rhelentbranding.py
index 3334c066f5..60a299c246 100644
--- a/src/subscription_manager/rhelentbranding.py
+++ b/src/subscription_manager/rhelentbranding.py
@@ -79,7 +79,7 @@ def _get_branded_cert_product(self):
         # same product, with the same branded name.
 
         branded_name_set = set([])
-        for cert, product in branded_certs:
+        for _cert, product in branded_certs:
             # uniq on product id and product name
             branded_name_set.add(product.brand_name)
 
diff --git a/src/subscription_manager/utils.py b/src/subscription_manager/utils.py
index 2b2495a740..776d8d2340 100644
--- a/src/subscription_manager/utils.py
+++ b/src/subscription_manager/utils.py
@@ -67,9 +67,9 @@ def parse_server_info(local_server_entry, config=None):
     port = ''
     prefix = ''
     if config is not None:
-        hostname = config.get("server", "hostname")
-        port = config.get("server", "port")
-        prefix = config.get("server", "prefix")
+        hostname = config["server"]["hostname"]
+        port = config["server"]["port"]
+        prefix = config["server"]["prefix"]
     return parse_url(local_server_entry,
                       hostname or DEFAULT_HOSTNAME,
                       port or DEFAULT_PORT,
@@ -501,7 +501,7 @@ def print_error(message):
     sys.stderr.write("\n")
 
 
-def unique_list_items(list, hash_function=lambda x: x):
+def unique_list_items(l, hash_function=lambda x: x):
     """
     Accepts a list of items.
     Returns a list of the unique items in the input.
@@ -509,7 +509,7 @@ def unique_list_items(list, hash_function=lambda x: x):
     """
     observed = set()
     unique_items = []
-    for item in list:
+    for item in l:
         item_key = hash_function(item)
         if item_key in observed:
             continue
diff --git a/subscription-manager.spec b/subscription-manager.spec
index 4c84063002..9a881f100a 100644
--- a/subscription-manager.spec
+++ b/subscription-manager.spec
@@ -77,8 +77,10 @@ BuildRoot: %{_tmppath}/%{name}-%{version}-%{release}-root-%(%{__id_u} -n)
 
 Requires:  python-ethtool
 Requires:  python-iniparse
+Requires:  python-decorator
+Requires:  dbus-x11
 Requires:  virt-what
-Requires:  python-rhsm >= 1.18.1
+Requires:  python-rhsm > 1.18.4
 Requires:  python-decorator
 
 %if 0%{?sles_version}
@@ -218,6 +220,7 @@ Summary: Subscription Manager plugins for DNF
 Group: System Environment/Base
 Requires: %{name} = %{version}-%{release}
 Requires: dnf >= 1.0.0
+Requires: python2-dnf-plugins-core
 
 %description -n dnf-plugin-subscription-manager
 This package provides plugins to interact with repositories and subscriptions
@@ -330,14 +333,6 @@ rm -rf %{buildroot}
 %attr(755,root,root) %{_libexecdir}/rhsmcertd-worker
 %attr(755,root,root) %{_libexecdir}/rhsmd
 
-# init scripts and systemd services
-%if %use_systemd
-    %attr(644,root,root) %{_unitdir}/rhsmcertd.service
-    %attr(644,root,root) %{_tmpfilesdir}/%{name}.conf
-%else
-    %attr(755,root,root) %{_initrddir}/rhsmcertd
-%endif
-
 # our config dirs and files
 %attr(755,root,root) %dir %{_sysconfdir}/pki/consumer
 %attr(755,root,root) %dir %{_sysconfdir}/pki/entitlement
@@ -346,8 +341,6 @@ rm -rf %{buildroot}
 %attr(644,root,root) %config(noreplace) %{_sysconfdir}/rhsm/rhsm.conf
 %config %attr(644,root,root) %{_sysconfdir}/rhsm/logging.conf
 
-%config(noreplace) %{_sysconfdir}/dbus-1/system.d/com.redhat.SubscriptionManager.conf
-
 # PAM config
 %if !0%{?sles_version}
 %{_sysconfdir}/pam.d/subscription-manager
@@ -365,7 +358,6 @@ rm -rf %{buildroot}
 # misc system config
 %config(noreplace) %attr(644,root,root) %{_sysconfdir}/logrotate.d/subscription-manager
 %attr(700,root,root) %{_sysconfdir}/cron.daily/rhsmd
-%{_datadir}/dbus-1/system-services/com.redhat.SubscriptionManager.service
 
 %attr(755,root,root) %dir %{_var}/log/rhsm
 %attr(755,root,root) %dir %{_var}/spool/rhsm/debug
@@ -382,12 +374,7 @@ rm -rf %{buildroot}
 %{_sysconfdir}/bash_completion.d/rhsm-icon
 %{_sysconfdir}/bash_completion.d/rhsmcertd
 
-%dir %{python_sitelib}/
 %dir %{python_sitelib}/subscription_manager
-%dir %{python_sitelib}/subscription_manager/api
-%dir %{python_sitelib}/subscription_manager/branding
-%dir %{python_sitelib}/subscription_manager/model
-%dir %{python_sitelib}/subscription_manager/plugin
 
 # code, python modules and packages
 %{python_sitelib}/subscription_manager-*.egg-info/*
@@ -419,6 +406,30 @@ rm -rf %{buildroot}
 %{_prefix}/lib/yum-plugins/product-id.py*
 %{_prefix}/lib/yum-plugins/search-disabled-repos.py*
 
+# rhsmlib
+%dir %{python_sitelib}/rhsmlib
+%{python_sitelib}/rhsmlib/*.py*
+%{python_sitelib}/rhsmlib/candlepin/*.py*
+%{python_sitelib}/rhsmlib/compat/*.py*
+%{python_sitelib}/rhsmlib/facts/*.py*
+%{python_sitelib}/rhsmlib/services/*.py*
+%{python_sitelib}/rhsmlib/dbus/*.py*
+%{python_sitelib}/rhsmlib/dbus/facts/*.py*
+%{python_sitelib}/rhsmlib/dbus/objects/*.py*
+
+%{_datadir}/polkit-1/actions/com.redhat.*.policy
+%{_datadir}/dbus-1/system-services/com.redhat.*.service
+%attr(755,root,root) %{_libexecdir}/rhsm*-service
+
+# Despite the name similarity dbus-1/system.d has nothing to do with systemd
+%config(noreplace) %{_sysconfdir}/dbus-1/system.d/com.redhat.*.conf
+%if %use_systemd
+    %attr(644,root,root) %{_unitdir}/*.service
+    %attr(644,root,root) %{_tmpfilesdir}/%{name}.conf
+%else
+    %attr(755,root,root) %{_initrddir}/rhsmcertd
+%endif
+
 # Incude rt CLI tool
 %dir %{python_sitelib}/rct
 %{python_sitelib}/rct/*.py*
@@ -448,11 +459,6 @@ rm -rf %{buildroot}
 %{_bindir}/rhsm-icon
 
 %dir %{python_sitelib}/subscription_manager/gui
-%dir %{python_sitelib}/subscription_manager/gui/data
-%dir %{python_sitelib}/subscription_manager/gui/data/ui
-%dir %{python_sitelib}/subscription_manager/gui/data/glade
-%dir %{python_sitelib}/subscription_manager/gui/data/icons
-
 %{python_sitelib}/subscription_manager/gui/*.py*
 %{python_sitelib}/subscription_manager/gui/data/ui/*.ui
 %{python_sitelib}/subscription_manager/gui/data/glade/*.glade
@@ -521,10 +527,6 @@ rm -rf %{buildroot}
 %files -n subscription-manager-initial-setup-addon
 %defattr(-,root,root,-)
 %dir %{_datadir}/anaconda/addons/com_redhat_subscription_manager/
-%dir %{_datadir}/anaconda/addons/com_redhat_subscription_manager/gui/
-%dir %{_datadir}/anaconda/addons/com_redhat_subscription_manager/gui/spokes/
-%dir %{_datadir}/anaconda/addons/com_redhat_subscription_manager/categories/
-%dir %{_datadir}/anaconda/addons/com_redhat_subscription_manager/ks/
 %{_datadir}/anaconda/addons/com_redhat_subscription_manager/*.py*
 %{_datadir}/anaconda/addons/com_redhat_subscription_manager/gui/*.py*
 %{_datadir}/anaconda/addons/com_redhat_subscription_manager/gui/spokes/*.ui
diff --git a/test-requirements.txt b/test-requirements.txt
index 0791d95b32..75410cb52b 100644
--- a/test-requirements.txt
+++ b/test-requirements.txt
@@ -1,3 +1,4 @@
+-r requirements.txt
 lxml
 nose
 nose-capturestderr
@@ -6,7 +7,7 @@ coverage
 polib
 pep8==1.5.7
 pyflakes
-flake8==3.0.2
+flake8==3.0.4
 freezegun
 simplejson
 mock
diff --git a/test/fixture.py b/test/fixture.py
index db09e595ca..a7f8e11482 100644
--- a/test/fixture.py
+++ b/test/fixture.py
@@ -26,16 +26,23 @@
 import stubs
 import subscription_manager.injection as inj
 import subscription_manager.managercli
+from rhsmlib.services import config
 
 # use instead of the normal pid file based ActionLock
 from threading import RLock
 
 
 @contextmanager
-def open_mock(content, **kwargs):
+def open_mock(content=None, **kwargs):
+    content_out = StringIO.StringIO()
     m = mock_open(read_data=content)
-    with patch('__builtin__.open', m, create=True, **kwargs) as m:
-        yield m
+    with patch('__builtin__.open', m, create=True, **kwargs) as mo:
+        stream = StringIO.StringIO(content)
+        rv = mo.return_value
+        rv.write = lambda x: content_out.write(x)
+        rv.content_out = lambda: content_out.getvalue()
+        rv.__iter__ = lambda x: iter(stream.readlines())
+        yield rv
 
 
 @contextmanager
@@ -108,18 +115,38 @@ def __eq__(self, other):
 
 
 class SubManFixture(unittest.TestCase):
+    def set_facts(self):
+        """Override if you need to set facts for a test."""
+        return {"mock.facts": "true"}
+
     """
     Can be extended by any subscription manager test case to make
     sure nothing on the actual system is read/touched, and appropriate
     mocks/stubs are in place.
     """
     def setUp(self):
+        # No matter what, stop all patching (even if we have a failure in setUp itself)
         self.addCleanup(patch.stopall)
 
         # Never attempt to use the actual managercli.cfg which points to a
         # real file in etc.
-        cfg_patcher = patch.object(subscription_manager.managercli, 'cfg', new=stubs.config.CFG)
-        self.mock_cfg = cfg_patcher.start()
+
+        self.mock_cfg_parser = stubs.StubConfig()
+
+        original_conf = subscription_manager.managercli.conf
+
+        def unstub_conf():
+            subscription_manager.managercli.conf = original_conf
+
+        # Mock makes it damn near impossible to mock a module attribute (which we shouldn't be using
+        # in the first place because it's terrible) so we monkey-patch it ourselves.
+        # TODO Fix this idiocy by not reading the damn config on module import
+        subscription_manager.managercli.conf = config.Config(self.mock_cfg_parser)
+        self.addCleanup(unstub_conf)
+
+        facts_host_patcher = patch('rhsmlib.dbus.facts.FactsClient', auto_spec=True)
+        self.mock_facts_host = facts_host_patcher.start()
+        self.mock_facts_host.return_value.GetFacts.return_value = self.set_facts()
 
         # By default mock that we are registered. Individual test cases
         # can override if they are testing disconnected scenario.
@@ -244,7 +271,7 @@ def _inject_mock_valid_consumer(self, uuid=None):
         return identity
 
     def _inject_mock_invalid_consumer(self, uuid=None):
-        """For chaning injected consumer identity to one that fails is_valid()
+        """For chaining injected consumer identity to one that fails is_valid()
 
         Returns the injected identity if it need to be examined.
         """
diff --git a/test/rhsmlib_test/__init__.py b/test/rhsmlib_test/__init__.py
new file mode 100644
index 0000000000..e69de29bb2
diff --git a/test/rhsmlib_test/base.py b/test/rhsmlib_test/base.py
new file mode 100644
index 0000000000..7298d71b92
--- /dev/null
+++ b/test/rhsmlib_test/base.py
@@ -0,0 +1,233 @@
+#! /usr/bin/env python
+#
+# Copyright (c) 2011 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public
+# License as published by the Free Software Foundation; either version
+# 2 of the License (GPLv2) or (at your option) any later version.
+# There is NO WARRANTY for this software, express or implied,
+# including the implied warranties of MERCHANTABILITY,
+# NON-INFRINGEMENT, or FITNESS FOR A PARTICULAR PURPOSE. You should
+# have received a copy of GPLv2 along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+from tempfile import NamedTemporaryFile
+
+try:
+    import unittest2 as unittest
+except ImportError:
+    import unittest
+
+import os
+import sys
+import dbus
+import dbus.lowlevel
+import dbus.bus
+import dbus.mainloop.glib
+import functools
+import logging
+import threading
+import Queue
+
+from rhsmlib.dbus import constants, server
+
+# Set DBus mainloop early in test run (test import time!)
+dbus.mainloop.glib.DBusGMainLoop(set_as_default=True)
+logger = logging.getLogger(__name__)
+
+
+class TestUtilsMixin(object):
+    def assert_items_equals(self, a, b):
+        """Assert that two lists contain the same items regardless of order."""
+        if sorted(a) != sorted(b):
+            self.fail("%s != %s" % (a, b))
+        return True
+
+    def write_temp_file(self, data):
+        # create a temp file for use as a config file. This should get cleaned
+        # up magically when it is closed so make sure to close it!
+        fid = NamedTemporaryFile(mode='w+b', suffix='.tmp')
+        fid.write(data)
+        fid.seek(0)
+        return fid
+
+
+class DBusObjectTest(unittest.TestCase):
+    '''Subclass of unittest.TestCase use for testing DBus methods in the same process.  During setUp this
+    class starts a thread that makes a DBus connection and exposes some objects on the bus.  The main thread
+    blocks until the connection has completed.
+
+    When the main thread reaches a test case, the test case needs to call dbus_request() and pass in a DBus
+    proxy object and a function to run after the DBus call has received a response.  The dbus_request method
+    starts another thread that makes an async call to the thread serving the objects under test and then
+    blocks the main thread (the DBus call must be asynchronous to avoid deadlock).  The function passed to
+    dbus_request is run and then dbus_request unblocks the main thread.
+    '''
+    def setUp(self):
+        self.started_event = threading.Event()
+        self.stopped_event = threading.Event()
+        self.handler_complete_event = threading.Event()
+
+        # If we don't use a BusConnection and use say dbus.SessionBus() directly, each test will end up
+        # getting old bus connections since the dbus bindings cache bus connections.  You can use the private
+        # kwarg to tell dbus.SessionBus/SystemBus not to cache, but that's deprecated.
+        self.server_thread = ServerThread(kwargs={
+            'object_classes': self.dbus_objects(),
+            'bus_name': self.bus_name(),
+            'bus_class': dbus.bus.BusConnection,
+            'bus_kwargs': self.bus_kwargs,
+            'started_event': self.started_event,
+            'stopped_event': self.stopped_event,
+        })
+        self.started_event.wait()
+        self.result_queue = Queue.Queue(maxsize=1)
+        self.addCleanup(self.stop_server)
+
+    def stop_server(self):
+        self.server_thread.stop()
+        self.stopped_event.wait()
+
+    @property
+    def bus_kwargs(self):
+        if os.geteuid() == 0:
+            return {'address_or_type': dbus.Bus.TYPE_SYSTEM}
+        else:
+            return {'address_or_type': dbus.Bus.TYPE_SESSION}
+
+    def proxy_for(self, path):
+        return dbus.bus.BusConnection(**self.bus_kwargs).get_object(self.bus_name(), path)
+
+    def dbus_request(self, reply_handler, proxy, proxy_args=None, error_handler=None):
+        '''This method makes an async request to the server thread and *does not* block.  It is
+        unlikely that you will want to use this since not blocking means that the rest of your test case
+        will run potentially before the async callback finishes.  If you do need this method,
+        you will still almost certainly need to call self.handler_complete_event.wait() at the end of your
+        test so that the test runner itself will block until the async callback finishes.'''
+
+        DBusRequestThread(kwargs={
+            'proxy': proxy,
+            'proxy_args': proxy_args,
+            'reply_handler': reply_handler,
+            'error_handler': error_handler,
+            'handler_complete_event': self.handler_complete_event,
+            'queue': self.result_queue
+        })
+        self.handler_complete_event.wait()
+        # Raise any exception generated by the handlers.  I.e. actually fail a test if assertions failed in
+        # the DBusRequestThread
+        if not self.result_queue.empty():
+            result = self.result_queue.get()
+            raise result[0], result[1], result[2]
+
+    def dbus_objects(self):
+        '''This method should return a list of DBus service classes that need to be instantiated in the
+        server thread.  Generally this should just be a list containing the class under test.
+        In that list, you can also pass in a tuple composed of the object class and a dictionary of keyword
+        arguments for the object's constructor
+        '''
+        raise NotImplementedError('Subclasses should define what DBus objects to test')
+
+    def bus_name(self):
+        '''This method should return the bus name that the server thread should use'''
+        return constants.BUS_NAME
+
+
+class ServerThread(threading.Thread):
+    def __init__(self, **kwds):
+        super(ServerThread, self).__init__(name=self.__class__.__name__, **kwds)
+        kwargs = kwds['kwargs']
+        self.bus_class = kwargs.get('bus_class', dbus.bus.BusConnection(dbus.bus.BUS_SESSION))
+        self.bus_name = kwargs.get('bus_name', constants.BUS_NAME)
+        self.object_classes = kwargs.get('object_classes', [])
+        self.started_event = kwargs['started_event']
+        self.stopped_event = kwargs['stopped_event']
+        self.bus_kwargs = kwargs['bus_kwargs']
+        self.server = None
+        self.start()
+
+    def run(self):
+        try:
+            self.server = server.Server(
+                bus_class=self.bus_class,
+                bus_name=self.bus_name,
+                object_classes=self.object_classes,
+                bus_kwargs=self.bus_kwargs)
+            self.server.run(self.started_event, self.stopped_event)
+        except Exception as e:
+            logger.exception(e)
+            self.started_event.set()
+
+    def stop(self):
+        if self.server:
+            self.server.shutdown()
+
+
+class DBusRequestThread(threading.Thread):
+    def __init__(self, **kwds):
+        super(DBusRequestThread, self).__init__(name=self.__class__.__name__, **kwds)
+        kwargs = kwds['kwargs']
+        self.queue = kwargs['queue']
+        self.proxy = kwargs['proxy']
+        self.proxy_args = kwargs['proxy_args']
+
+        if self.proxy_args is None:
+            self.proxy_args = []
+
+        self.reply_handler = self.reply_wrap(kwargs['reply_handler'])
+        # If no error_handler is given, error_wrap will just raise the DBus error
+        self.error_handler = self.error_wrap(kwargs.get('error_handler'))
+
+        self.handler_complete_event = kwargs['handler_complete_event']
+        self.start()
+
+    def reply_wrap(self, func):
+        def dummy():
+            pass
+
+        if func is None:
+            func = dummy
+
+        @functools.wraps(func)
+        def wrapper(*args, **kwargs):
+            try:
+                if func is not dummy:
+                    func(*args, **kwargs)
+            except Exception:
+                self.queue.put(sys.exc_info())
+            finally:
+                self.handler_complete_event.set()
+
+        return wrapper
+
+    def error_wrap(self, func=None):
+        def dummy():
+            pass
+
+        if func is None:
+            func = dummy
+
+        @functools.wraps(func)
+        def wrapper(*args, **kwargs):
+            try:
+                if func is not dummy:
+                    func(*args, **kwargs)
+                else:
+                    raise args[0]
+            except Exception:
+                self.queue.put(sys.exc_info())
+            finally:
+                self.handler_complete_event.set()
+
+        return wrapper
+
+    def run(self):
+        try:
+            self.proxy(
+                *self.proxy_args,
+                reply_handler=self.reply_handler,
+                error_handler=self.error_handler)
+        except Exception:
+            # If the proxy is messed up some how, we still need to push the error to the main thread and
+            # wake it.
+            self.queue.put(sys.exc_info())
+            self.handler_complete_event.set()
diff --git a/test/rhsmlib_test/test_collector.py b/test/rhsmlib_test/test_collector.py
new file mode 100644
index 0000000000..62b72d5fed
--- /dev/null
+++ b/test/rhsmlib_test/test_collector.py
@@ -0,0 +1,35 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+
+try:
+    import unittest2 as unittest
+except ImportError:
+    import unittest
+
+import mock
+from test.fixture import open_mock
+
+from rhsmlib.facts import collector
+
+
+class GetArchTest(unittest.TestCase):
+    @mock.patch('platform.machine')
+    def test_returns_arch(self, mock_machine):
+        mock_machine.return_value = "hello_arch"
+        arch = collector.get_arch()
+        self.assertEqual("hello_arch", arch)
+
+    def test_returns_arch_override(self):
+        with open_mock(content="hello_arch"):
+            arch = collector.get_arch(prefix="/does/not/exist")
+            self.assertEqual("hello_arch", arch)
diff --git a/test/rhsmlib_test/test_config.py b/test/rhsmlib_test/test_config.py
new file mode 100644
index 0000000000..224ada9947
--- /dev/null
+++ b/test/rhsmlib_test/test_config.py
@@ -0,0 +1,230 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+try:
+    import unittest2 as unittest
+except ImportError:
+    import unittest
+
+import dbus
+
+from rhsm.config import RhsmConfigParser, NoOptionError
+from rhsmlib.dbus import constants
+from rhsmlib.dbus.objects.config import ConfigDBusObject
+from rhsmlib.services.config import Config, ConfigSection
+from test.rhsmlib_test.base import DBusObjectTest, TestUtilsMixin
+
+TEST_CONFIG = """
+[foo]
+bar =
+quux = baz
+bigger_than_32_bit = 21474836470
+bigger_than_64_bit = 123456789009876543211234567890
+
+[server]
+hostname = server.example.com
+prefix = /candlepin
+port = 8443
+insecure = 1
+ssl_verify_depth = 3
+proxy_hostname =
+proxy_port =
+proxy_user =
+proxy_password =
+
+[rhsm]
+ca_cert_dir = /etc/rhsm/ca-test/
+baseurl= https://content.example.com
+repo_ca_cert = %(ca_cert_dir)sredhat-uep-non-default.pem
+productCertDir = /etc/pki/product
+entitlementCertDir = /etc/pki/entitlement
+consumerCertDir = /etc/pki/consumer
+report_package_profile = 1
+pluginDir = /usr/lib/rhsm-plugins
+some_option = %(repo_ca_cert)stest
+manage_repos =
+
+[rhsmcertd]
+certCheckInterval = 245
+
+[logging]
+default_log_level = DEBUG
+"""
+
+
+class BaseConfigTest(unittest.TestCase, TestUtilsMixin):
+    expected_sections = ['foo', 'server', 'rhsm', 'rhsmcertd', 'logging']
+
+    def setUp(self):
+        super(BaseConfigTest, self).setUp()
+        self.fid = self.write_temp_file(TEST_CONFIG)
+        self.parser = RhsmConfigParser(self.fid.name)
+        self.config = Config(self.parser)
+        self.addCleanup(self.fid.close)
+
+
+class TestConfig(BaseConfigTest):
+    def test_config_contains(self):
+        self.assertTrue('server' in self.config)
+        self.assertFalse('not_here' in self.config)
+
+    def test_config_len(self):
+        self.assertEquals(len(self.expected_sections), len(self.config))
+
+    def test_keys(self):
+        self.assert_items_equals(self.expected_sections, self.config.keys())
+
+    def test_values(self):
+        values = self.config.values()
+        for v in values:
+            self.assertIsInstance(v, ConfigSection)
+
+    def test_set_new_section(self):
+        self.config['new_section'] = {'hello': 'world'}
+        self.assertEquals(['hello'], self.config._parser.options('new_section'))
+        self.assertEquals('world', self.config._parser.get('new_section', 'hello'))
+
+    def test_set_old_section(self):
+        self.config['foo'] = {'hello': 'world'}
+        self.assertEquals(['hello'], self.config._parser.options('foo'))
+        self.assertEquals('world', self.config._parser.get('foo', 'hello'))
+        self.assertRaises(NoOptionError, self.config._parser.get, 'foo', 'quux')
+
+    def test_get_item(self):
+        self.assertIsInstance(self.config['server'], ConfigSection)
+
+    def test_persist(self):
+        self.config['foo'] = {'hello': 'world'}
+        self.config.persist()
+        reparsed = RhsmConfigParser(self.fid.name)
+        self.assertEquals('world', reparsed.get('foo', 'hello'))
+        self.assertRaises(NoOptionError, reparsed.get, 'foo', 'quux')
+
+    def test_auto_persists(self):
+        config = Config(self.parser, auto_persist=True)
+        config['foo'] = {'hello': 'world'}
+        reparsed = RhsmConfigParser(self.fid.name)
+        self.assertEquals('world', reparsed.get('foo', 'hello'))
+        self.assertRaises(NoOptionError, reparsed.get, 'foo', 'quux')
+
+    def test_does_not_auto_persist_by_default(self):
+        config = Config(self.parser, auto_persist=False)
+        config['foo'] = {'hello': 'world'}
+        reparsed = RhsmConfigParser(self.fid.name)
+        self.assertEquals('baz', reparsed.get('foo', 'quux'))
+        self.assertRaises(NoOptionError, reparsed.get, 'foo', 'hello')
+
+    def test_del_item(self):
+        del self.config['foo']
+        self.assertFalse(self.config._parser.has_section('foo'))
+
+    def test_iter(self):
+        sections = [s for s in self.config]
+        self.assert_items_equals(self.expected_sections, sections)
+
+
+class TestConfigSection(BaseConfigTest):
+    def test_get_value(self):
+        self.assertEquals('1', self.config['server']['insecure'])
+
+    def test_get_missing_value(self):
+        with self.assertRaises(KeyError):
+            self.config['server']['missing']
+
+    def test_set_item(self):
+        self.assertEquals('baz', self.config['foo']['quux'])
+        self.config['foo']['quux'] = 'fizz'
+        self.assertEquals('fizz', self.config['foo']['quux'])
+
+    def test_auto_persist(self):
+        config = Config(self.parser, auto_persist=True)
+        self.assertEquals('baz', config['foo']['quux'])
+        config['foo']['quux'] = 'fizz'
+        self.assertEquals('fizz', config['foo']['quux'])
+
+        reparsed = RhsmConfigParser(self.fid.name)
+        self.assertEquals('fizz', reparsed.get('foo', 'quux'))
+
+    def test_persist_cascades(self):
+        config = Config(self.parser, auto_persist=False)
+        self.assertEquals('baz', config['foo']['quux'])
+        config['foo']['quux'] = 'fizz'
+        config.persist()
+        self.assertEquals('fizz', config['foo']['quux'])
+
+        reparsed = RhsmConfigParser(self.fid.name)
+        self.assertEquals('fizz', reparsed.get('foo', 'quux'))
+
+    def test_del_item(self):
+        del self.config['foo']['quux']
+        self.assertNotIn('quux', self.config['foo'])
+
+        with self.assertRaises(KeyError):
+            del self.config['foo']['missing_key']
+
+    def test_len(self):
+        self.assertEquals(4, len(self.config['foo']))
+
+    def test_in(self):
+        self.assertIn("quux", self.config['foo'])
+        self.assertNotIn("missing", self.config['foo'])
+
+
+class TestConfigDBusObject(DBusObjectTest, TestUtilsMixin):
+    def setUp(self):
+        super(TestConfigDBusObject, self).setUp()
+        self.proxy = self.proxy_for(ConfigDBusObject.default_dbus_path)
+        self.interface = dbus.Interface(self.proxy, constants.CONFIG_INTERFACE)
+
+    def dbus_objects(self):
+        self.fid = self.write_temp_file(TEST_CONFIG)
+        self.addCleanup(self.fid.close)
+        self.parser = RhsmConfigParser(self.fid.name)
+        return [(ConfigDBusObject, {'parser': self.parser})]
+
+    def test_get_all(self):
+        def assertions(*args):
+            result = args[0]
+            self.assertIn("server", result)
+
+        dbus_method_args = []
+        self.dbus_request(assertions, self.interface.GetAll, dbus_method_args)
+
+    def test_get_property(self):
+        def assertions(*args):
+            result = args[0]
+            self.assertIn('server.example.com', result)
+
+        dbus_method_args = ['server.hostname']
+        self.dbus_request(assertions, self.interface.Get, dbus_method_args)
+
+    def test_get_section(self):
+        def assertions(*args):
+            result = args[0]
+            self.assertIn('hostname', result)
+
+        dbus_method_args = ['server']
+        self.dbus_request(assertions, self.interface.Get, dbus_method_args)
+
+    def test_set(self):
+        def assertions(*args):
+            self.assertEqual('new', self.parser.get('server', 'hostname'))
+
+        dbus_method_args = ['server.hostname', 'new']
+        self.dbus_request(assertions, self.interface.Set, dbus_method_args)
+
+    def test_set_section_fails(self):
+        dbus_method_args = ['server', 'new']
+
+        with self.assertRaisesRegexp(dbus.DBusException, r'Setting an entire section is not.*'):
+            self.dbus_request(None, self.interface.Set, dbus_method_args)
diff --git a/test/rhsmlib_test/test_facts.py b/test/rhsmlib_test/test_facts.py
new file mode 100644
index 0000000000..ccd32b8410
--- /dev/null
+++ b/test/rhsmlib_test/test_facts.py
@@ -0,0 +1,46 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+import dbus
+import dbus.exceptions
+
+from rhsmlib.dbus.facts.base import AllFacts
+from rhsmlib.dbus.facts import constants
+
+from test.rhsmlib_test.base import DBusObjectTest
+
+
+class TestFactsDBusObject(DBusObjectTest):
+    def setUp(self):
+        super(TestFactsDBusObject, self).setUp()
+        self.proxy = self.proxy_for(AllFacts.default_dbus_path)
+        self.interface = dbus.Interface(self.proxy, constants.FACTS_DBUS_INTERFACE)
+
+    def dbus_objects(self):
+        return [AllFacts]
+
+    def bus_name(self):
+        return constants.FACTS_DBUS_NAME
+
+    def test_get_facts(self):
+        def assertions(*args):
+            result = args[0]
+            self.assertIn("uname.machine", result)
+
+        self.dbus_request(assertions, self.interface.GetFacts)
+
+    def test_missing_method(self):
+        def assertions(*args):
+            pass
+
+        with self.assertRaises(dbus.exceptions.DBusException):
+            self.dbus_request(assertions, self.interface.MissingMethod)
diff --git a/test/rhsmlib_test/test_register.py b/test/rhsmlib_test/test_register.py
new file mode 100644
index 0000000000..7723de5f5d
--- /dev/null
+++ b/test/rhsmlib_test/test_register.py
@@ -0,0 +1,262 @@
+#
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+#
+
+import errno
+import mock
+import json
+import dbus.connection
+import socket
+
+import rhsm.connection
+import subscription_manager.injection as inj
+
+from test import stubs
+from test.fixture import SubManFixture
+from test.rhsmlib_test.base import DBusObjectTest
+
+from rhsmlib.dbus import dbus_utils, constants
+from rhsmlib.dbus.objects import DomainSocketRegisterDBusObject, RegisterDBusObject
+
+CONTENT_JSON = '''{"hypervisorId": null,
+        "serviceLevel": "",
+        "autoheal": true,
+        "idCert": "FAKE_KEY",
+        "owner": {"href": "/owners/admin", "displayName": "Admin Owner",
+        "id": "ff808081550d997c01550d9adaf40003", "key": "admin"},
+        "href": "/consumers/c1b8648c-6f0a-4aa5-b34e-b9e62c0e4364",
+        "facts": {}, "id": "ff808081550d997c015511b0406d1065",
+        "uuid": "c1b8648c-6f0a-4aa5-b34e-b9e62c0e4364",
+        "guestIds": null, "capabilities": null,
+        "environment": null, "installedProducts": null,
+        "canActivate": false, "type": {"manifest": false,
+        "id": "1000", "label": "system"}, "annotations": null,
+        "username": "admin", "updated": "2016-06-02T15:16:51+0000",
+        "lastCheckin": null, "entitlementCount": 0, "releaseVer":
+        {"releaseVer": null}, "entitlementStatus": "valid", "name":
+        "test.example.com", "created": "2016-06-02T15:16:51+0000",
+        "contentTags": null, "dev": false}'''
+
+SUCCESSFUL_REGISTRATION = {
+    "headers": {
+        'content-type': 'application/json',
+        'date': 'Thu, 02 Jun 2016 15:16:51 GMT',
+        'server': 'Apache-Coyote/1.1',
+        'transfer-encoding': 'chunked',
+        'x-candlepin-request-uuid': '01566658-137b-478c-84c0-38540daa8602',
+        'x-version': '2.0.13-1'
+    },
+    "content": CONTENT_JSON,
+    "status": "200"
+}
+
+
+class DomainSocketRegisterDBusObjectUnitTest(SubManFixture):
+    def setUp(self):
+        self.dbus_connection = mock.Mock(spec=dbus.connection.Connection)
+        super(DomainSocketRegisterDBusObjectUnitTest, self).setUp()
+
+    @mock.patch("subscription_manager.managerlib.persist_consumer_cert")
+    @mock.patch("rhsm.connection.UEPConnection")
+    def test_register(self, stub_uep, mock_persist_consumer):
+        self._inject_mock_invalid_consumer()
+
+        expected_consumer = json.loads(CONTENT_JSON, object_hook=dbus_utils._decode_dict)
+        del expected_consumer['idCert']
+
+        stub_uep.return_value.registerConsumer = mock.Mock(return_value=SUCCESSFUL_REGISTRATION)
+        register_service = DomainSocketRegisterDBusObject(conn=self.dbus_connection)
+
+        output = register_service.Register('admin', 'admin', 'admin', {
+            'host': 'localhost',
+            'port': '8443',
+            'handler': '/candlepin'
+        })
+
+        # Be sure we are persisting the consumer cert
+        mock_persist_consumer.assert_called_once_with(expected_consumer)
+        # Be sure we get the right output
+        self.assertEquals(output, SUCCESSFUL_REGISTRATION)
+
+    @mock.patch("rhsm.connection.UEPConnection")
+    def test_get_uep_from_options(self, stub_uep):
+        stub_uep.return_value = mock.Mock(spec=rhsm.connection.UEPConnection)
+        options = {
+            'username': 'test',
+            'password': 'test_password',
+            'host': 'localhost',
+            'port': '8443',
+            'handler': '/candlepin',
+            'insecure': True
+        }
+
+        self._inject_mock_invalid_consumer()
+
+        register_service = DomainSocketRegisterDBusObject(conn=self.dbus_connection)
+        register_service.build_uep(options)
+
+        stub_uep.assert_called_once_with(
+            username=options.get('username', None),
+            password=options.get('password', None),
+            host=options.get('host', None),
+            ssl_port=rhsm.connection.safe_int(options.get('port', None)),
+            handler=options.get('handler', None),
+            insecure=options.get('insecure', None),
+            proxy_hostname=options.get('proxy_hostname', None),
+            proxy_port=options.get('proxy_port', None),
+            proxy_user=options.get('proxy_user', None),
+            proxy_password=options.get('proxy_password', None),
+            restlib_class=rhsm.connection.BaseRestLib
+        )
+
+    @mock.patch("subscription_manager.managerlib.persist_consumer_cert")
+    @mock.patch("rhsm.connection.UEPConnection")
+    def test_register_with_activation_keys(self, stub_uep, mock_persist_consumer):
+        self._inject_mock_invalid_consumer()
+
+        expected_consumer = json.loads(CONTENT_JSON,
+            object_hook=dbus_utils._decode_dict)
+        del expected_consumer['idCert']
+        stub_uep.return_value.registerConsumer = mock.Mock(return_value=SUCCESSFUL_REGISTRATION)
+        register_service = DomainSocketRegisterDBusObject(self.dbus_connection)
+
+        output = register_service.RegisterWithActivationKeys('admin', ['default_key'], {
+            'host': 'localhost',
+            'port': '8443',
+            'handler': '/candlepin'
+        })
+
+        # Be sure we are persisting the consumer cert
+        mock_persist_consumer.assert_called_once_with(expected_consumer)
+        # Be sure we get the right output
+        self.assertEquals(output, SUCCESSFUL_REGISTRATION)
+
+
+class DomainSocketRegisterDBusObjectFunctionalTest(DBusObjectTest):
+    def dbus_objects(self):
+        return [RegisterDBusObject]
+
+    def setUp(self):
+        inj.provide(inj.INSTALLED_PRODUCTS_MANAGER, stubs.StubInstalledProductsManager())
+        facts_host_patcher = mock.patch('rhsmlib.dbus.facts.FactsClient', auto_spec=True)
+        self.addCleanup(facts_host_patcher.stop)
+        self.mock_facts_host = facts_host_patcher.start()
+        self.mock_facts_host.return_value.GetFacts.return_value = {}
+
+        super(DomainSocketRegisterDBusObjectFunctionalTest, self).setUp()
+        self.proxy = self.proxy_for(RegisterDBusObject.default_dbus_path)
+        self.interface = dbus.Interface(self.proxy, constants.REGISTER_INTERFACE)
+
+    def test_open_domain_socket(self):
+        dbus_method_args = []
+
+        def assertions(*args):
+            result = args[0]
+            self.assertRegexpMatches(result, r'/var/run/dbus.*')
+
+        self.dbus_request(assertions, self.interface.Start, dbus_method_args)
+
+    def test_same_socket_on_subsequent_opens(self):
+        dbus_method_args = []
+
+        def assertions(*args):
+            # Assign the result as an attribute to this function.
+            # See http://stackoverflow.com/a/27910553/6124862
+            assertions.result = args[0]
+            self.assertRegexpMatches(assertions.result, r'/var/run/dbus.*')
+
+        self.dbus_request(assertions, self.interface.Start, dbus_method_args)
+
+        # Reset the handler_complete_event so we'll block for the second
+        # dbus_request
+        self.handler_complete_event.clear()
+
+        def assertions2(*args):
+            result2 = args[0]
+            self.assertEqual(assertions.result, result2)
+
+        self.dbus_request(assertions2, self.interface.Start, dbus_method_args)
+
+    def test_cannot_close_what_is_not_opened(self):
+        with self.assertRaises(dbus.exceptions.DBusException):
+            self.dbus_request(None, self.interface.Stop, [])
+
+    def test_closes_domain_socket(self):
+        def get_address(*args):
+            address = args[0]
+            _prefix, _equal, address = address.partition('=')
+            get_address.address, _equal, _suffix = address.partition(',')
+
+        self.dbus_request(get_address, self.interface.Start, [])
+        self.handler_complete_event.clear()
+
+        sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
+        try:
+            # The socket returned for connection is an abstract socket so we have
+            # to begin the name with a NUL byte to get into that namespace.  See
+            # http://blog.eduardofleury.com/archives/2007/09/13
+            sock.connect('\0' + get_address.address)
+        finally:
+            sock.close()
+
+        self.dbus_request(None, self.interface.Stop, [])
+        self.handler_complete_event.wait()
+
+        with self.assertRaises(socket.error) as serr:
+            sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
+            try:
+                sock.connect('\0' + get_address.address)
+            finally:
+                sock.close()
+            self.assertEqual(serr.errno, errno.ECONNREFUSED)
+
+    def _inject_mock_invalid_consumer(self, uuid=None):
+        invalid_identity = mock.NonCallableMock(name='InvalidIdentityMock')
+        invalid_identity.is_valid = mock.Mock(return_value=False)
+        invalid_identity.uuid = uuid or "INVALIDCONSUMERUUID"
+        invalid_identity.cert_dir_path = "/not/a/real/path/to/pki/consumer/"
+        inj.provide(inj.IDENTITY, invalid_identity)
+        return invalid_identity
+
+    @mock.patch("subscription_manager.managerlib.persist_consumer_cert")
+    @mock.patch("rhsm.connection.UEPConnection")
+    def test_can_register_over_domain_socket(self, stub_uep, mock_persist_consumer):
+        def get_address(*args):
+            get_address.address = args[0]
+
+        self.dbus_request(get_address, self.interface.Start, [])
+        self.handler_complete_event.clear()
+
+        socket_conn = dbus.connection.Connection(get_address.address)
+        socket_proxy = socket_conn.get_object(constants.BUS_NAME, constants.PRIVATE_REGISTER_DBUS_PATH)
+        socket_interface = dbus.Interface(socket_proxy, constants.PRIVATE_REGISTER_INTERFACE)
+
+        expected_consumer = json.loads(CONTENT_JSON, object_hook=dbus_utils._decode_dict)
+        del expected_consumer['idCert']
+
+        def assertions(*args):
+            # Be sure we are persisting the consumer cert
+            mock_persist_consumer.assert_called_once_with(expected_consumer)
+            self.assertEquals(args[0], SUCCESSFUL_REGISTRATION)
+
+        self._inject_mock_invalid_consumer()
+        stub_uep.return_value.registerConsumer = mock.Mock(return_value=SUCCESSFUL_REGISTRATION)
+
+        register_opts = ['admin', 'admin', 'admin', {
+            'host': 'localhost',
+            'port': '8443',
+            'handler': '/candlepin'
+        }]
+
+        self.dbus_request(assertions, socket_interface.Register, register_opts)
diff --git a/test/rhsmlib_test/test_service_wrapper.py b/test/rhsmlib_test/test_service_wrapper.py
new file mode 100644
index 0000000000..c96e79ebef
--- /dev/null
+++ b/test/rhsmlib_test/test_service_wrapper.py
@@ -0,0 +1,60 @@
+# Copyright (c) 2016 Red Hat, Inc.
+#
+# This software is licensed to you under the GNU General Public License,
+# version 2 (GPLv2). There is NO WARRANTY for this software, express or
+# implied, including the implied warranties of MERCHANTABILITY or FITNESS
+# FOR A PARTICULAR PURPOSE. You should have received a copy of GPLv2
+# along with this software; if not, see
+# http://www.gnu.org/licenses/old-licenses/gpl-2.0.txt.
+#
+# Red Hat trademarks are not licensed under GPLv2. No permission is
+# granted to use or replicate Red Hat trademarks that are incorporated
+# in this software or its documentation.
+try:
+    import unittest2 as unittest
+except ImportError:
+    import unittest
+
+import dbus
+import mock
+
+from rhsmlib.dbus import service_wrapper, constants
+
+
+class ServiceWrapperTest(unittest.TestCase):
+    def test_parse_argv(self):
+        opts, args = service_wrapper.parse_argv(
+            ['cmd_name', '--verbose', '--bus-name', 'Hello', 'Foo'], 'Default')
+        self.assertTrue(opts.verbose)
+        self.assertEqual(opts.bus_name, 'Hello')
+        self.assertEqual(args, ['Foo'])
+
+    def test_uses_default_bus_name(self):
+        opts, args = service_wrapper.parse_argv(['cmd_name', 'Foo'], 'Default')
+        self.assertFalse(opts.verbose)
+        self.assertEqual(opts.bus, dbus.SystemBus)
+        self.assertEqual(opts.bus_name, 'Default')
+        self.assertEqual(args, ['Foo'])
+
+    def test_loads_bus_given(self):
+        opts, args = service_wrapper.parse_argv(['cmd_name', '--bus', 'dbus.SessionBus', 'Foo'], 'Default')
+        self.assertEqual(opts.bus, dbus.SessionBus)
+
+    @mock.patch("rhsmlib.dbus.service_wrapper.server.Server")
+    def test_loads_an_object_class(self, mock_serve):
+        # Just use some class we have available
+        service_wrapper.main(['cmd_name', 'mock.MagicMock'])
+        mock_serve.assert_called_with(
+            bus_class=dbus.SystemBus,
+            bus_name=constants.BUS_NAME,
+            object_classes=[mock.MagicMock]
+        )
+
+    @mock.patch("rhsmlib.dbus.service_wrapper.server.Server")
+    def test_loads_from_an_array_of_classes(self, mock_serve):
+        service_wrapper.main(['cmd_name'], [mock.MagicMock])
+        mock_serve.assert_called_with(
+            bus_class=dbus.SystemBus,
+            bus_name=constants.BUS_NAME,
+            object_classes=[mock.MagicMock]
+        )
diff --git a/test/smoke.sh b/test/smoke.sh
index 4b2c5d77ea..5c7875c5ab 100755
--- a/test/smoke.sh
+++ b/test/smoke.sh
@@ -10,15 +10,18 @@ WRAPPER=""
 # or "SUBMAN_DEBUG=1 bin/subscription-manager"
 #SM="SUBMAN_DEBUG=1 bin/subscription-manager"
 #SM="subscription-manager"
-SM="PYTHONPATH=../python-rhsm/src/:src/ bin/subscription-manager"
-WORKER="PYTHONPATH=../python-rhsm/src/:src/ python src/daemons/rhsmcertd-worker.py"
-RHSMD="PYTHONPATH=../python-rhsm/src/:src/ src/daemons/rhsm_d.py"
+# To unset the default path and use the installed version (or system paths, etc)
+# pass in PYPATH=, aka 'PYPATH= test/smoke.sh'
+PYPATH=${PYPATH-PYTHONPATH=../python-rhsm/src:src/}
+SM="${PYPATH} bin/subscription-manager"
+WORKER="${PYPATH} python src/daemons/rhsmcertd-worker.py"
+RHSMD="${PYPATH} src/daemons/rhsm_d.py"
 RHSMCERTD="bin/rhsmcertd"
-RCT="PYTHONPATH=../python-rhsm/src/:src/ bin/rct"
-RHSM_DEBUG="PYTHONPATH=../python-rhsm/src/:src/ bin/rhsm-debug"
+RCT="${PYPATH} bin/rct"
+RHSM_DEBUG="${PYPATH} bin/rhsm-debug"
 
 # assume we are testing installed version
-VIRT_WHO="PYTHONPATH=../python-rhsm/src/:src/ /usr/bin/virt-who"
+VIRT_WHO="${PYPATH} /usr/bin/virt-who"
 
 # where to store backup copies of rhsm related files
 # NOTE: we currently dont restore them
@@ -29,7 +32,7 @@ CONF_BACKUP="${BACKUP_DIR}/${TIMESTAMP}/"
 
 # running yum requires installing the pluings
 # Note: have to set CONF_BACKUP first
-YUM="PYTHONPATH=../python-rhsm/src/:src/ yum -c ${CONF_BACKUP}/yum-smoke.conf"
+YUM="${PYPATH} yum -c ${CONF_BACKUP}/yum-smoke.conf"
 
 
 # this script assumes it's running from top level of src checkout
@@ -269,6 +272,9 @@ run_sm "0" refresh
 run_sm "0" redeem --email "${REDEEM_EMAIL}"
 
 run_sm "0" facts
+run_sm "0" facts --list
+run_sm "0" facts --update
+
 run_sm "0" identity
 run_sm "0" orgs --username "${USERNAME}" --password "${PASSWORD}"
 
diff --git a/test/stubs.py b/test/stubs.py
index 451d1a7739..aabd067cf4 100644
--- a/test/stubs.py
+++ b/test/stubs.py
@@ -35,8 +35,6 @@
 from rhsm.certificate2 import EntitlementCertificate, ProductCertificate, \
         Product, Content, Order
 from rhsm import profile
-
-
 from rhsm import ourjson as json
 
 # config file is root only, so just fill in a stringbuffer
@@ -62,6 +60,7 @@
 productCertDir = /etc/pki/product
 entitlementCertDir = /etc/pki/entitlement
 consumerCertDir = /etc/pki/consumer
+ca_cert_dir = /etc/rhsm/ca/
 
 [rhsmcertd]
 certCheckInterval = 240
@@ -116,8 +115,6 @@ def save(self, config_file=None):
             raise IOError
         return None
 
-    # replace read with readfp on stringio
-
 
 def stubInitConfig():
     return StubConfig()
@@ -390,7 +387,7 @@ def __init__(self, host=None, ssl_port=None, handler=None,
                  username=None, password=None,
                  proxy_hostname=None, proxy_port=None,
                  proxy_user=None, proxy_password=None,
-                 cert_file=None, key_file=None):
+                 cert_file=None, key_file=None, restlib_class=None):
         self.registered_consumer_info = {"uuid": 'dummy-consumer-uuid'}
         self.environment_list = []
         self.called_unregister_uuid = None
@@ -455,6 +452,8 @@ def setConsumer(self, consumer):
     def getConsumer(self, consumerId, username=None, password=None):
         if hasattr(self, 'consumer') and self.consumer:
             return self.consumer
+        if callable(self.registered_consumer_info):
+            return self.registered_consumer_info()
         return self.registered_consumer_info
 
     def unbindAll(self, consumer):
diff --git a/test/test_async.py b/test/test_async.py
index a67e15c94d..c176cf0f01 100644
--- a/test/test_async.py
+++ b/test/test_async.py
@@ -63,7 +63,7 @@ def _create_async_pool(self):
         inj.provide(inj.CERT_SORTER, stubs.StubCertSorter())
 
         self.pool_stash = \
-                managerlib.PoolStash(facts=self.stub_facts)
+                managerlib.PoolStash()
 
         self.ap = async.AsyncPool(self.pool_stash)
 
@@ -88,5 +88,6 @@ def test_exception(self):
 
         self.mainloop.run()
         self.assertTrue(len(self.callbacks) > 3)
-        # we should have an exception in the error from the callback
-        self.assertTrue(isinstance(self.callbacks[0][1], IOError))
+        # we should have an sys.exc_info tuple in the error from the callback
+        self.assertTrue(isinstance(self.callbacks[0][1], tuple))
+        self.assertTrue(isinstance(self.callbacks[0][1][1], IOError))
diff --git a/test/test_dnf_content_plugin.py b/test/test_dnf_content_plugin.py
index bbca596598..23a949b47f 100644
--- a/test/test_dnf_content_plugin.py
+++ b/test/test_dnf_content_plugin.py
@@ -10,7 +10,7 @@
 try:
     import dnf
     import librepo
-except ImportError, e:
+except ImportError as e:
     raise SkipTest(e)
 
 
@@ -33,6 +33,8 @@
 fp, pathname, description = imp.find_module(module_name, [dir_path])
 try:
     dnf_product_id = imp.load_module('dnf_product_id', fp, pathname, description)
+except ImportError as e:
+    raise SkipTest(e)
 finally:
     fp.close()
 
diff --git a/test/test_factlib.py b/test/test_factlib.py
index c4229c05fb..10f551842d 100644
--- a/test/test_factlib.py
+++ b/test/test_factlib.py
@@ -20,11 +20,10 @@
 
 
 class TestFactlib(fixture.SubManFixture):
-
     def setUp(self):
         super(TestFactlib, self).setUp()
-        #self.stub_uep = stubs.StubUEP()
-        self.expected_facts = {'fact1': 'F1', 'fact2': 'F2'}
+        # As set in fixture.py:
+        self.expected_facts = {"mock.facts": "true"}
 
         inj.provide(inj.FACTS, stubs.StubFacts(self.expected_facts))
         self.fl = factlib.FactsActionInvoker()
@@ -36,7 +35,6 @@ def test_factlib_updates_when_identity_does_not_exist(self):
         self.assertEquals(len(self.expected_facts), count)
 
     def test_factlib_updates_when_identity_exists(self):
-
         invalid_consumer = self._inject_mock_valid_consumer()
         self.facts_passed_to_server = None
         self.consumer_uuid_passed_to_server = None
@@ -54,12 +52,3 @@ def track_facts_update(consumer_uuid, facts):
         self.assertEquals(len(self.expected_facts), count)
         self.assertEquals(self.expected_facts, self.facts_passed_to_server)
         self.assertEquals(invalid_consumer.uuid, self.consumer_uuid_passed_to_server)
-
-
-class ConsumerIdentityExistsStub(stubs.StubConsumerIdentity):
-    def __init__(self, keystring, certstring):
-        super(ConsumerIdentityExistsStub, self).__init__(keystring, certstring)
-
-    @classmethod
-    def exists(cls):
-        return True
diff --git a/test/test_facts.py b/test/test_facts.py
index 441ba24d8d..70f8ab3882 100644
--- a/test/test_facts.py
+++ b/test/test_facts.py
@@ -3,7 +3,6 @@
 from mock import patch
 
 import fixture
-from stubs import StubEntitlementDirectory, StubProductDirectory
 from subscription_manager import facts
 from rhsm import ourjson as json
 
@@ -133,8 +132,7 @@ def setUp(self):
         fd = open(fact_cache, "w")
         fd.write(facts_buf)
         fd.close()
-        self.f = facts.Facts(ent_dir=StubEntitlementDirectory([]),
-                             prod_dir=StubProductDirectory([]))
+        self.f = facts.Facts()
         self.f.CACHE_FILE = fact_cache
 
     def tearDown(self):
@@ -149,31 +147,25 @@ def test_facts_last_update(self):
         #FIXME: verify the date is correct
         self.f.get_last_update()
 
-    @patch('subscription_manager.facts.Facts._load_custom_facts',
-           return_value={})
-    @patch('subscription_manager.facts.Facts._load_hw_facts',
+    @patch('subscription_manager.facts.Facts.get_facts',
            return_value={'newstuff': 'a new_hope'})
-    def test_facts_has_changed(self, mock_load_hw, mock_load_cf):
+    def test_facts_has_changed(self, mock_collect):
         self.assertTrue(self.f.has_changed())
 
-    @patch('subscription_manager.facts.Facts._load_custom_facts',
-           return_value={})
-    @patch('subscription_manager.facts.Facts._load_hw_facts')
-    def test_facts_has_changed_no_change(self, mock_load_hw, mock_load_cf):
+    @patch('subscription_manager.facts.Facts.get_facts')
+    def test_facts_has_changed_no_change(self, mock_collect):
         test_facts = json.loads(facts_buf)
-        mock_load_hw.return_value = test_facts
+        mock_collect.return_value = test_facts
         changed = self.f.has_changed()
         self.assert_equal_dict(test_facts, self.f.facts)
         self.assertFalse(changed)
 
-    @patch('subscription_manager.facts.Facts._load_custom_facts',
-           return_value={})
-    @patch('subscription_manager.facts.Facts._load_hw_facts')
-    def test_facts_has_changed_with_change(self, mock_load_hw, mock_load_cf):
+    @patch('subscription_manager.facts.Facts.get_facts')
+    def test_facts_has_changed_with_change(self, mock_collect):
         test_facts = json.loads(facts_buf)
         # change socket fact count from what is in the cache
         test_facts['cpu.cpu_socket(s)'] = '16'
-        mock_load_hw.return_value = test_facts
+        mock_collect.return_value = test_facts
 
         changed = self.f.has_changed()
         self.assertEquals(self.f.facts['cpu.cpu_socket(s)'], '16')
@@ -181,14 +173,10 @@ def test_facts_has_changed_with_change(self, mock_load_hw, mock_load_cf):
 
     @patch('subscription_manager.facts.Facts._read_cache',
            return_value=None)
-    @patch('subscription_manager.facts.Facts._load_custom_facts',
-           return_value={})
-    @patch('subscription_manager.facts.Facts._load_hw_facts')
-    def test_facts_has_changed_cache_is_none(self, mock_load_hw,
-                                             mock_load_cf,
-                                             mock_read_cache):
+    @patch('subscription_manager.facts.Facts.get_facts')
+    def test_facts_has_changed_cache_is_none(self, mock_collect, mock_read_cache):
         test_facts = json.loads(facts_buf)
-        mock_load_hw.return_value = test_facts
+        mock_collect.return_value = test_facts
 
         changed = self.f.has_changed()
         self.assert_equal_dict(test_facts, self.f.facts)
@@ -196,107 +184,20 @@ def test_facts_has_changed_cache_is_none(self, mock_load_hw,
 
     @patch('subscription_manager.facts.Facts._cache_exists',
            return_value=False)
-    @patch('subscription_manager.facts.Facts._load_custom_facts',
-           return_value={})
-    @patch('subscription_manager.facts.Facts._load_hw_facts')
-    def test_facts_has_changed_cache_exists_false(self, mock_load_hw,
-                                                  mock_load_cf,
-                                                  mock_read_cache):
-
+    @patch('subscription_manager.facts.Facts.get_facts')
+    def test_facts_has_changed_cache_exists_false(self, mock_collect, mock_read_cache):
         test_facts = json.loads(facts_buf)
-        mock_load_hw.return_value = test_facts
+        mock_collect.return_value = test_facts
 
         changed = self.f.has_changed()
         self.assertTrue(changed)
 
-    @patch('subscription_manager.facts.Facts._load_custom_facts')
-    @patch('subscription_manager.facts.Facts._load_hw_facts')
-    def test_get_facts(self, mock_load_hw, mock_load_cf):
-        mock_load_hw.return_value = \
+    @patch('subscription_manager.facts.Facts.get_facts')
+    def test_get_facts(self, mock_collect):
+        mock_collect.return_value = \
             {'net.interface.lo.ipv4_address': '127.0.0.1'}
 
-        mock_load_cf.return_value = \
-            {'some.custom_fact': 'foobar'}
-
         f = self.f.get_facts()
 
         self.assertTrue(isinstance(f, dict))
         self.assertEquals(f['net.interface.lo.ipv4_address'], '127.0.0.1')
-        self.assertEquals(f['some.custom_fact'], 'foobar')
-
-    @patch('subscription_manager.facts.Facts._load_custom_facts')
-    @patch('subscription_manager.facts.Facts._load_hw_facts')
-    def test_custom_facts_override_hardware_facts(self, mock_load_hw, mock_load_cf):
-        mock_load_hw.return_value = \
-            {'net.interface.lo.ipv4_address': '127.0.0.1'}
-
-        mock_load_cf.return_value = \
-            {'net.interface.lo.ipv4_address': 'foobar'}
-
-        f = self.f.get_facts()
-        self.assertEquals(f['net.interface.lo.ipv4_address'], 'foobar')
-
-    # simulate an empty facts file
-    @patch('subscription_manager.facts.Facts._open_custom_facts',
-           return_value="")
-    @patch('subscription_manager.facts.Facts._load_hw_facts',
-           return_value={})
-    def test_empty_custom_facts(self, mock_load_hw, mock_open_cf):
-        # dont load hardware info
-        mock_load_hw.return_value = {}
-        f = self.f.get_facts()
-        # not much to check, just want to verify we dont
-        # throw an exception
-        # see rhbz #966747
-        self.assertTrue(isinstance(f, dict))
-
-    @patch('glob.glob', return_value="/path/to/custom/facts/foo.fact")
-    @patch('subscription_manager.facts.Facts._open_custom_facts')
-    @patch('subscription_manager.facts.Facts._load_hw_facts',
-           return_value={})
-    def test_custom_facts(self, mock_load_hw, mock_open_cf, mock_glob):
-        mock_open_cf.return_value = facts_buf
-        f = self.f.get_facts()
-        self.assertTrue(isinstance(f, dict))
-
-    @patch('__builtin__.open',
-           side_effect=IOError)
-    @patch('subscription_manager.facts.Facts._load_hw_facts',
-           return_value={'test_key': 'test_value'})
-    def test_io_error_on_custom_facts(self, mock_load_hw, mock_open):
-        # verify we handle ioerrors reading custom facts
-        f = self.f.get_facts()
-
-        self.assertTrue(isinstance(f, dict))
-        self.assertEquals(f['test_key'], 'test_value')
-
-    @patch('subscription_manager.facts.Facts._load_custom_facts')
-    @patch('subscription_manager.facts.Facts._load_hw_facts')
-    def test_write_facts(self, mock_load_hw, mock_load_cf):
-        mock_load_hw.return_value = \
-            {'net.interface.lo.ipv4_address': '127.0.0.1',
-             'cpu.cpu_socket(s)': '128',
-             'newstuff': 'newstuff_is_true'}
-        fact_cache_dir = tempfile.mkdtemp()
-        fact_cache = fact_cache_dir + "/facts.json"
-
-        # write to a new file
-        self.f.fact_cache_dir = fact_cache_dir
-        self.f.CACHE_FILE = fact_cache
-
-        # mocking load_hw_facts and load_custom_facts neuters get_facts
-        #self.f.get_facts = 'asdfadfasdfadf'
-        self.f.write_cache()
-
-        new_facts_buf = open(fact_cache).read()
-        new_facts = json.loads(new_facts_buf)
-        self.assertEquals(new_facts['newstuff'], 'newstuff_is_true')
-
-    @patch('subscription_manager.facts.Facts._load_custom_facts',
-           return_value={})
-    @patch('subscription_manager.facts.Facts._load_hw_facts',
-           return_value={})
-    def test_entitlement_version(self, mock_load_hw, mock_load_cf):
-        self.assertTrue("system.certificate_version" in self.f.get_facts())
-        self.assertEquals(facts.CERT_VERSION,
-                self.f.get_facts()['system.certificate_version'])
diff --git a/test/test_facts_gui.py b/test/test_facts_gui.py
index cf99bbc808..38518a5556 100644
--- a/test/test_facts_gui.py
+++ b/test/test_facts_gui.py
@@ -20,26 +20,14 @@ def setUp(self):
         self.expected_facts = expected_facts
         self.stub_facts = StubFacts(expected_facts)
 
-    def test_facts_are_displayed(self):
-        found_facts = {}
-
-        def check_facts(parent, facts):
-            found_facts[facts[0]] = facts[1]
-
-        dialog = factsgui.SystemFactsDialog(self.stub_facts)
-        dialog.facts_store.append = check_facts
-        dialog.display_facts()
-
-        self.assertEquals(self.expected_facts, found_facts)
-
     def test_hides_environment_when_not_supported(self):
-        dialog = factsgui.SystemFactsDialog(self.stub_facts)
+        dialog = factsgui.SystemFactsDialog()
         dialog.display_facts()
         self.assertEquals(False, dialog.environment_title.get_property("visible"))
         self.assertEquals(False, dialog.environment_label.get_property("visible"))
 
     def test_shows_unknown_for_no_org(self):
-        dialog = factsgui.SystemFactsDialog(self.stub_facts)
+        dialog = factsgui.SystemFactsDialog()
         dialog.display_facts()
         #No owner id should show if we have no owner
         self.assertEquals(False, dialog.owner_label.get_property("visible"))
@@ -48,7 +36,7 @@ def test_shows_unknown_for_no_org(self):
     @patch.object(StubUEP, 'getOwner')
     def test_shows_org_id(self, mock_getOwner):
         mock_getOwner.return_value = {'displayName': 'foo', 'key': 'bar'}
-        dialog = factsgui.SystemFactsDialog(self.stub_facts)
+        dialog = factsgui.SystemFactsDialog()
         dialog.display_facts()
         self.assertEquals(True, dialog.owner_label.get_property("visible"))
         self.assertEquals(True, dialog.owner_title.get_property("visible"))
@@ -59,7 +47,7 @@ def test_shows_org_id(self, mock_getOwner):
     def test_shows_environment_when_supported(self, mock_getConsumer, mock_supports_resource):
         mock_supports_resource.return_value = True
         mock_getConsumer.return_value = {'environment': {'name': 'foobar'}}
-        dialog = factsgui.SystemFactsDialog(self.stub_facts)
+        dialog = factsgui.SystemFactsDialog()
         dialog.display_facts()
         self.assertEquals(True, dialog.environment_title.get_property("visible"))
         self.assertEquals(True, dialog.environment_label.get_property("visible"))
@@ -70,7 +58,7 @@ def test_shows_environment_when_supported(self, mock_getConsumer, mock_supports_
     def test_shows_environment_when_empty(self, mock_getConsumer, mock_supports_resource):
         mock_supports_resource.return_value = True
         mock_getConsumer.return_value = {'environment': None}
-        dialog = factsgui.SystemFactsDialog(self.stub_facts)
+        dialog = factsgui.SystemFactsDialog()
         dialog.display_facts()
         self.assertEquals(True, dialog.environment_title.get_property("visible"))
         self.assertEquals(True, dialog.environment_label.get_property("visible"))
@@ -86,7 +74,7 @@ def new_identity():
             return id_mock
         provide(IDENTITY, new_identity)
 
-        dialog = factsgui.SystemFactsDialog(self.stub_facts)
+        dialog = factsgui.SystemFactsDialog()
         dialog.show()
 
         enabled = dialog.update_button.get_property('sensitive')
@@ -94,7 +82,7 @@ def new_identity():
         self.assertFalse(enabled)
 
     def test_update_button_enabled(self):
-        dialog = factsgui.SystemFactsDialog(self.stub_facts)
+        dialog = factsgui.SystemFactsDialog()
         dialog.show()
 
         enabled = dialog.update_button.get_property('sensitive')
diff --git a/test/test_lock.py b/test/test_lock.py
index f8d74767a5..7e615246d7 100644
--- a/test/test_lock.py
+++ b/test/test_lock.py
@@ -6,6 +6,7 @@
 import os
 import subprocess
 import sys
+import shutil
 import tempfile
 import threading
 import time
@@ -19,15 +20,11 @@ class TestLock(unittest.TestCase):
     lf_name = "lock.file"
 
     def setUp(self):
-        self.tmp_dir = self._tmp_dir()
         self.other_process = None
 
-    def _tmp_dir(self):
-        tmp_dir = tempfile.mkdtemp(suffix="lock", prefix="subman-unit-tests-")
-        return tmp_dir
-
     def _lock_path(self):
-        tmp_dir = self._tmp_dir()
+        tmp_dir = tempfile.mkdtemp(suffix="-lock", prefix="subman-unit-tests-")
+        self.addCleanup(shutil.rmtree, tmp_dir, ignore_errors=True)
         return os.path.join(tmp_dir, self.lf_name)
 
     # For thread.Timer()
diff --git a/test/test_logutil.py b/test/test_logutil.py
index 445dd09181..2b12b43793 100644
--- a/test/test_logutil.py
+++ b/test/test_logutil.py
@@ -38,8 +38,15 @@ def test_log_init(self):
         logutil.init_logger()
         sm_logger = logging.getLogger("subscription_manager")
         rhsm_logger = logging.getLogger("rhsm-app")
-        self.assertEqual(sm_logger.getEffectiveLevel(), logging.DEBUG)
-        self.assertEqual(rhsm_logger.getEffectiveLevel(), logging.DEBUG)
+        sm_effective = sm_logger.getEffectiveLevel()
+        rhsm_effective = rhsm_logger.getEffectiveLevel()
+        # Fun hack for 2.6/2.7 interoperability
+        self.assertTrue(
+            logging.DEBUG == sm_effective or
+            logging._levelNames[sm_effective] == logging.DEBUG)
+        self.assertTrue(
+            logging.DEBUG == rhsm_effective or
+            logging._levelNames[rhsm_effective] == logging.DEBUG)
 
     def test_log_init_default_log_level(self):
         self.rhsm_config.set("logging", "default_log_level", "WARNING")
@@ -47,8 +54,15 @@ def test_log_init_default_log_level(self):
         logutil.init_logger()
         sm_logger = logging.getLogger("subscription_manager")
         rhsm_logger = logging.getLogger("rhsm-app")
-        self.assertEqual(sm_logger.getEffectiveLevel(), logging.WARNING)
-        self.assertEqual(rhsm_logger.getEffectiveLevel(), logging.WARNING)
+        sm_effective = sm_logger.getEffectiveLevel()
+        rhsm_effective = rhsm_logger.getEffectiveLevel()
+        # Fun hack for 2.6/2.7 interoperability
+        self.assertTrue(
+            logging.WARNING == sm_effective or
+            logging._levelNames[sm_effective] == logging.WARNING)
+        self.assertTrue(
+            logging.WARNING == rhsm_effective or
+            logging._levelNames[rhsm_effective] == logging.WARNING)
 
     def test_init_logger_for_yum(self):
         logutil.init_logger_for_yum()
@@ -77,7 +91,9 @@ def test_set_valid_logger_level(self):
 
         for logger_name, log_level in logging_conf:
             real_log_level = logging.getLogger(logger_name).getEffectiveLevel()
-            self.assertEqual(real_log_level, logging._checkLevel(log_level))
+            self.assertTrue(
+                logging._levelNames[log_level] == real_log_level or
+                log_level == real_log_level)
 
     def test_set_invalid_logger_level(self):
         test_logger_name = 'foobar'
diff --git a/test/test_managercli.py b/test/test_managercli.py
index ec0601fa3a..f04be51642 100644
--- a/test/test_managercli.py
+++ b/test/test_managercli.py
@@ -383,19 +383,19 @@ def test_no_commands(self):
         self._test_no_exception([])
 
     def test_main_server_url(self):
-        with patch.object(self.mock_cfg, "save") as mock_save:
+        with patch.object(self.mock_cfg_parser, "save") as mock_save:
             server_url = "https://subscription.rhsm.redhat.com/subscription"
             self._test_no_exception(["--serverurl", server_url])
             mock_save.assert_called_with()
 
     def test_main_base_url(self):
-        with patch.object(self.mock_cfg, "save") as mock_save:
+        with patch.object(self.mock_cfg_parser, "save") as mock_save:
             base_url = "https://cdn.redhat.com"
             self._test_no_exception(["--baseurl", base_url])
             mock_save.assert_called_with()
 
     def test_insecure(self):
-        with patch.object(self.mock_cfg, "save") as mock_save:
+        with patch.object(self.mock_cfg_parser, "save") as mock_save:
             self._test_no_exception(["--insecure"])
             mock_save.assert_called_with()
 
@@ -940,7 +940,7 @@ def test_set_config(self):
 
         baseurl = 'https://someserver.example.com/foo'
         self.cc.main(['--rhsm.baseurl', baseurl])
-        self.assertEquals(managercli.cfg.store['rhsm']['baseurl'], baseurl)
+        self.assertEquals(managercli.conf['rhsm']['baseurl'], baseurl)
 
     def test_remove_config_default(self):
         with Capture() as cap:
@@ -1171,6 +1171,12 @@ class TestFactsCommand(TestCliProxyCommand):
 class TestImportCertCommand(TestCliCommand):
     command_class = managercli.ImportCertCommand
 
+    def setUp(self):
+        super(TestImportCertCommand, self).setUp()
+        argv_patcher = patch.object(sys, 'argv', ['subscription-manager', 'import'])
+        argv_patcher.start()
+        self.addCleanup(argv_patcher.stop)
+
     def test_certificates(self):
         self.cc.is_registered = Mock(return_value=False)
         self.cc.main(["--certificate", "one", "--certificate", "two"])
@@ -1239,10 +1245,7 @@ def test_service_level_not_supported(self):
 
     def test_service_level_supported(self):
         self.cc.cp.setConsumer({'serviceLevel': 'Jarjar'})
-        try:
-            self.cc.set_service_level('JRJAR')
-        except SystemExit:
-            self.fail("Exception Raised")
+        self.cc.set_service_level('JRJAR')
 
 
 class TestReleaseCommand(TestCliProxyCommand):
diff --git a/test/test_managergui.py b/test/test_managergui.py
index 7d258e42f1..acc6ccf0f8 100644
--- a/test/test_managergui.py
+++ b/test/test_managergui.py
@@ -13,7 +13,7 @@ def test_main_window(self):
         provide(PROD_DIR, stubs.StubProductDirectory([]))
         provide(PRODUCT_DATE_RANGE_CALCULATOR, mock.Mock())
 
-        managergui.MainWindow(backend=stubs.StubBackend(), facts=stubs.StubFacts(),
+        managergui.MainWindow(backend=stubs.StubBackend(),
                               ent_dir=stubs.StubCertificateDirectory([]),
                               prod_dir=stubs.StubProductDirectory([]))
 
diff --git a/test/test_managerlib.py b/test/test_managerlib.py
index 3023a1a8c1..f5f7847a34 100644
--- a/test/test_managerlib.py
+++ b/test/test_managerlib.py
@@ -296,7 +296,7 @@ def test_multiple_pools(self):
         self.assertEquals(5, merged_pools.consumed)
 
 
-class PoolFilterTests(unittest.TestCase):
+class PoolFilterTests(SubManFixture):
 
     def test_uninstalled_filter_direct_match(self):
         product1 = 'product1'
@@ -1032,7 +1032,7 @@ def test_sort_virt_to_top(self):
 class PoolStashTest(unittest.TestCase):
 
     def test_empty_stash_zero_length(self):
-        my_stash = PoolStash(None)
+        my_stash = PoolStash()
         self.assertTrue(my_stash.all_pools_size() == 0)
 
 
@@ -1106,7 +1106,7 @@ def test_no_pools(self):
         # get the injected stub uep
         cp = self.get_consumer_cp()
         cp.getPoolsList = Mock(return_value=[])
-        res = managerlib.get_available_entitlements(facts={})
+        res = managerlib.get_available_entitlements()
         self.assertEquals(0, len(res))
 
     def test_incompatible(self):
@@ -1122,10 +1122,10 @@ def get_pools_list(consumer=None, listAll=False, active_on=None, owner=None, fil
 
         cp.getPoolsList = Mock(side_effect=get_pools_list)
 
-        res = managerlib.get_available_entitlements(facts={}, get_all=True)
+        res = managerlib.get_available_entitlements(get_all=True)
         self.assertEquals(2, len(res))
 
-        res = managerlib.get_available_entitlements(facts={}, get_all=False)
+        res = managerlib.get_available_entitlements(get_all=False)
         self.assertEquals(1, len(res))
 
     def test_installed(self):
@@ -1144,10 +1144,10 @@ def get_pools_list(consumer=None, listAll=False, active_on=None, owner=None, fil
         product_directory = StubProductDirectory(pids=['some_product'])
         provide(PROD_DIR, product_directory)
 
-        res = managerlib.get_available_entitlements(facts={}, get_all=True, uninstalled=True)
+        res = managerlib.get_available_entitlements(get_all=True, uninstalled=True)
         self.assertEquals(2, len(res))
 
-        res = managerlib.get_available_entitlements(facts={}, uninstalled=True)
+        res = managerlib.get_available_entitlements(uninstalled=True)
         self.assertEquals(1, len(res))
 
     def build_pool_dict(self, pool_id, provided_products=[]):
diff --git a/test/test_migration.py b/test/test_migration.py
index 82355e168b..14ab1cde32 100644
--- a/test/test_migration.py
+++ b/test/test_migration.py
@@ -391,17 +391,23 @@ def test_setting_unauthenticated_proxy(self):
             "enableProxyAuth": False,
             }
         self.engine.rhncfg = rhn_config
+        section = MagicMock()
+        self.engine.rhsmcfg.__getitem__.return_value = section
+
         self.engine.transfer_http_proxy_settings()
-        expected = [call("server", "proxy_hostname", "proxy.example.com"),
-            call("server", "proxy_port", "123"),
-            call("server", "proxy_user", ""),
-            call("server", "proxy_password", ""),
-            ]
-        self.assertTrue(self.engine.rhsmcfg.set.call_args_list == expected)
-        self.engine.rhsmcfg.save.assert_called_once_with()
+        expected = [call("proxy_hostname", "proxy.example.com"),
+            call("proxy_port", "123"),
+            call("proxy_user", ""),
+            call("proxy_password", ""),
+        ]
+        self.assertTrue(section.__setitem__.call_args_list == expected)
+        self.engine.rhsmcfg.persist.assert_called_once_with()
 
     def test_setting_authenticated_proxy(self):
         self.engine.rhsmcfg = MagicMock()
+        section = MagicMock()
+        self.engine.rhsmcfg.__getitem__.return_value = section
+
         self.engine.options = self.create_options(noproxy=False)
 
         rhn_config = {
@@ -410,16 +416,16 @@ def test_setting_authenticated_proxy(self):
             "enableProxyAuth": True,
             "proxyUser": "foo",
             "proxyPassword": "bar",
-            }
+        }
         self.engine.rhncfg = rhn_config
         self.engine.transfer_http_proxy_settings()
-        expected = [call("server", "proxy_hostname", "proxy.example.com"),
-            call("server", "proxy_port", "123"),
-            call("server", "proxy_user", "foo"),
-            call("server", "proxy_password", "bar"),
-            ]
-        self.assertTrue(self.engine.rhsmcfg.set.call_args_list == expected)
-        self.engine.rhsmcfg.save.assert_called_once_with()
+        expected = [call("proxy_hostname", "proxy.example.com"),
+            call("proxy_port", "123"),
+            call("proxy_user", "foo"),
+            call("proxy_password", "bar"),
+        ]
+        self.assertTrue(section.__setitem__.call_args_list == expected)
+        self.engine.rhsmcfg.persist.assert_called_once_with()
 
     def test_setting_prefixed_proxy(self):
         self.engine.rhsmcfg = MagicMock()
@@ -431,14 +437,17 @@ def test_setting_prefixed_proxy(self):
             "enableProxyAuth": False,
             }
         self.engine.rhncfg = rhn_config
+        section = MagicMock()
+        self.engine.rhsmcfg.__getitem__.return_value = section
         self.engine.transfer_http_proxy_settings()
-        expected = [call("server", "proxy_hostname", "proxy.example.com"),
-            call("server", "proxy_port", "123"),
-            call("server", "proxy_user", ""),
-            call("server", "proxy_password", ""),
-            ]
-        self.assertTrue(self.engine.rhsmcfg.set.call_args_list == expected)
-        self.engine.rhsmcfg.save.assert_called_once_with()
+        expected = [
+            call("proxy_hostname", "proxy.example.com"),
+            call("proxy_port", "123"),
+            call("proxy_user", ""),
+            call("proxy_password", ""),
+        ]
+        self.assertTrue(section.__setitem__.call_args_list == expected)
+        self.engine.rhsmcfg.persist.assert_called_once_with()
 
     def test_noproxy_option(self):
         self.engine.rhsmcfg = MagicMock()
@@ -450,36 +459,20 @@ def test_noproxy_option(self):
             "enableProxyAuth": False,
             }
         self.engine.rhncfg = rhn_config
+        section = MagicMock()
+        self.engine.rhsmcfg.__getitem__.return_value = section
         self.engine.transfer_http_proxy_settings()
-        expected = [call("server", "proxy_hostname", ""),
-            call("server", "proxy_port", ""),
-            call("server", "proxy_user", ""),
-            call("server", "proxy_password", ""),
+        expected = [call("proxy_hostname", ""),
+            call("proxy_port", ""),
+            call("proxy_user", ""),
+            call("proxy_password", ""),
             ]
-        self.assertTrue(self.engine.rhsmcfg.set.call_args_list == expected)
+        self.assertTrue(section.__setitem__.call_args_list == expected)
         self.assertEquals("proxy.example.com", self.engine.proxy_host)
         self.assertEquals("123", self.engine.proxy_port)
         self.assertEquals(None, self.engine.proxy_user)
         self.assertEquals(None, self.engine.proxy_pass)
 
-    def _setup_rhsmcfg_mocks(self):
-        self.engine.options = self.create_options()
-
-        self.engine.rhsmcfg = MagicMock()
-        self.engine.rhsmcfg.get = MagicMock(side_effect=[
-            "candlepin.example.com",
-            "/candlepin",
-            ])
-        self.engine.rhsmcfg.get_int = MagicMock(side_effect=[443])
-
-        expected = [call("server", "hostname"),
-            call("server", "prefix"),
-            ]
-
-        get_int_expected = [call("server", "port")]
-
-        return expected, get_int_expected
-
     @patch("rhn.rpclib.Server")
     def test_load_transition_data(self, mock_server):
         mock_server.system.transitionDataForSystem.return_value = {"uuid": "1"}
@@ -541,10 +534,27 @@ def test_consumer_does_not_exist(self):
         self.engine.cp.getConsumer.assert_called_once_with("123")
 
     def test_no_server_url_provided_basic_auth(self):
-        expected, get_int_expected = self._setup_rhsmcfg_mocks()
+        self.engine.options = self.create_options()
+
+        self.engine.rhsmcfg = MagicMock()
+        section = MagicMock()
+        self.engine.rhsmcfg.__getitem__.return_value = section
+
+        section.__getitem__.return_value = MagicMock(side_effect=[
+            "candlepin.example.com",
+            "/candlepin",
+        ])
+        section.get_int = MagicMock(side_effect=[443])
+
+        expected = [call("hostname"),
+            call("prefix"),
+        ]
+
+        int_expected = [call("port")]
+
         self.engine.get_candlepin_connection("some_username", "some_password")
-        self.assertTrue(self.engine.rhsmcfg.get.call_args_list == expected)
-        self.assertTrue(self.engine.rhsmcfg.get_int.call_args_list == get_int_expected)
+        self.assertTrue(section.__getitem__.call_args_list == expected)
+        self.assertTrue(section.get_int.call_args_list == int_expected)
 
     def test_bad_server_url_basic_auth(self):
         self.engine.options = self.create_options(destination_url='http://')
diff --git a/test/test_registrationgui.py b/test/test_registrationgui.py
index 963e9e791c..e71f8efc3b 100644
--- a/test/test_registrationgui.py
+++ b/test/test_registrationgui.py
@@ -28,16 +28,13 @@ def setUp(self):
         self.facts = StubFacts(fact_dict=expected_facts)
 
         self.reg_info = RegisterInfo()
-        self.rs = RegisterWidget(backend=self.backend,
-                                 facts=self.facts,
-                                 reg_info=self.reg_info)
+        self.rs = RegisterWidget(backend=self.backend, reg_info=self.reg_info)
 
         self.rs._screens[CHOOSE_SERVER_PAGE] = Mock()
         self.rs._screens[CHOOSE_SERVER_PAGE].index = 0
         self.rs._screens[CHOOSE_SERVER_PAGE].screens_index = 0
         self.rs._screens[CHOOSE_SERVER_PAGE].button_label = "Dummy"
-        self.rs._screens[CHOOSE_SERVER_PAGE].apply.return_value = \
-                CREDENTIALS_PAGE
+        self.rs._screens[CHOOSE_SERVER_PAGE].apply.return_value = CREDENTIALS_PAGE
 
     def test_show(self):
         self.rs.initialize()
@@ -154,7 +151,6 @@ def setUp(self):
         stub_reg = StubReg()
         self.screen = CredentialsScreen(reg_info=stub_reg.reg_info,
                                         async_backend=stub_reg.async,
-                                        facts=stub_reg.facts,
                                         parent_window=stub_reg.parent_window)
 
     def test_clear_credentials_dialog(self):
@@ -178,7 +174,6 @@ def setUp(self):
         stub_reg = StubReg()
         self.screen = ActivationKeyScreen(reg_info=stub_reg.reg_info,
                                           async_backend=stub_reg.async,
-                                          facts=stub_reg.facts,
                                           parent_window=stub_reg.parent_window)
 
     def test_split_activation_keys(self):
@@ -194,7 +189,6 @@ def setUp(self):
         stub_reg = StubReg()
         self.screen = ChooseServerScreen(reg_info=stub_reg.reg_info,
                                          async_backend=stub_reg.async,
-                                         facts=stub_reg.facts,
                                          parent_window=stub_reg.parent_window)
 
     def test_activation_key_checkbox_sensitive(self):
@@ -236,20 +230,20 @@ def setUp(self):
 
     def test_auto_system_complete(self):
         self.backend.cp_provider.get_consumer_auth_cp().getConsumer = \
-           Mock(return_value={"serviceLevel": "", "owner": {"key": "admin"}})
+            Mock(return_value={"serviceLevel": "", "owner": {"key": "admin"}})
         self.backend.cs.valid_products = ['RH001', 'RH002']
         self.backend.cs.installed_products = ['RH001', 'RH002']
         self.backend.cs.partial_stacks = []
         self.backend.cs.system_status = 'valid'
         self.backend.cp_provider.get_consumer_auth_cp().getServiceLevelList = Mock(return_value=[])
-        self.assertRaises(AllProductsCoveredException, self.asyncBackend._find_suitable_service_levels, '12345', {})
+        self.assertRaises(AllProductsCoveredException, self.asyncBackend._find_suitable_service_levels, '12345')
 
     def test_auto_system_partial(self):
         self.backend.cp_provider.get_consumer_auth_cp().getConsumer = \
-           Mock(return_value={"serviceLevel": "", "owner": {"key": "admin"}})
+            Mock(return_value={"serviceLevel": "", "owner": {"key": "admin"}})
         self.backend.cs.valid_products = ['RH001', 'RH002']
         self.backend.cs.installed_products = ['RH001', 'RH002']
         self.backend.cs.partial_stacks = []
         self.backend.cs.system_status = 'partial'
         self.backend.cp_provider.get_consumer_auth_cp().getServiceLevelList = Mock(return_value=[])
-        self.asyncBackend._find_suitable_service_levels('12345', {})
+        self.asyncBackend._find_suitable_service_levels('12345')
diff --git a/test/test_repolib.py b/test/test_repolib.py
index 3c0a1fe21a..b759e8172e 100644
--- a/test/test_repolib.py
+++ b/test/test_repolib.py
@@ -31,7 +31,8 @@
 from subscription_manager.repolib import Repo, RepoActionInvoker, \
         RepoUpdateActionCommand, TidyWriter, RepoFile, YumReleaseverSource
 from subscription_manager import injection as inj
-from rhsm import config
+from rhsm.config import RhsmConfigParser
+from rhsmlib.services import config
 
 from subscription_manager import repolib
 
@@ -757,7 +758,13 @@ def test_configparsers_equal_int(self, tidy_writer, stub_create):
 """
 
 
-class RhsmConfigParserFromString(config.RhsmConfigParser):
+class ConfigFromString(config.Config):
+    def __init__(self, config_string):
+        parser = RhsmConfigParserFromString(config_string)
+        super(ConfigFromString, self).__init__(parser)
+
+
+class RhsmConfigParserFromString(RhsmConfigParser):
     def __init__(self, config_string):
         SafeConfigParser.__init__(self)
         self.stringio = StringIO(config_string)
@@ -786,41 +793,35 @@ def __init__(self, config_string):
 
 
 class TestManageReposEnabled(fixture.SubManFixture):
-    @patch.object(repolib, 'CFG',
-                  RhsmConfigParserFromString(config_string=unset_config))
+    @patch.object(repolib, 'conf', ConfigFromString(config_string=unset_config))
     def test(self):
         # default stub config, no manage_repo defined, uses default
         manage_repos_enabled = repolib.manage_repos_enabled()
         self.assertEquals(manage_repos_enabled, True)
 
-    @patch.object(repolib, 'CFG',
-                  RhsmConfigParserFromString(config_string=unset_manage_repos_cfg_buf))
+    @patch.object(repolib, 'conf', ConfigFromString(config_string=unset_manage_repos_cfg_buf))
     def test_empty_manage_repos(self):
         manage_repos_enabled = repolib.manage_repos_enabled()
         self.assertEquals(manage_repos_enabled, True)
 
-    @patch.object(repolib, 'CFG',
-                  RhsmConfigParserFromString(config_string=manage_repos_zero_config))
+    @patch.object(repolib, 'conf', ConfigFromString(config_string=manage_repos_zero_config))
     def test_empty_manage_repos_zero(self):
         manage_repos_enabled = repolib.manage_repos_enabled()
         self.assertEquals(manage_repos_enabled, False)
 
-    @patch.object(repolib, 'CFG',
-                  RhsmConfigParserFromString(config_string=manage_repos_bool_config))
+    @patch.object(repolib, 'config', ConfigFromString(config_string=manage_repos_bool_config))
     def test_empty_manage_repos_bool(self):
         manage_repos_enabled = repolib.manage_repos_enabled()
         # Should fail, and return default of 1
         self.assertEquals(manage_repos_enabled, True)
 
-    @patch.object(repolib, 'CFG',
-                  RhsmConfigParserFromString(config_string=manage_repos_not_an_int))
+    @patch.object(repolib, 'config', ConfigFromString(config_string=manage_repos_not_an_int))
     def test_empty_manage_repos_not_an_int(self):
         manage_repos_enabled = repolib.manage_repos_enabled()
         # Should fail, and return default of 1
         self.assertEquals(manage_repos_enabled, True)
 
-    @patch.object(repolib, 'CFG',
-                  RhsmConfigParserFromString(config_string=manage_repos_int_37))
+    @patch.object(repolib, 'conf', ConfigFromString(config_string=manage_repos_int_37))
     def test_empty_manage_repos_int_37(self):
         manage_repos_enabled = repolib.manage_repos_enabled()
         # Should fail, and return default of 1
diff --git a/test/test_utils.py b/test/test_utils.py
index 198383060c..8930f950d5 100644
--- a/test/test_utils.py
+++ b/test/test_utils.py
@@ -16,6 +16,8 @@
 from rhsm.config import DEFAULT_PORT, DEFAULT_PREFIX, DEFAULT_HOSTNAME, \
     DEFAULT_CDN_HOSTNAME, DEFAULT_CDN_PORT, DEFAULT_CDN_PREFIX
 
+from rhsmlib.services import config
+
 
 class TestParseServerInfo(SubManFixture):
     def setUp(self):
@@ -55,7 +57,7 @@ def test_hostname_only_config(self):
         self.stubConfig.set("server", "prefix", "/test-prefix")
 
         local_url = "myhost.example.com"
-        (hostname, port, prefix) = parse_server_info(local_url, self.stubConfig)
+        (hostname, port, prefix) = parse_server_info(local_url, config.Config(self.stubConfig))
         self.assertEquals("myhost.example.com", hostname)
         self.assertEquals("344", port)
         self.assertEquals("/test-prefix", prefix)
@@ -64,7 +66,7 @@ def test_hostname_port_config(self):
         self.stubConfig.set("server", "port", "600")
 
         local_url = "myhost.example.com/myapp"
-        (hostname, port, prefix) = parse_server_info(local_url, self.stubConfig)
+        (hostname, port, prefix) = parse_server_info(local_url, config.Config(self.stubConfig))
         self.assertEquals("myhost.example.com", hostname)
         self.assertEquals("600", port)
         self.assertEquals("/myapp", prefix)
@@ -73,7 +75,7 @@ def test_hostname_prefix_config(self):
         self.stubConfig.set("server", "prefix", "/test-prefix")
 
         local_url = "myhost.example.com:500"
-        (hostname, port, prefix) = parse_server_info(local_url, self.stubConfig)
+        (hostname, port, prefix) = parse_server_info(local_url, config.Config(self.stubConfig))
         self.assertEquals("myhost.example.com", hostname)
         self.assertEquals("500", port)
         self.assertEquals("/test-prefix", prefix)
diff --git a/tox.ini b/tox.ini
index fee37e955f..82c1685e7a 100644
--- a/tox.ini
+++ b/tox.ini
@@ -13,12 +13,13 @@
 # E402 module level import not at top of file
 # E731 do not assign a lambda expression, use a def
 
+# TODO enable E198, E199, E122, E124, E121
 [pep8]
-ignore=E121,E122,E123,E124,E125,E126,E127,E128,E129,E131,E265,E402,E501,E713,E714,E731
+ignore=E123,E125,E126,E127,E128,E129,E265,E402,E501,E713,E714,E731,E198,E199,E122,E124,E121
 max-line-length=300
 
 [flake8]
-ignore=E121,E122,E123,E124,E125,E126,E127,E128,E129,E131,E265,E402,E501,E713,E714,E731,V250,V260
+ignore=E123,E125,E126,E127,E128,E129,E265,E402,E501,E713,E714,E731,V250,V260,E198,E199,E122,E124,E121
 exclude=*certdata*,*manifestdata*
 jobs=auto
 max-line-length=300
