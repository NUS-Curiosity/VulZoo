diff --git a/tests/repository_data/fishy_rolenames/1.a.json b/tests/repository_data/fishy_rolenames/1.a.json
new file mode 100644
index 0000000000..e88a590da8
--- /dev/null
+++ b/tests/repository_data/fishy_rolenames/1.a.json
@@ -0,0 +1,15 @@
+{
+ "signatures": [
+  {
+   "keyid": "056a036ef6f15c1dbff1f3d61dfadfc9e92699f6b66a2e21513698b576cc498d",
+   "sig": "6550a087bd0f01648f57e02a275f20c8e38974271d73739c446f53a028c4118e070b1d37224bc022ab6e0500c8051494f276365868ed6039ec49c7ecd8b9f602"
+  }
+ ],
+ "signed": {
+  "_type": "targets",
+  "expires": "2021-10-22T11:21:56Z",
+  "spec_version": "1.0.19",
+  "targets": {},
+  "version": 1
+ }
+}
\ No newline at end of file
diff --git a/tests/repository_data/fishy_rolenames/metadata/1...json b/tests/repository_data/fishy_rolenames/metadata/1...json
new file mode 100644
index 0000000000..74e1118c40
--- /dev/null
+++ b/tests/repository_data/fishy_rolenames/metadata/1...json
@@ -0,0 +1,15 @@
+{
+ "signatures": [
+  {
+   "keyid": "c4f5b1013293e01cedb1680fc3aa670278fd46277c62d0bfa24ffff5f0ad0602",
+   "sig": "c0266de0724c2ab9c14e679b258033fe3aff8ce3c99419479456170975bb43de9e8539caed437cccc8e6c6068252a921f7badc5384149dab18261a7f157ae406"
+  }
+ ],
+ "signed": {
+  "_type": "targets",
+  "expires": "2021-10-22T11:21:56Z",
+  "spec_version": "1.0.19",
+  "targets": {},
+  "version": 1
+ }
+}
\ No newline at end of file
diff --git a/tests/repository_data/fishy_rolenames/metadata/1.root.json b/tests/repository_data/fishy_rolenames/metadata/1.root.json
new file mode 100644
index 0000000000..9a7a80e63b
--- /dev/null
+++ b/tests/repository_data/fishy_rolenames/metadata/1.root.json
@@ -0,0 +1,71 @@
+{
+ "signatures": [
+  {
+   "keyid": "b24fc41c37a5e3c7b504516351633494e462137338182d8f701dc889acbd2eb6",
+   "sig": "1d3b9cebfdab388db500d01cb2cd499f016320029df17bf2f1196d8f83f12d041832dc165f23667e537d8a8aa66c716d19835bd2bcd55d4c18bbbd0c6eaf4b06"
+  }
+ ],
+ "signed": {
+  "_type": "root",
+  "consistent_snapshot": true,
+  "expires": "2021-10-22T11:21:56Z",
+  "keys": {
+   "965e45aad2af966bafe3719a99152fa34576a07b61742e6501c0b235fd3b8f9c": {
+    "keytype": "ed25519",
+    "keyval": {
+     "public": "d98dace51d795525971342b9f7317cea0d743710dca932543fedb92bb083c2c0"
+    },
+    "scheme": "ed25519"
+   },
+   "b24fc41c37a5e3c7b504516351633494e462137338182d8f701dc889acbd2eb6": {
+    "keytype": "ed25519",
+    "keyval": {
+     "public": "46d386175220afd55ad9b09b6b18fa96cd69e25bc29c97ed7024a522e7e7938c"
+    },
+    "scheme": "ed25519"
+   },
+   "c808865e701882b89c075941ca158034d8c47bde97f1dcdb2afd854334a3ffef": {
+    "keytype": "ed25519",
+    "keyval": {
+     "public": "a7beb72fb686a645f5ffd52e246a55d2914411853c70a5b47d837ed7b4c40734"
+    },
+    "scheme": "ed25519"
+   },
+   "e1f4f87b77838c39ec348fc6e74a10e28272fb6bf3f45bff09cd694148150095": {
+    "keytype": "ed25519",
+    "keyval": {
+     "public": "efdf10805063c1b7356f40ede43d2c5c6d2d11d79e350887ce96fe5d1e44901a"
+    },
+    "scheme": "ed25519"
+   }
+  },
+  "roles": {
+   "root": {
+    "keyids": [
+     "b24fc41c37a5e3c7b504516351633494e462137338182d8f701dc889acbd2eb6"
+    ],
+    "threshold": 1
+   },
+   "snapshot": {
+    "keyids": [
+     "e1f4f87b77838c39ec348fc6e74a10e28272fb6bf3f45bff09cd694148150095"
+    ],
+    "threshold": 1
+   },
+   "targets": {
+    "keyids": [
+     "c808865e701882b89c075941ca158034d8c47bde97f1dcdb2afd854334a3ffef"
+    ],
+    "threshold": 1
+   },
+   "timestamp": {
+    "keyids": [
+     "965e45aad2af966bafe3719a99152fa34576a07b61742e6501c0b235fd3b8f9c"
+    ],
+    "threshold": 1
+   }
+  },
+  "spec_version": "1.0.19",
+  "version": 1
+ }
+}
\ No newline at end of file
diff --git a/tests/repository_data/fishy_rolenames/metadata/1.targets.json b/tests/repository_data/fishy_rolenames/metadata/1.targets.json
new file mode 100644
index 0000000000..766c028bd8
--- /dev/null
+++ b/tests/repository_data/fishy_rolenames/metadata/1.targets.json
@@ -0,0 +1,75 @@
+{
+ "signatures": [
+  {
+   "keyid": "c808865e701882b89c075941ca158034d8c47bde97f1dcdb2afd854334a3ffef",
+   "sig": "ffa055ab5108f9d22f309fecd0160b02971d7a454c8d48db4f99cdaf114b329a401b756a11e42630bff6667ad897fb05f501e3299d25fe786d12651cb0db6c06"
+  }
+ ],
+ "signed": {
+  "_type": "targets",
+  "delegations": {
+   "keys": {
+    "056a036ef6f15c1dbff1f3d61dfadfc9e92699f6b66a2e21513698b576cc498d": {
+     "keytype": "ed25519",
+     "keyval": {
+      "public": "45d4d9ee28ef61506695130fe600d637e5f2de0de72473c280b02b89467d7aab"
+     },
+     "scheme": "ed25519"
+    },
+    "c4f5b1013293e01cedb1680fc3aa670278fd46277c62d0bfa24ffff5f0ad0602": {
+     "keytype": "ed25519",
+     "keyval": {
+      "public": "abe021d7594f04467627c2be390c665b311dceb83cceb685edc9b90a6e229d08"
+     },
+     "scheme": "ed25519"
+    },
+    "e38fb1b3a2dea12551541bbb205f09609d9386e147207182c8b900bc0a25e2b8": {
+     "keytype": "ed25519",
+     "keyval": {
+      "public": "52b790190bccf730fad4b769e7073c1551938101483ff8612534eb9105426dce"
+     },
+     "scheme": "ed25519"
+    }
+   },
+   "roles": [
+    {
+     "keyids": [
+      "056a036ef6f15c1dbff1f3d61dfadfc9e92699f6b66a2e21513698b576cc498d"
+     ],
+     "name": "../a",
+     "paths": [
+      "*"
+     ],
+     "terminating": false,
+     "threshold": 1
+    },
+    {
+     "keyids": [
+      "c4f5b1013293e01cedb1680fc3aa670278fd46277c62d0bfa24ffff5f0ad0602"
+     ],
+     "name": ".",
+     "paths": [
+      "*"
+     ],
+     "terminating": false,
+     "threshold": 1
+    },
+    {
+     "keyids": [
+      "e38fb1b3a2dea12551541bbb205f09609d9386e147207182c8b900bc0a25e2b8"
+     ],
+     "name": "\u00f6",
+     "paths": [
+      "*"
+     ],
+     "terminating": false,
+     "threshold": 1
+    }
+   ]
+  },
+  "expires": "2021-10-22T11:21:56Z",
+  "spec_version": "1.0.19",
+  "targets": {},
+  "version": 1
+ }
+}
\ No newline at end of file
diff --git "a/tests/repository_data/fishy_rolenames/metadata/1.\303\266.json" "b/tests/repository_data/fishy_rolenames/metadata/1.\303\266.json"
new file mode 100644
index 0000000000..fbfecadf31
--- /dev/null
+++ "b/tests/repository_data/fishy_rolenames/metadata/1.\303\266.json"
@@ -0,0 +1,15 @@
+{
+ "signatures": [
+  {
+   "keyid": "e38fb1b3a2dea12551541bbb205f09609d9386e147207182c8b900bc0a25e2b8",
+   "sig": "854fdccea623c33bf968c7ef5abea6e5e5f7c390a691ae0ae5ad87a7580fc00910b566d5dbdbfcaa948f2d8fe4348eecd5a12710d05f576aecf83fbec32c580b"
+  }
+ ],
+ "signed": {
+  "_type": "targets",
+  "expires": "2021-10-22T11:21:56Z",
+  "spec_version": "1.0.19",
+  "targets": {},
+  "version": 1
+ }
+}
\ No newline at end of file
diff --git a/tests/repository_data/fishy_rolenames/metadata/2.snapshot.json b/tests/repository_data/fishy_rolenames/metadata/2.snapshot.json
new file mode 100644
index 0000000000..8e33783c6b
--- /dev/null
+++ b/tests/repository_data/fishy_rolenames/metadata/2.snapshot.json
@@ -0,0 +1,28 @@
+{
+ "signatures": [
+  {
+   "keyid": "e1f4f87b77838c39ec348fc6e74a10e28272fb6bf3f45bff09cd694148150095",
+   "sig": "f00f4b0040dc6879e7ad69867ba611d52bd5e9993cbfd27e6d8073449356c716b4277093c67ae70eba90ab0367a070e69be750284e70e1135615832efda54008"
+  }
+ ],
+ "signed": {
+  "_type": "snapshot",
+  "expires": "2021-10-22T11:21:56Z",
+  "meta": {
+   "../a.json": {
+    "version": 1
+   },
+   "..json": {
+    "version": 1
+   },
+   "targets.json": {
+    "version": 1
+   },
+   "\u00f6.json": {
+    "version": 1
+   }
+  },
+  "spec_version": "1.0.19",
+  "version": 2
+ }
+}
\ No newline at end of file
diff --git a/tests/repository_data/fishy_rolenames/metadata/timestamp.json b/tests/repository_data/fishy_rolenames/metadata/timestamp.json
new file mode 100644
index 0000000000..a85d176b0a
--- /dev/null
+++ b/tests/repository_data/fishy_rolenames/metadata/timestamp.json
@@ -0,0 +1,19 @@
+{
+ "signatures": [
+  {
+   "keyid": "965e45aad2af966bafe3719a99152fa34576a07b61742e6501c0b235fd3b8f9c",
+   "sig": "5a0040f56454f2f338acb8a81b4c2e170e0bc61219a7cd823f635dfc9faeefcf30dfe9c792f148a25949cc9594f8ac1bfffe436b737eff140d236eba57fe9e08"
+  }
+ ],
+ "signed": {
+  "_type": "timestamp",
+  "expires": "2021-10-22T11:21:56Z",
+  "meta": {
+   "snapshot.json": {
+    "version": 2
+   }
+  },
+  "spec_version": "1.0.19",
+  "version": 2
+ }
+}
\ No newline at end of file
diff --git a/tests/repository_simulator.py b/tests/repository_simulator.py
index 4bd43bbad5..6f6ca32ecd 100644
--- a/tests/repository_simulator.py
+++ b/tests/repository_simulator.py
@@ -59,6 +59,8 @@
 from tuf.api.serialization.json import JSONSerializer
 from tuf.exceptions import FetcherHTTPError
 from tuf.api.metadata import (
+    DelegatedRole,
+    Delegations,
     Key,
     Metadata,
     MetaFile,
@@ -106,6 +108,9 @@ def __init__(self):
         self.dump_dir = None
         self.dump_version = 0
 
+        now = datetime.utcnow()
+        self.safe_expiry = now.replace(microsecond=0) + timedelta(days=30)
+
         self._initialize()
 
     @property
@@ -135,20 +140,19 @@ def create_key(self) -> Tuple[Key, SSlibSigner]:
 
     def _initialize(self):
         """Setup a minimal valid repository"""
-        expiry = datetime.utcnow().replace(microsecond=0) + timedelta(days=30)
 
-        targets = Targets(1, SPEC_VER, expiry, {}, None)
+        targets = Targets(1, SPEC_VER, self.safe_expiry, {}, None)
         self.md_targets = Metadata(targets, OrderedDict())
 
         meta = {"targets.json": MetaFile(targets.version)}
-        snapshot = Snapshot(1, SPEC_VER, expiry, meta)
+        snapshot = Snapshot(1, SPEC_VER, self.safe_expiry, meta)
         self.md_snapshot = Metadata(snapshot, OrderedDict())
 
         snapshot_meta = MetaFile(snapshot.version)
-        timestamp = Timestamp(1, SPEC_VER, expiry, snapshot_meta)
+        timestamp = Timestamp(1, SPEC_VER, self.safe_expiry, snapshot_meta)
         self.md_timestamp = Metadata(timestamp, OrderedDict())
 
-        root = Root(1, SPEC_VER, expiry, {}, {}, True)
+        root = Root(1, SPEC_VER, self.safe_expiry, {}, {}, True)
         for role in ["root", "timestamp", "snapshot", "targets"]:
             key, signer = self.create_key()
             root.roles[role] = Role([], 1)
@@ -172,27 +176,27 @@ def publish_root(self):
     def fetch(self, url: str) -> Iterator[bytes]:
         if not self.root.consistent_snapshot:
             raise NotImplementedError("non-consistent snapshot not supported")
-
-        spliturl = parse.urlparse(url)
-        if spliturl.path.startswith("/metadata/"):
-            parts = spliturl.path[len("/metadata/") :].split(".")
-            if len(parts) == 3:
-                version: Optional[int] = int(parts[0])
-                role = parts[1]
-            else:
+        path = parse.urlparse(url).path
+        if path.startswith("/metadata/") and path.endswith(".json"):
+            ver_and_name = path[len("/metadata/") :][: -len(".json")]
+            # only consistent_snapshot supported ATM: timestamp is special case
+            if ver_and_name == "timestamp":
                 version = None
-                role = parts[0]
+                role = "timestamp"
+            else:
+                version, _, role = ver_and_name.partition(".")
+                version = int(version)
             yield self._fetch_metadata(role, version)
-        elif spliturl.path.startswith("/targets/"):
+        elif path.startswith("/targets/"):
             # figure out target path and hash prefix
-            path = spliturl.path[len("/targets/") :]
-            dir_parts, sep , prefixed_filename = path.rpartition("/")
+            target_path = path[len("/targets/") :]
+            dir_parts, sep , prefixed_filename = target_path.rpartition("/")
             prefix, _, filename = prefixed_filename.partition(".")
             target_path = f"{dir_parts}{sep}{filename}"
 
             yield self._fetch_target(target_path, prefix)
         else:
-            raise FetcherHTTPError(f"Unknown path '{spliturl.path}'", 404)
+            raise FetcherHTTPError(f"Unknown path '{path}'", 404)
 
     def _fetch_target(self, target_path: str, hash: Optional[str]) -> bytes:
         """Return data for 'target_path', checking 'hash' if it is given.
@@ -268,12 +272,14 @@ def update_timestamp(self):
 
     def update_snapshot(self):
         for role, delegate in self.all_targets():
-            self.snapshot.meta[f"{role}.json"].version = delegate.version
-
+            hashes = None
+            length = None
             if self.compute_metafile_hashes_length:
                 hashes, length = self._compute_hashes_and_length(role)
-                self.snapshot.meta[f"{role}.json"].hashes = hashes
-                self.snapshot.meta[f"{role}.json"].length = length
+
+            self.snapshot.meta[f"{role}.json"] = MetaFile(
+                delegate.version, length, hashes
+            )
 
         self.snapshot.version += 1
         self.update_timestamp()
@@ -288,6 +294,37 @@ def add_target(self, role: str, data: bytes, path: str):
         targets.targets[path] = target
         self.target_files[path] = RepositoryTarget(data, target)
 
+    def add_delegation(
+        self,
+        delegator_name: str,
+        name: str,
+        targets: Targets,
+        terminating: bool,
+        paths: Optional[List[str]],
+        hash_prefixes: Optional[List[str]],
+    ):
+        if delegator_name == "targets":
+            delegator = self.targets
+        else:
+            delegator = self.md_delegates[delegator_name].signed
+
+        # Create delegation
+        role = DelegatedRole(name, [], 1, terminating, paths, hash_prefixes)
+        if delegator.delegations is None:
+            delegator.delegations = Delegations({}, {})
+        # put delegation last by default
+        delegator.delegations.roles[role.name] = role
+
+        # By default add one new key for the role
+        key, signer = self.create_key()
+        delegator.add_key(role.name, key)
+        if role.name not in self.signers:
+            self.signers[role.name] = []
+        self.signers[role.name].append(signer)
+
+        # Add metadata for the role
+        self.md_delegates[role.name] = Metadata(targets, OrderedDict())
+
     def write(self):
         """Dump current repository metadata to self.dump_dir
 
diff --git a/tests/test_updater.py b/tests/test_updater.py
index 45b014f732..9f79fd8b12 100755
--- a/tests/test_updater.py
+++ b/tests/test_updater.py
@@ -454,74 +454,6 @@ def test_1__refresh_must_not_count_duplicate_keyids_towards_threshold(self):
           "Expected a NoWorkingMirrorError composed of one BadSignatureError")
 
 
-  def test_1__update_fileinfo(self):
-      # Tests
-      # Verify that the 'self.fileinfo' dictionary is empty (its starts off empty
-      # and is only populated if _update_fileinfo() is called.
-      fileinfo_dict = self.repository_updater.fileinfo
-      self.assertEqual(len(fileinfo_dict), 0)
-
-      # Load the fileinfo of the top-level root role.  This populates the
-      # 'self.fileinfo' dictionary.
-      self.repository_updater._update_fileinfo('root.json')
-      self.assertEqual(len(fileinfo_dict), 1)
-      self.assertTrue(tuf.formats.FILEDICT_SCHEMA.matches(fileinfo_dict))
-      root_filepath = os.path.join(self.client_metadata_current, 'root.json')
-      length, hashes = securesystemslib.util.get_file_details(root_filepath)
-      root_fileinfo = tuf.formats.make_targets_fileinfo(length, hashes)
-      self.assertTrue('root.json' in fileinfo_dict)
-      self.assertEqual(fileinfo_dict['root.json'], root_fileinfo)
-
-      # Verify that 'self.fileinfo' is incremented if another role is updated.
-      self.repository_updater._update_fileinfo('targets.json')
-      self.assertEqual(len(fileinfo_dict), 2)
-
-      # Verify that 'self.fileinfo' is inremented if a non-existent role is
-      # requested, and has its fileinfo entry set to 'None'.
-      self.repository_updater._update_fileinfo('bad_role.json')
-      self.assertEqual(len(fileinfo_dict), 3)
-      self.assertEqual(fileinfo_dict['bad_role.json'], None)
-
-
-
-
-  def test_2__fileinfo_has_changed(self):
-      #  Verify that the method returns 'False' if file info was not changed.
-      root_filepath = os.path.join(self.client_metadata_current, 'root.json')
-      length, hashes = securesystemslib.util.get_file_details(root_filepath)
-      root_fileinfo = tuf.formats.make_targets_fileinfo(length, hashes)
-      self.assertFalse(self.repository_updater._fileinfo_has_changed('root.json',
-                                                             root_fileinfo))
-
-      # Verify that the method returns 'True' if length or hashes were changed.
-      new_length = 8
-      new_root_fileinfo = tuf.formats.make_targets_fileinfo(new_length, hashes)
-      self.assertTrue(self.repository_updater._fileinfo_has_changed('root.json',
-                                                             new_root_fileinfo))
-      # Hashes were changed.
-      new_hashes = {'sha256': self.random_string()}
-      new_root_fileinfo = tuf.formats.make_targets_fileinfo(length, new_hashes)
-      self.assertTrue(self.repository_updater._fileinfo_has_changed('root.json',
-                                                             new_root_fileinfo))
-
-      # Verify that _fileinfo_has_changed() returns True if no fileinfo (or set
-      # to None) exists for some role.
-      self.assertTrue(self.repository_updater._fileinfo_has_changed('bad.json',
-          new_root_fileinfo))
-
-      saved_fileinfo = self.repository_updater.fileinfo['root.json']
-      self.repository_updater.fileinfo['root.json'] = None
-      self.assertTrue(self.repository_updater._fileinfo_has_changed('root.json',
-          new_root_fileinfo))
-
-
-      self.repository_updater.fileinfo['root.json'] = saved_fileinfo
-      new_root_fileinfo['hashes']['sha666'] = '666'
-      self.repository_updater._fileinfo_has_changed('root.json',
-          new_root_fileinfo)
-
-
-
   def test_2__import_delegations(self):
     # Setup.
     # In order to test '_import_delegations' the parent of the delegation
@@ -639,6 +571,20 @@ def test_2__move_current_to_previous(self):
     self.repository_updater._move_current_to_previous('snapshot')
     self.assertTrue(os.path.exists(previous_snapshot_filepath))
 
+    # assert that non-ascii alphanumeric role name "../ä" (that is url encoded
+    # in local filename) works
+    encoded_current = os.path.join(
+      self.client_metadata_current, '..%2F%C3%A4.json'
+    )
+    encoded_previous = os.path.join(
+      self.client_metadata_previous, '..%2F%C3%A4.json'
+    )
+
+    with open(encoded_current, "w"):
+      pass
+    self.repository_updater._move_current_to_previous('../ä')
+    self.assertTrue(os.path.exists(encoded_previous))
+
 
 
 
@@ -2073,6 +2019,64 @@ def test_get_updater(self):
     self.assertEqual(None, multi_repo_updater.get_updater('bad_repo_name'))
 
 
+class TestUpdaterRolenames(unittest_toolbox.Modified_TestCase):
+  def setUp(self):
+    unittest_toolbox.Modified_TestCase.setUp(self)
+
+    repo_dir = os.path.join(os.getcwd(), 'repository_data', 'fishy_rolenames')
+
+    self.client_dir = self.make_temp_directory()
+    os.makedirs(os.path.join(self.client_dir, "fishy_rolenames", "metadata", "current"))
+    os.makedirs(os.path.join(self.client_dir, "fishy_rolenames", "metadata", "previous"))
+    shutil.copy(
+      os.path.join(repo_dir, 'metadata', '1.root.json'),
+      os.path.join(self.client_dir, "fishy_rolenames", "metadata", "current", "root.json")
+    )
+
+    simple_server_path = os.path.join(os.getcwd(), 'simple_server.py')
+    self.server_process_handler = utils.TestServerProcess(log=logger,
+        server=simple_server_path)
+
+    url_prefix = 'http://' + utils.TEST_HOST_ADDRESS + ':' \
+        + str(self.server_process_handler.port) + "/repository_data/fishy_rolenames"
+
+    tuf.settings.repositories_directory = self.client_dir
+    mirrors = {'mirror1': {
+      'url_prefix': url_prefix,
+      'metadata_path': 'metadata/',
+      'targets_path': ''
+    }}
+    self.updater = updater.Updater("fishy_rolenames", mirrors)
+
+  def tearDown(self):
+    tuf.roledb.clear_roledb(clear_all=True)
+    tuf.keydb.clear_keydb(clear_all=True)
+    self.server_process_handler.flush_log()
+    self.server_process_handler.clean()
+    unittest_toolbox.Modified_TestCase.tearDown(self)
+
+  def test_unusual_rolenames(self):
+    """Test rolenames that may be tricky to handle as filenames
+
+    The test data in repository_data/fishy_rolenames has been produced
+    semi-manually using RepositorySimulator: using the RepositorySimulator
+    in these tests directly (like test_updater_with_simulator.py does for
+    ngclient) might make more sense... but would require some integration work
+    """
+
+    # Make a target search that fetches the delegated targets
+    self.updater.refresh()
+    with self.assertRaises(tuf.exceptions.UnknownTargetError):
+      self.updater.get_one_valid_targetinfo("anything")
+
+    # Assert that the metadata files are in the client metadata directory
+    metadata_dir = os.path.join(
+      self.client_dir, "fishy_rolenames", "metadata", "current"
+    )
+    local_metadata = os.listdir(metadata_dir)
+    for fname in ['%C3%B6.json', '..%2Fa.json', '..json']:
+      self.assertTrue(fname in local_metadata)
+
 
 def _load_role_keys(keystore_directory):
 
diff --git a/tests/test_updater_with_simulator.py b/tests/test_updater_with_simulator.py
index f7037cc1bd..5ea3fc5f20 100644
--- a/tests/test_updater_with_simulator.py
+++ b/tests/test_updater_with_simulator.py
@@ -9,6 +9,7 @@
 import os
 import sys
 import tempfile
+from tuf.api.metadata import SPECIFICATION_VERSION, Targets
 from typing import Optional, Tuple
 from tuf.exceptions import UnsignedMetadataError, BadVersionNumberError
 import unittest
@@ -125,6 +126,30 @@ def test_targets(self, test_case_data: Tuple[str, bytes, str]):
 
 
 
+    def test_fishy_rolenames(self):
+        roles_to_filenames = {
+            "../a": "..%2Fa.json",
+            "": ".json",
+            ".": "..json",
+            "/": "%2F.json",
+            "ö": "%C3%B6.json"
+        }
+
+        # Add new delegated targets, update the snapshot
+        spec_version = ".".join(SPECIFICATION_VERSION)
+        targets = Targets(1, spec_version, self.sim.safe_expiry, {}, None)
+        for role in roles_to_filenames.keys():
+            self.sim.add_delegation("targets", role, targets, False, ["*"], None)
+        self.sim.update_snapshot()
+
+        updater = self._run_refresh()
+
+        # trigger updater to fetch the delegated metadata, check filenames
+        updater.get_one_valid_targetinfo("anything")
+        local_metadata = os.listdir(self.metadata_dir)
+        for fname in roles_to_filenames.values():
+            self.assertTrue(fname in local_metadata)
+
     def test_keys_and_signatures(self):
         """Example of the two trickiest test areas: keys and root updates"""
 
diff --git a/tuf/client/updater.py b/tuf/client/updater.py
index ffb38dcb30..9d08e4d020 100755
--- a/tuf/client/updater.py
+++ b/tuf/client/updater.py
@@ -122,6 +122,7 @@
 import copy
 import warnings
 import io
+from urllib import parse
 
 from securesystemslib import exceptions as sslib_exceptions
 from securesystemslib import formats as sslib_formats
@@ -781,7 +782,13 @@ def __str__(self):
     return self.repository_name
 
 
+  @staticmethod
+  def _get_local_filename(rolename: str) -> str:
+    """Return safe local filename for roles metadata
 
+    Use URL encoding to prevent issues with path separators and
+    with forbidden characters in Windows filesystems"""
+    return parse.quote(rolename, '') + '.json'
 
 
   def _load_metadata_from_file(self, metadata_set, metadata_role):
@@ -827,7 +834,7 @@ def _load_metadata_from_file(self, metadata_set, metadata_role):
 
     # Save and construct the full metadata path.
     metadata_directory = self.metadata_directory[metadata_set]
-    metadata_filename = metadata_role + '.json'
+    metadata_filename = self._get_local_filename(metadata_role)
     metadata_filepath = os.path.join(metadata_directory, metadata_filename)
 
     # Ensure the metadata path is valid/exists, else ignore the call.
@@ -1656,10 +1663,6 @@ def _update_metadata(self, metadata_role, upperbound_filelength, version=None):
       None.
     """
 
-    # Construct the metadata filename as expected by the download/mirror
-    # modules.
-    metadata_filename = metadata_role + '.json'
-
     # Attempt a file download from each mirror until the file is downloaded and
     # verified.  If the signature of the downloaded file is valid, proceed,
     # otherwise log a warning and try the next mirror.  'metadata_file_object'
@@ -1676,7 +1679,11 @@ def _update_metadata(self, metadata_role, upperbound_filelength, version=None):
     # best length we can get for it, not request a specific version, but
     # perform the rest of the checks (e.g., signature verification).
 
-    remote_filename = metadata_filename
+    # Construct the metadata filename as expected by the download/mirror
+    # modules. Local filename is quoted to protect against names like"../file".
+
+    remote_filename = metadata_role + '.json'
+    local_filename = self._get_local_filename(metadata_role)
     filename_version = ''
 
     if self.consistent_snapshot and version:
@@ -1693,12 +1700,12 @@ def _update_metadata(self, metadata_role, upperbound_filelength, version=None):
     # First, move the 'current' metadata file to the 'previous' directory
     # if it exists.
     current_filepath = os.path.join(self.metadata_directory['current'],
-                metadata_filename)
+                local_filename)
     current_filepath = os.path.abspath(current_filepath)
     sslib_util.ensure_parent_dir(current_filepath)
 
     previous_filepath = os.path.join(self.metadata_directory['previous'],
-        metadata_filename)
+        local_filename)
     previous_filepath = os.path.abspath(previous_filepath)
 
     if os.path.exists(current_filepath):
@@ -1726,7 +1733,7 @@ def _update_metadata(self, metadata_role, upperbound_filelength, version=None):
     logger.debug('Updated ' + repr(current_filepath) + '.')
     self.metadata['previous'][metadata_role] = current_metadata_object
     self.metadata['current'][metadata_role] = updated_metadata_object
-    self._update_versioninfo(metadata_filename)
+    self._update_versioninfo(remote_filename)
 
 
 
@@ -1973,9 +1980,11 @@ def _update_versioninfo(self, metadata_filename):
     # __init__ (such as with delegated metadata), then get the version
     # info now.
 
-    # Save the path to the current metadata file for 'metadata_filename'.
+    # 'metadata_filename' is the key from meta dictionary: build the
+    # corresponding local filepath like _get_local_filename()
+    local_filename = parse.quote(metadata_filename, "")
     current_filepath = os.path.join(self.metadata_directory['current'],
-        metadata_filename)
+        local_filename)
 
     # If the path is invalid, simply return and leave versioninfo unset.
     if not os.path.exists(current_filepath):
@@ -2028,130 +2037,6 @@ def _update_versioninfo(self, metadata_filename):
 
 
 
-
-  def _fileinfo_has_changed(self, metadata_filename, new_fileinfo):
-    """
-    <Purpose>
-      Non-public method that determines whether the current fileinfo of
-      'metadata_filename' differs from 'new_fileinfo'.  The 'new_fileinfo'
-      argument should be extracted from the latest copy of the metadata that
-      references 'metadata_filename'.  Example: 'root.json' would be referenced
-      by 'snapshot.json'.
-
-      'new_fileinfo' should only be 'None' if this is for updating 'root.json'
-      without having 'snapshot.json' available.
-
-    <Arguments>
-      metadadata_filename:
-        The metadata filename for the role.  For the 'root' role,
-        'metadata_filename' would be 'root.json'.
-
-      new_fileinfo:
-        A dict object representing the new file information for
-        'metadata_filename'.  'new_fileinfo' may be 'None' when
-        updating 'root' without having 'snapshot' available.  This
-        dict conforms to 'tuf.formats.TARGETS_FILEINFO_SCHEMA' and has
-        the form:
-
-        {'length': 23423
-         'hashes': {'sha256': adfbc32343..}}
-
-    <Exceptions>
-      None.
-
-    <Side Effects>
-      If there is no fileinfo currently loaded for 'metada_filename',
-      try to load it.
-
-    <Returns>
-      Boolean.  True if the fileinfo has changed, false otherwise.
-    """
-
-    # If there is no fileinfo currently stored for 'metadata_filename',
-    # try to load the file, calculate the fileinfo, and store it.
-    if metadata_filename not in self.fileinfo:
-      self._update_fileinfo(metadata_filename)
-
-    # Return true if there is no fileinfo for 'metadata_filename'.
-    # 'metadata_filename' is not in the 'self.fileinfo' store
-    # and it doesn't exist in the 'current' metadata location.
-    if self.fileinfo[metadata_filename] is None:
-      return True
-
-    current_fileinfo = self.fileinfo[metadata_filename]
-
-    if current_fileinfo['length'] != new_fileinfo['length']:
-      return True
-
-    # Now compare hashes. Note that the reason we can't just do a simple
-    # equality check on the fileinfo dicts is that we want to support the
-    # case where the hash algorithms listed in the metadata have changed
-    # without having that result in considering all files as needing to be
-    # updated, or not all hash algorithms listed can be calculated on the
-    # specific client.
-    for algorithm, hash_value in new_fileinfo['hashes'].items():
-      # We're only looking for a single match. This isn't a security
-      # check, we just want to prevent unnecessary downloads.
-      if algorithm in current_fileinfo['hashes']:
-        if hash_value == current_fileinfo['hashes'][algorithm]:
-          return False
-
-    return True
-
-
-
-
-
-  def _update_fileinfo(self, metadata_filename):
-    """
-    <Purpose>
-      Non-public method that updates the 'self.fileinfo' entry for the metadata
-      belonging to 'metadata_filename'.  If the 'current' metadata for
-      'metadata_filename' cannot be loaded, set its fileinfo' to 'None' to
-      signal that it is not in the 'self.fileinfo' AND it also doesn't exist
-      locally.
-
-    <Arguments>
-      metadata_filename:
-        The metadata filename for the role.  For the 'root' role,
-        'metadata_filename' would be 'root.json'.
-
-    <Exceptions>
-      None.
-
-    <Side Effects>
-      The file details of 'metadata_filename' is calculated and
-      stored in 'self.fileinfo'.
-
-    <Returns>
-      None.
-    """
-
-    # In case we delayed loading the metadata and didn't do it in
-    # __init__ (such as with delegated metadata), then get the file
-    # info now.
-
-    # Save the path to the current metadata file for 'metadata_filename'.
-    current_filepath = os.path.join(self.metadata_directory['current'],
-        metadata_filename)
-
-    # If the path is invalid, simply return and leave fileinfo unset.
-    if not os.path.exists(current_filepath):
-      self.fileinfo[metadata_filename] = None
-      return
-
-    # Extract the file information from the actual file and save it
-    # to the fileinfo store.
-    file_length, hashes = sslib_util.get_file_details(current_filepath)
-    metadata_fileinfo = formats.make_targets_fileinfo(file_length, hashes)
-    self.fileinfo[metadata_filename] = metadata_fileinfo
-
-
-
-
-
-
-
   def _move_current_to_previous(self, metadata_role):
     """
     <Purpose>
@@ -2175,7 +2060,7 @@ def _move_current_to_previous(self, metadata_role):
     """
 
     # Get the 'current' and 'previous' full file paths for 'metadata_role'
-    metadata_filepath = metadata_role + '.json'
+    metadata_filepath = self._get_local_filename(metadata_role)
     previous_filepath = os.path.join(self.metadata_directory['previous'],
                                      metadata_filepath)
     current_filepath = os.path.join(self.metadata_directory['current'],
diff --git a/tuf/ngclient/updater.py b/tuf/ngclient/updater.py
index 424a74e2e9..fdbcec4ed3 100644
--- a/tuf/ngclient/updater.py
+++ b/tuf/ngclient/updater.py
@@ -278,28 +278,27 @@ def _download_metadata(
     ) -> bytes:
         """Download a metadata file and return it as bytes"""
         if version is None:
-            filename = f"{rolename}.json"
+            url = f"{self._metadata_base_url}{rolename}.json"
         else:
-            filename = f"{version}.{rolename}.json"
-        url = parse.urljoin(self._metadata_base_url, filename)
+            url = f"{self._metadata_base_url}{version}.{rolename}.json"
         return self._fetcher.download_bytes(url, length)
 
     def _load_local_metadata(self, rolename: str) -> bytes:
-        with open(os.path.join(self._dir, f"{rolename}.json"), "rb") as f:
+        encoded_name = parse.quote(rolename, "")
+        with open(os.path.join(self._dir, f"{encoded_name}.json"), "rb") as f:
             return f.read()
 
     def _persist_metadata(self, rolename: str, data: bytes) -> None:
-        """Acts as an atomic write operation to make sure
-        that if the process of writing is halted, at least the
-        original data is left intact.
-        """
+        """Write metadata to disk atomically to avoid data loss."""
 
-        original_filename = os.path.join(self._dir, f"{rolename}.json")
+        # encode the rolename to avoid issues with e.g. path separators
+        encoded_name = parse.quote(rolename, "")
+        filename = os.path.join(self._dir, f"{encoded_name}.json")
         with tempfile.NamedTemporaryFile(
             dir=self._dir, delete=False
         ) as temp_file:
             temp_file.write(data)
-        os.replace(temp_file.name, original_filename)
+        os.replace(temp_file.name, filename)
 
     def _load_root(self) -> None:
         """Load remote root metadata.
